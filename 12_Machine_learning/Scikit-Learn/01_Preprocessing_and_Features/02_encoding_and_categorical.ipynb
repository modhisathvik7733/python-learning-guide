{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Encoding Categorical Variables\n",
    "\n",
    "## The Problem\n",
    "\n",
    "Machine learning algorithms work with **numbers**, not text. We need to convert categorical data into numerical format.\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Color: ['Red', 'Blue', 'Green'] → ?\n",
    "```\n",
    "\n",
    "## Types of Categorical Data\n",
    "\n",
    "| Type | Definition | Examples |\n",
    "|------|------------|----------|\n",
    "| **Nominal** | No order/ranking | Colors, Countries, Gender |\n",
    "| **Ordinal** | Has meaningful order | Education (High School < Bachelor < Master), Ratings (Poor < Good < Excellent) |\n",
    "\n",
    "## Encoding Methods\n",
    "\n",
    "| Encoder | Use For | Output | When to Use |\n",
    "|---------|---------|--------|-------------|\n",
    "| **LabelEncoder** | Target variable (y) | Single column: [0, 1, 2, ...] | Classification labels only |\n",
    "| **OrdinalEncoder** | Ordinal features (X) | Ordered integers | When categories have meaningful order |\n",
    "| **OneHotEncoder** | Nominal features (X) | Multiple binary columns | Most common for features with no order |\n",
    "| **get_dummies** | Quick encoding | Multiple binary columns | Pandas convenience (not for production) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-data",
   "metadata": {},
   "source": [
    "## Sample Dataset: Customer Data\n",
    "\n",
    "Let's create a realistic dataset with different types of categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "create-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   customer_id       city    education product satisfaction  purchased\n",
      "0            1     Mumbai  High School  Laptop         Good          1\n",
      "1            2      Delhi     Bachelor   Phone    Excellent          1\n",
      "2            3     Mumbai       Master  Tablet         Poor          0\n",
      "3            4  Bangalore     Bachelor  Laptop         Good          1\n",
      "4            5      Delhi          PhD   Phone    Excellent          1\n",
      "5            6    Chennai  High School  Tablet         Good          0\n",
      "6            7     Mumbai       Master  Laptop    Excellent          1\n",
      "7            8  Bangalore     Bachelor   Phone         Poor          0\n",
      "8            9    Chennai          PhD  Tablet         Good          1\n",
      "9           10      Delhi       Master  Laptop    Excellent          1\n",
      "\n",
      "Data Types:\n",
      "customer_id      int64\n",
      "city            object\n",
      "education       object\n",
      "product         object\n",
      "satisfaction    object\n",
      "purchased        int64\n",
      "dtype: object\n",
      "\n",
      "Categorical Columns:\n",
      "['city', 'education', 'product', 'satisfaction']\n"
     ]
    }
   ],
   "source": [
    "# Create customer dataset\n",
    "data = {\n",
    "    'customer_id': range(1, 11),\n",
    "    'city': ['Mumbai', 'Delhi', 'Mumbai', 'Bangalore', 'Delhi', \n",
    "             'Chennai', 'Mumbai', 'Bangalore', 'Chennai', 'Delhi'],\n",
    "    'education': ['High School', 'Bachelor', 'Master', 'Bachelor', 'PhD',\n",
    "                  'High School', 'Master', 'Bachelor', 'PhD', 'Master'],\n",
    "    'product': ['Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone',\n",
    "                'Tablet', 'Laptop', 'Phone', 'Tablet', 'Laptop'],\n",
    "    'satisfaction': ['Good', 'Excellent', 'Poor', 'Good', 'Excellent',\n",
    "                     'Good', 'Excellent', 'Poor', 'Good', 'Excellent'],\n",
    "    'purchased': [1, 1, 0, 1, 1, 0, 1, 0, 1, 1]  # Target variable\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Dataset:\")\n",
    "print(df)\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nCategorical Columns:\")\n",
    "print(df.select_dtypes(include='object').columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "label-encoder",
   "metadata": {},
   "source": [
    "## 1. LabelEncoder\n",
    "\n",
    "**Definition**: Converts each unique category to an integer (0, 1, 2, ...)\n",
    "\n",
    "**Use Case**: Encoding **target variable (y)** only\n",
    "\n",
    "**Warning**: ⚠️ Don't use for features! Creates false ordering.\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "['Red', 'Blue', 'Green', 'Red'] → [2, 0, 1, 2]\n",
    "```\n",
    "\n",
    "**Why not for features?**\n",
    "- Algorithm might think Blue(0) < Green(1) < Red(2)\n",
    "- No such relationship exists for colors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "label-encoder-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['Good' 'Excellent' 'Poor' 'Good' 'Excellent' 'Good' 'Excellent' 'Poor'\n",
      " 'Good' 'Excellent']\n",
      "Encoded:  [1 0 2 1 0 1 0 2 1 0]\n",
      "\n",
      "Mapping:\n",
      "  Excellent    → 0\n",
      "  Good         → 1\n",
      "  Poor         → 2\n",
      "\n",
      "Inverse transform: ['Good' 'Excellent' 'Poor' 'Good' 'Excellent' 'Good' 'Excellent' 'Poor'\n",
      " 'Good' 'Excellent']\n",
      "\n",
      "============================================================\n",
      "WHY NOT USE FOR FEATURES?\n",
      "============================================================\n",
      "\n",
      "Cities encoded with LabelEncoder:\n",
      "  Mumbai       → 3\n",
      "  Delhi        → 2\n",
      "  Bangalore    → 0\n",
      "  Chennai      → 1\n",
      "\n",
      "⚠️ Problem: Algorithm thinks Bangalore(0) < Chennai(1) < Delhi(2) < Mumbai(3)\n",
      "   But cities have NO inherent order!\n",
      "   Solution: Use OneHotEncoder for nominal features\n"
     ]
    }
   ],
   "source": [
    "# LabelEncoder for target variable\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Example: Encode satisfaction levels\n",
    "satisfaction = df['satisfaction'].values\n",
    "print(\"Original:\", satisfaction)\n",
    "\n",
    "# Fit and transform\n",
    "satisfaction_encoded = le.fit_transform(satisfaction)\n",
    "print(\"Encoded: \", satisfaction_encoded)\n",
    "\n",
    "# See the mapping\n",
    "print(\"\\nMapping:\")\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f\"  {label:12s} → {i}\")\n",
    "\n",
    "# Inverse transform (get back original)\n",
    "original_back = le.inverse_transform(satisfaction_encoded)\n",
    "print(\"\\nInverse transform:\", original_back)\n",
    "\n",
    "# ⚠️ Problem with LabelEncoder for features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WHY NOT USE FOR FEATURES?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cities = ['Mumbai', 'Delhi', 'Bangalore', 'Chennai']\n",
    "le_city = LabelEncoder()\n",
    "encoded_cities = le_city.fit_transform(cities)\n",
    "\n",
    "print(\"\\nCities encoded with LabelEncoder:\")\n",
    "for city, code in zip(cities, encoded_cities):\n",
    "    print(f\"  {city:12s} → {code}\")\n",
    "\n",
    "print(\"\\n⚠️ Problem: Algorithm thinks Bangalore(0) < Chennai(1) < Delhi(2) < Mumbai(3)\")\n",
    "print(\"   But cities have NO inherent order!\")\n",
    "print(\"   Solution: Use OneHotEncoder for nominal features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinal-encoder",
   "metadata": {},
   "source": [
    "## 2. OrdinalEncoder\n",
    "\n",
    "**Definition**: Encodes categorical features with meaningful order\n",
    "\n",
    "**Use Case**: Features with **natural ordering** (ordinal data)\n",
    "\n",
    "**Examples**:\n",
    "- Education: High School < Bachelor < Master < PhD\n",
    "- Temperature: Cold < Warm < Hot\n",
    "- Rating: Poor < Fair < Good < Excellent\n",
    "\n",
    "**Advantage**: Preserves order information for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ordinal-encoder-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Education:\n",
      "['High School' 'Bachelor' 'Master' 'Bachelor' 'PhD' 'High School' 'Master'\n",
      " 'Bachelor' 'PhD' 'Master']\n",
      "\n",
      "Encoded (with order):\n",
      "[0. 1. 2. 1. 3. 0. 2. 1. 3. 2.]\n",
      "\n",
      "Mapping (preserves order):\n",
      "  0 ← High School\n",
      "  1 ← Bachelor\n",
      "  2 ← Master\n",
      "  3 ← PhD\n",
      "\n",
      "============================================================\n",
      "MULTIPLE ORDINAL COLUMNS\n",
      "============================================================\n",
      "\n",
      "Original vs Encoded:\n",
      "     education satisfaction  education_encoded  satisfaction_encoded\n",
      "0  High School         Good                0.0                   1.0\n",
      "1     Bachelor    Excellent                1.0                   2.0\n",
      "2       Master         Poor                2.0                   0.0\n",
      "3     Bachelor         Good                1.0                   1.0\n",
      "4          PhD    Excellent                3.0                   2.0\n",
      "5  High School         Good                0.0                   1.0\n",
      "6       Master    Excellent                2.0                   2.0\n",
      "7     Bachelor         Poor                1.0                   0.0\n",
      "8          PhD         Good                3.0                   1.0\n",
      "9       Master    Excellent                2.0                   2.0\n"
     ]
    }
   ],
   "source": [
    "# Define custom order for education\n",
    "education_order = ['High School', 'Bachelor', 'Master', 'PhD']\n",
    "\n",
    "# OrdinalEncoder with custom order\n",
    "oe = OrdinalEncoder(categories=[education_order])\n",
    "\n",
    "# Reshape for sklearn (needs 2D array)\n",
    "education_data = df[['education']]\n",
    "print(\"Original Education:\")\n",
    "print(education_data.values.flatten())\n",
    "\n",
    "# Fit and transform\n",
    "education_encoded = oe.fit_transform(education_data)\n",
    "print(\"\\nEncoded (with order):\")\n",
    "print(education_encoded.flatten())\n",
    "\n",
    "print(\"\\nMapping (preserves order):\")\n",
    "for i, level in enumerate(education_order):\n",
    "    print(f\"  {i} ← {level}\")\n",
    "\n",
    "# Multiple ordinal columns\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTIPLE ORDINAL COLUMNS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "satisfaction_order = ['Poor', 'Good', 'Excellent']\n",
    "\n",
    "# Create ordinal encoder for multiple columns\n",
    "oe_multi = OrdinalEncoder(categories=[education_order, satisfaction_order])\n",
    "\n",
    "# Encode both columns\n",
    "ordinal_features = df[['education', 'satisfaction']]\n",
    "ordinal_encoded = oe_multi.fit_transform(ordinal_features)\n",
    "\n",
    "result_df = pd.DataFrame(\n",
    "    ordinal_encoded,\n",
    "    columns=['education_encoded', 'satisfaction_encoded']\n",
    ")\n",
    "result_df = pd.concat([ordinal_features.reset_index(drop=True), result_df], axis=1)\n",
    "\n",
    "print(\"\\nOriginal vs Encoded:\")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "onehot-encoder",
   "metadata": {},
   "source": [
    "## 3. OneHotEncoder\n",
    "\n",
    "**Definition**: Creates binary column for each category\n",
    "\n",
    "**Use Case**: Nominal features with **no order**\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Color: ['Red', 'Blue', 'Green']\n",
    "\n",
    "Becomes:\n",
    "  Red  Blue  Green\n",
    "   1     0      0     (Red)\n",
    "   0     1      0     (Blue)\n",
    "   0     0      1     (Green)\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- No false ordering\n",
    "- Each category is independent\n",
    "\n",
    "**Disadvantage**: High cardinality (many categories) creates many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "onehot-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Cities:\n",
      "['Mumbai' 'Delhi' 'Mumbai' 'Bangalore' 'Delhi' 'Chennai' 'Mumbai'\n",
      " 'Bangalore' 'Chennai' 'Delhi']\n",
      "\n",
      "One-Hot Encoded Shape: (10, 4)\n",
      "\n",
      "Encoded Matrix:\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "\n",
      "Column Names: ['city_Bangalore' 'city_Chennai' 'city_Delhi' 'city_Mumbai']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create readable dataframe\u001b[39;00m\n\u001b[1;32m     19\u001b[0m city_encoded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(city_encoded, columns\u001b[38;5;241m=\u001b[39mfeature_names)\n\u001b[0;32m---> 20\u001b[0m city_encoded_df\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_city\u001b[39m\u001b[38;5;124m'\u001b[39m, city_data\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReadable Format:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(city_encoded_df)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py:5171\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   5169\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 5171\u001b[0m value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m   5172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(loc, column, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py:5267\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m-> 5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n\u001b[1;32m   5275\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   5276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting an Index with object dtype into a DataFrame will stop \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferring another dtype in a future version. Cast the Index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   5281\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/construction.py:606\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    604\u001b[0m subarr \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 606\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(data)\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    608\u001b[0m         object_index\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_pyarrow_string_dtype()\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr)\n\u001b[1;32m    611\u001b[0m     ):\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[1;32m    613\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/dtypes/cast.py:1181\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(value))  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;66;03m# Caller is responsible\u001b[39;00m\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(value\u001b[38;5;241m.\u001b[39mndim)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mValueError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# OneHotEncoder for city (nominal feature)\n",
    "ohe = OneHotEncoder(sparse_output=False)  # sparse_output=False for readable output\n",
    "\n",
    "city_data = df[['city']]\n",
    "print(\"Original Cities:\")\n",
    "print(city_data.values.flatten())\n",
    "\n",
    "# Fit and transform\n",
    "city_encoded = ohe.fit_transform(city_data)\n",
    "print(\"\\nOne-Hot Encoded Shape:\", city_encoded.shape)\n",
    "print(\"\\nEncoded Matrix:\")\n",
    "print(city_encoded)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = ohe.get_feature_names_out(['city'])\n",
    "print(\"\\nColumn Names:\", feature_names)\n",
    "\n",
    "# Create readable dataframe\n",
    "city_encoded_df = pd.DataFrame(city_encoded, columns=feature_names)\n",
    "city_encoded_df.insert(0, 'original_city', city_data.values)\n",
    "\n",
    "print(\"\\nReadable Format:\")\n",
    "print(city_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "onehot-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder for multiple columns\n",
    "print(\"=\"*60)\n",
    "print(\"ONE-HOT ENCODING MULTIPLE COLUMNS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select nominal features\n",
    "nominal_features = df[['city', 'product']]\n",
    "print(\"\\nOriginal Data:\")\n",
    "print(nominal_features)\n",
    "\n",
    "# Encode\n",
    "ohe_multi = OneHotEncoder(sparse_output=False)\n",
    "encoded = ohe_multi.fit_transform(nominal_features)\n",
    "\n",
    "# Get column names\n",
    "column_names = ohe_multi.get_feature_names_out(['city', 'product'])\n",
    "print(\"\\nGenerated Columns:\", column_names)\n",
    "\n",
    "# Create dataframe\n",
    "encoded_df = pd.DataFrame(encoded, columns=column_names)\n",
    "print(\"\\nEncoded Result:\")\n",
    "print(encoded_df.head())\n",
    "print(f\"\\nShape: {nominal_features.shape} → {encoded_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drop-first",
   "metadata": {},
   "source": [
    "## Important: drop='first' to Avoid Dummy Variable Trap\n",
    "\n",
    "**Problem**: OneHotEncoding creates multicollinearity\n",
    "\n",
    "**Example**: For 3 colors, we create 3 columns\n",
    "```\n",
    "Red  Blue  Green\n",
    " 1    0     0      If Red=0 AND Blue=0, we KNOW Green=1\n",
    " 0    1     0      One column is redundant!\n",
    " 0    0     1\n",
    "```\n",
    "\n",
    "**Solution**: Drop first column (or any one column)\n",
    "\n",
    "**When to use**:\n",
    "- Linear models (Linear/Logistic Regression)\n",
    "- Tree-based models: not necessary but saves memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drop-first-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without drop='first'\n",
    "ohe_full = OneHotEncoder(sparse_output=False)\n",
    "city_full = ohe_full.fit_transform(df[['city']])\n",
    "\n",
    "print(\"Without drop='first':\")\n",
    "print(f\"Columns: {ohe_full.get_feature_names_out()}\")\n",
    "print(f\"Shape: {city_full.shape}\")\n",
    "print(city_full[:3])\n",
    "\n",
    "# With drop='first' (recommended for linear models)\n",
    "ohe_drop = OneHotEncoder(sparse_output=False, drop='first')\n",
    "city_drop = ohe_drop.fit_transform(df[['city']])\n",
    "\n",
    "print(\"\\nWith drop='first':\")\n",
    "print(f\"Columns: {ohe_drop.get_feature_names_out()}\")\n",
    "print(f\"Shape: {city_drop.shape}\")\n",
    "print(city_drop[:3])\n",
    "print(\"\\n✓ First category (Bangalore) dropped\")\n",
    "print(\"  If all columns are 0 → Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handle-unknown",
   "metadata": {},
   "source": [
    "## Handling Unknown Categories\n",
    "\n",
    "**Problem**: What if test data has categories not seen in training?\n",
    "\n",
    "**Solution**: Use `handle_unknown='ignore'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-categories",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "train_cities = np.array([['Mumbai'], ['Delhi'], ['Bangalore']])\n",
    "\n",
    "# Fit encoder\n",
    "ohe_unknown = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "ohe_unknown.fit(train_cities)\n",
    "\n",
    "print(\"Trained on:\", train_cities.flatten())\n",
    "print(\"Categories learned:\", ohe_unknown.categories_)\n",
    "\n",
    "# Test data with unknown category\n",
    "test_cities = np.array([['Mumbai'], ['Kolkata'], ['Delhi']])  # Kolkata is new!\n",
    "\n",
    "print(\"\\nTest data:\", test_cities.flatten())\n",
    "\n",
    "# Transform (without error)\n",
    "test_encoded = ohe_unknown.transform(test_cities)\n",
    "print(\"\\nEncoded:\")\n",
    "print(test_encoded)\n",
    "print(\"\\n'Kolkata' (unknown) → all zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pandas-dummies",
   "metadata": {},
   "source": [
    "## Pandas get_dummies() - Quick Alternative\n",
    "\n",
    "**Use Case**: Quick exploratory data analysis\n",
    "\n",
    "**Limitations**:\n",
    "- Not compatible with sklearn pipelines\n",
    "- Can't handle unknown categories in test data\n",
    "- Not recommended for production\n",
    "\n",
    "**When to use**: Prototyping, notebooks, quick experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pandas-dummies-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data\n",
    "print(\"Original DataFrame:\")\n",
    "print(df[['city', 'product', 'satisfaction']].head())\n",
    "\n",
    "# get_dummies - all categorical columns\n",
    "df_dummies = pd.get_dummies(df[['city', 'product', 'satisfaction']])\n",
    "print(\"\\nAfter get_dummies():\")\n",
    "print(df_dummies.head())\n",
    "print(f\"\\nShape: 3 columns → {df_dummies.shape[1]} columns\")\n",
    "\n",
    "# With drop_first\n",
    "df_dummies_drop = pd.get_dummies(\n",
    "    df[['city', 'product', 'satisfaction']], \n",
    "    drop_first=True\n",
    ")\n",
    "print(\"\\nWith drop_first=True:\")\n",
    "print(f\"Shape: {df_dummies_drop.shape[1]} columns\")\n",
    "print(df_dummies_drop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real-world-example",
   "metadata": {},
   "source": [
    "## Real-World Example: Predicting Purchases\n",
    "\n",
    "Complete pipeline with proper encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ml-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create larger dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "cities = np.random.choice(['Mumbai', 'Delhi', 'Bangalore', 'Chennai'], n_samples)\n",
    "education = np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples)\n",
    "product = np.random.choice(['Laptop', 'Phone', 'Tablet'], n_samples)\n",
    "age = np.random.randint(20, 60, n_samples)\n",
    "salary = np.random.randint(30000, 150000, n_samples)\n",
    "\n",
    "# Target: purchased (influenced by salary and education)\n",
    "purchased = ((salary > 80000) & (education != 'High School')).astype(int)\n",
    "purchased = np.random.permutation(purchased)  # Add randomness\n",
    "\n",
    "data_large = pd.DataFrame({\n",
    "    'city': cities,\n",
    "    'education': education,\n",
    "    'product': product,\n",
    "    'age': age,\n",
    "    'salary': salary,\n",
    "    'purchased': purchased\n",
    "})\n",
    "\n",
    "print(\"Dataset:\")\n",
    "print(data_large.head(10))\n",
    "print(f\"\\nShape: {data_large.shape}\")\n",
    "print(f\"Purchase rate: {data_large['purchased'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ml-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data_large.drop('purchased', axis=1)\n",
    "y = data_large['purchased']\n",
    "\n",
    "# Split data FIRST\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:    \", X_test.shape)\n",
    "\n",
    "# Identify column types\n",
    "nominal_cols = ['city', 'product']\n",
    "ordinal_cols = ['education']\n",
    "numeric_cols = ['age', 'salary']\n",
    "\n",
    "print(\"\\nColumn Types:\")\n",
    "print(f\"  Nominal: {nominal_cols}\")\n",
    "print(f\"  Ordinal: {ordinal_cols}\")\n",
    "print(f\"  Numeric: {numeric_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encode-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode nominal features (city, product)\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_train_nominal = ohe.fit_transform(X_train[nominal_cols])\n",
    "X_test_nominal = ohe.transform(X_test[nominal_cols])\n",
    "\n",
    "nominal_feature_names = ohe.get_feature_names_out(nominal_cols)\n",
    "print(\"Nominal features encoded:\")\n",
    "print(f\"  Original: {nominal_cols}\")\n",
    "print(f\"  Encoded:  {nominal_feature_names}\")\n",
    "print(f\"  Shape: {X_train[nominal_cols].shape} → {X_train_nominal.shape}\")\n",
    "\n",
    "# Encode ordinal features (education)\n",
    "education_order = ['High School', 'Bachelor', 'Master', 'PhD']\n",
    "oe = OrdinalEncoder(categories=[education_order])\n",
    "X_train_ordinal = oe.fit_transform(X_train[ordinal_cols])\n",
    "X_test_ordinal = oe.transform(X_test[ordinal_cols])\n",
    "\n",
    "print(\"\\nOrdinal features encoded:\")\n",
    "print(f\"  {ordinal_cols} with order: {education_order}\")\n",
    "\n",
    "# Get numeric features\n",
    "X_train_numeric = X_train[numeric_cols].values\n",
    "X_test_numeric = X_test[numeric_cols].values\n",
    "\n",
    "# Combine all features\n",
    "X_train_processed = np.hstack([\n",
    "    X_train_nominal,\n",
    "    X_train_ordinal,\n",
    "    X_train_numeric\n",
    "])\n",
    "\n",
    "X_test_processed = np.hstack([\n",
    "    X_test_nominal,\n",
    "    X_test_ordinal,\n",
    "    X_test_numeric\n",
    "])\n",
    "\n",
    "print(\"\\nFinal processed features:\")\n",
    "print(f\"  Training: {X_train_processed.shape}\")\n",
    "print(f\"  Test:     {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = rf.predict(X_train_processed)\n",
    "y_pred_test = rf.predict(X_test_processed)\n",
    "\n",
    "# Evaluate\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:     {test_acc:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "all_feature_names = list(nominal_feature_names) + ordinal_cols + numeric_cols\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "## Comparison: When to Use Each Encoder\n",
    "\n",
    "| Scenario | Encoder | Reason |\n",
    "|----------|---------|--------|\n",
    "| Target variable for classification | **LabelEncoder** | Converts classes to 0, 1, 2, ... |\n",
    "| Education level (High School → PhD) | **OrdinalEncoder** | Preserves natural order |\n",
    "| City/Country names | **OneHotEncoder** | No inherent order |\n",
    "| Product categories | **OneHotEncoder** | Independent categories |\n",
    "| Temperature (Cold/Warm/Hot) | **OrdinalEncoder** | Has meaningful order |\n",
    "| Size (S/M/L/XL) | **OrdinalEncoder** | Has size order |\n",
    "| Color (Red/Blue/Green) | **OneHotEncoder** | No natural order |\n",
    "| Rating (1-5 stars) | **OrdinalEncoder** | Ordered scale |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "high-cardinality",
   "metadata": {},
   "source": [
    "## Handling High Cardinality Features\n",
    "\n",
    "**Problem**: Feature with 100+ categories → 100+ columns after OneHotEncoding\n",
    "\n",
    "**Solutions**:\n",
    "\n",
    "1. **Frequency Encoding**: Replace category with its frequency\n",
    "2. **Target Encoding**: Replace with mean of target for that category\n",
    "3. **Grouping**: Combine rare categories into 'Other'\n",
    "4. **Hashing**: Use FeatureHasher (covered in text features notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "high-cardinality-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: High cardinality feature\n",
    "cities_many = ['City_' + str(i) for i in range(50)]  # 50 cities\n",
    "city_sample = np.random.choice(cities_many, 100)\n",
    "\n",
    "print(f\"Number of unique cities: {len(np.unique(city_sample))}\")\n",
    "print(\"OneHotEncoding would create 50 columns!\\n\")\n",
    "\n",
    "# Solution 1: Frequency Encoding\n",
    "city_counts = pd.Series(city_sample).value_counts()\n",
    "city_freq_encoded = pd.Series(city_sample).map(city_counts)\n",
    "\n",
    "print(\"Frequency Encoding:\")\n",
    "print(f\"Original: {city_sample[:5]}\")\n",
    "print(f\"Encoded:  {city_freq_encoded[:5].values}\")\n",
    "print(\"Each city → its frequency count\")\n",
    "\n",
    "# Solution 2: Group rare categories\n",
    "top_10_cities = city_counts.head(10).index\n",
    "city_grouped = pd.Series(city_sample).apply(\n",
    "    lambda x: x if x in top_10_cities else 'Other'\n",
    ")\n",
    "\n",
    "print(f\"\\nGrouping: 50 categories → {len(city_grouped.unique())} categories\")\n",
    "print(f\"Top 10 cities kept, rest grouped as 'Other'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Decision Flow Chart\n",
    "\n",
    "```\n",
    "START: Have categorical variable\n",
    "  |\n",
    "  ├─ Is it TARGET variable (y)?\n",
    "  │   └─ YES → LabelEncoder\n",
    "  |\n",
    "  ├─ Is it FEATURE (X)?\n",
    "  │   |\n",
    "  │   ├─ Has natural ORDER?\n",
    "  │   │   └─ YES → OrdinalEncoder\n",
    "  │   │       (e.g., education, rating, temperature)\n",
    "  │   |\n",
    "  │   └─ NO ORDER (nominal)?\n",
    "  │       └─ YES → OneHotEncoder\n",
    "  │           (e.g., city, color, product)\n",
    "  │       |\n",
    "  │       ├─ High cardinality (>50 categories)?\n",
    "  │       │   └─ Consider: Frequency/Target encoding or grouping\n",
    "  │       |\n",
    "  │       └─ Use drop='first' for linear models\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **LabelEncoder**: Only for target variable (y)\n",
    "2. **OrdinalEncoder**: For features with meaningful order\n",
    "3. **OneHotEncoder**: For features without order (most common)\n",
    "4. **Always fit on training data**, transform on test\n",
    "5. **Use `drop='first'`** for linear models to avoid dummy variable trap\n",
    "6. **Use `handle_unknown='ignore'`** to handle new categories in test set\n",
    "7. **High cardinality**: Consider alternatives to OneHotEncoding\n",
    "8. **Pandas get_dummies**: Quick but not for production\n",
    "\n",
    "## Common Mistakes to Avoid\n",
    "\n",
    "❌ Using LabelEncoder for features (creates false ordering)  \n",
    "❌ Fitting encoder on test data  \n",
    "❌ Encoding before train-test split  \n",
    "❌ Not handling unknown categories  \n",
    "❌ Forgetting to combine encoded features with numeric ones  \n",
    "\n",
    "✅ OneHotEncode nominal features  \n",
    "✅ Ordinal encode ordered features  \n",
    "✅ Fit on train, transform on test  \n",
    "✅ Use pipelines for proper workflow  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
