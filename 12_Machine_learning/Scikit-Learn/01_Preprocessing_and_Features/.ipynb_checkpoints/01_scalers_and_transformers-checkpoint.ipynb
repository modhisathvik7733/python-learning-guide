{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# Scalers and Transformers in Sklearn\n",
        "\n",
        "## Why Feature Scaling?\n",
        "\n",
        "**Problem**: Features with different scales can dominate the learning process.\n",
        "\n",
        "**Example**:\n",
        "- Age: 25-80 (small range)\n",
        "- Income: 20,000-150,000 (large range)\n",
        "\n",
        "Machine learning algorithms (especially distance-based ones like KNN, SVM, Neural Networks) treat all features equally. Without scaling, 'Income' would dominate because its values are much larger.\n",
        "\n",
        "## When to Scale?\n",
        "\n",
        "| Need Scaling | Don't Need Scaling |\n",
        "|--------------|--------------------|\n",
        "| Neural Networks | Tree-based models (Decision Trees, Random Forest, XGBoost) |\n",
        "| SVM | Naive Bayes |\n",
        "| KNN | |\n",
        "| Linear/Logistic Regression | |\n",
        "| PCA, K-Means | |\n",
        "\n",
        "## Types of Scalers\n",
        "\n",
        "| Scaler | Formula | Range | Use When |\n",
        "|--------|---------|-------|----------|\n",
        "| **StandardScaler** | \\\\( \\frac{x - \\mu}{\\sigma} \\\\) | Mean=0, Std=1 | Data is normally distributed |\n",
        "| **MinMaxScaler** | \\\\( \\frac{x - x_{min}}{x_{max} - x_{min}} \\\\) | [0, 1] or custom | Need bounded range |\n",
        "| **RobustScaler** | \\\\( \\frac{x - Q_{50}}{Q_{75} - Q_{25}} \\\\) | Varies | Data has outliers |\n",
        "| **PowerTransformer** | Box-Cox/Yeo-Johnson | ~Normal dist | Make data more Gaussian |\n",
        "| **Normalizer** | \\\\( \\frac{x}{||x||} \\\\) | L2 norm = 1 | For text/sparse data |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, MinMaxScaler, RobustScaler, \n",
        "    PowerTransformer, Normalizer\n",
        ")\n",
        "from sklearn.datasets import load_diabetes, load_wine\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "create-data",
      "metadata": {},
      "source": [
        "## Example Dataset: Employee Data\n",
        "\n",
        "Let's create a realistic dataset with different scales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sample-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample employee data\n",
        "data = {\n",
        "    'age': [25, 30, 35, 40, 45, 50, 28, 33, 38, 43],\n",
        "    'salary': [45000, 55000, 65000, 75000, 85000, 95000, 50000, 60000, 70000, 80000],\n",
        "    'experience_years': [2, 5, 8, 12, 15, 20, 3, 6, 10, 14],\n",
        "    'hours_per_week': [40, 45, 42, 38, 50, 48, 41, 43, 39, 46]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(df)\n",
        "print(\"\\nStatistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Notice the different scales:\n",
        "print(\"\\nFeature Ranges:\")\n",
        "for col in df.columns:\n",
        "    print(f\"{col:20s}: [{df[col].min():,.0f}, {df[col].max():,.0f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "standard-scaler",
      "metadata": {},
      "source": [
        "## 1. StandardScaler (Z-score Normalization)\n",
        "\n",
        "**Definition**: Transforms features to have mean=0 and standard deviation=1\n",
        "\n",
        "**Formula**: \\\\( z = \\frac{x - \\mu}{\\sigma} \\\\)\n",
        "- \\\\(\\mu\\\\) = mean of feature\n",
        "- \\\\(\\sigma\\\\) = standard deviation\n",
        "\n",
        "**When to Use**:\n",
        "- Data is roughly normally distributed\n",
        "- No strict bounds needed\n",
        "- Most common choice for many algorithms\n",
        "\n",
        "**Assumptions**: Features follow Gaussian distribution (no strong outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "standard-scaler-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# StandardScaler\n",
        "scaler_std = StandardScaler()\n",
        "\n",
        "# Fit and transform\n",
        "df_std = pd.DataFrame(\n",
        "    scaler_std.fit_transform(df),\n",
        "    columns=df.columns\n",
        ")\n",
        "\n",
        "print(\"StandardScaler Results:\")\n",
        "print(df_std.round(3))\n",
        "print(\"\\nVerify: Mean \u2248 0, Std \u2248 1\")\n",
        "print(df_std.describe().round(3))\n",
        "\n",
        "# Access learned parameters\n",
        "print(\"\\nLearned Parameters:\")\n",
        "print(f\"Mean (\u00b5):  {scaler_std.mean_}\")\n",
        "print(f\"Std (\u03c3):   {np.sqrt(scaler_std.var_)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "minmax-scaler",
      "metadata": {},
      "source": [
        "## 2. MinMaxScaler\n",
        "\n",
        "**Definition**: Scales features to a fixed range (default [0, 1])\n",
        "\n",
        "**Formula**: \\\\( x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}} \\\\)\n",
        "\n",
        "**When to Use**:\n",
        "- Need features in specific range (e.g., [0, 1] for neural networks)\n",
        "- Data has known bounds\n",
        "- Image pixel values (already in [0, 255])\n",
        "\n",
        "**Warning**: Sensitive to outliers (one extreme value affects entire scaling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "minmax-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# MinMaxScaler (default: [0, 1])\n",
        "scaler_minmax = MinMaxScaler()\n",
        "df_minmax = pd.DataFrame(\n",
        "    scaler_minmax.fit_transform(df),\n",
        "    columns=df.columns\n",
        ")\n",
        "\n",
        "print(\"MinMaxScaler Results (range [0, 1]):\")\n",
        "print(df_minmax.round(3))\n",
        "print(\"\\nMin and Max values:\")\n",
        "print(f\"Min: {df_minmax.min().values}\")\n",
        "print(f\"Max: {df_minmax.max().values}\")\n",
        "\n",
        "# Custom range [-1, 1]\n",
        "scaler_custom = MinMaxScaler(feature_range=(-1, 1))\n",
        "df_custom = pd.DataFrame(\n",
        "    scaler_custom.fit_transform(df),\n",
        "    columns=df.columns\n",
        ")\n",
        "\n",
        "print(\"\\nMinMaxScaler with custom range [-1, 1]:\")\n",
        "print(df_custom.round(3))\n",
        "print(f\"\\nRange: [{df_custom.min().min():.1f}, {df_custom.max().max():.1f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "robust-scaler",
      "metadata": {},
      "source": [
        "## 3. RobustScaler\n",
        "\n",
        "**Definition**: Scales using median and IQR (Interquartile Range), robust to outliers\n",
        "\n",
        "**Formula**: \\\\( x_{scaled} = \\frac{x - Q_{50}}{Q_{75} - Q_{25}} \\\\)\n",
        "- \\\\(Q_{50}\\\\) = Median\n",
        "- \\\\(Q_{75} - Q_{25}\\\\) = IQR (middle 50% of data)\n",
        "\n",
        "**When to Use**:\n",
        "- Data has outliers\n",
        "- Distribution is skewed\n",
        "- Don't want outliers to affect scaling\n",
        "\n",
        "**Advantage**: Outliers don't influence the scaling parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "robust-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add outlier to demonstrate RobustScaler\n",
        "df_with_outlier = df.copy()\n",
        "df_with_outlier.loc[10] = [25, 250000, 2, 40]  # Salary outlier!\n",
        "\n",
        "print(\"Data with Outlier:\")\n",
        "print(df_with_outlier)\n",
        "\n",
        "# Compare StandardScaler vs RobustScaler\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON: StandardScaler vs RobustScaler\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# StandardScaler (affected by outlier)\n",
        "std_scaler = StandardScaler()\n",
        "df_std_out = pd.DataFrame(\n",
        "    std_scaler.fit_transform(df_with_outlier),\n",
        "    columns=df.columns\n",
        ")\n",
        "\n",
        "# RobustScaler (not affected by outlier)\n",
        "robust_scaler = RobustScaler()\n",
        "df_robust = pd.DataFrame(\n",
        "    robust_scaler.fit_transform(df_with_outlier),\n",
        "    columns=df.columns\n",
        ")\n",
        "\n",
        "print(\"\\nStandardScaler (salary column):\")\n",
        "print(df_std_out['salary'].values)\n",
        "print(f\"Notice: Outlier at index 10 has value {df_std_out['salary'].iloc[10]:.2f}\")\n",
        "print(f\"Other values compressed near 0\")\n",
        "\n",
        "print(\"\\nRobustScaler (salary column):\")\n",
        "print(df_robust['salary'].values)\n",
        "print(f\"Outlier: {df_robust['salary'].iloc[10]:.2f}\")\n",
        "print(f\"Other values preserve their relative differences\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "power-transformer",
      "metadata": {},
      "source": [
        "## 4. PowerTransformer\n",
        "\n",
        "**Definition**: Applies power transformation to make data more Gaussian (normal)\n",
        "\n",
        "**Two Methods**:\n",
        "1. **Box-Cox**: Only for positive data, estimates best power\n",
        "2. **Yeo-Johnson**: Works with positive and negative data\n",
        "\n",
        "**When to Use**:\n",
        "- Data is highly skewed\n",
        "- Need to reduce skewness for algorithms that assume normality\n",
        "- Improve model performance\n",
        "\n",
        "**Effect**: Makes skewed distribution more bell-shaped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "power-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create skewed data\n",
        "np.random.seed(42)\n",
        "skewed_data = np.random.exponential(scale=2.0, size=1000).reshape(-1, 1)\n",
        "\n",
        "print(\"Original Skewed Data Statistics:\")\n",
        "print(f\"Mean: {skewed_data.mean():.2f}\")\n",
        "print(f\"Median: {np.median(skewed_data):.2f}\")\n",
        "print(f\"Skewness: {pd.Series(skewed_data.flatten()).skew():.2f}\")\n",
        "\n",
        "# Apply PowerTransformer (Yeo-Johnson)\n",
        "power_transformer = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "transformed_data = power_transformer.fit_transform(skewed_data)\n",
        "\n",
        "print(\"\\nTransformed Data Statistics:\")\n",
        "print(f\"Mean: {transformed_data.mean():.2f}\")\n",
        "print(f\"Median: {np.median(transformed_data):.2f}\")\n",
        "print(f\"Skewness: {pd.Series(transformed_data.flatten()).skew():.2f}\")\n",
        "print(\"\\nNotice: Skewness closer to 0 (more symmetric)\")\n",
        "\n",
        "# Visualize transformation\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axes[0].hist(skewed_data, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_title('Original Skewed Data')\n",
        "axes[0].set_xlabel('Value')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "axes[1].hist(transformed_data, bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
        "axes[1].set_title('After PowerTransformer')\n",
        "axes[1].set_xlabel('Value')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "normalizer",
      "metadata": {},
      "source": [
        "## 5. Normalizer\n",
        "\n",
        "**Definition**: Scales each sample (row) to have unit norm\n",
        "\n",
        "**Formula**: \\\\( x_{norm} = \\frac{x}{||x||_p} \\\\)\n",
        "- L1 norm: \\\\( ||x||_1 = |x_1| + |x_2| + ... \\\\)\n",
        "- L2 norm: \\\\( ||x||_2 = \\sqrt{x_1^2 + x_2^2 + ...} \\\\)\n",
        "\n",
        "**When to Use**:\n",
        "- Text classification (TF-IDF vectors)\n",
        "- Comparing similarity between samples\n",
        "- Neural networks with sparse data\n",
        "\n",
        "**Key Difference**: Normalizes ROWS, not COLUMNS (unlike other scalers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "normalizer-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample data (3 samples, 4 features)\n",
        "X = np.array([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(X)\n",
        "\n",
        "# L2 Normalizer (default)\n",
        "normalizer_l2 = Normalizer(norm='l2')\n",
        "X_l2 = normalizer_l2.fit_transform(X)\n",
        "\n",
        "print(\"\\nL2 Normalized:\")\n",
        "print(X_l2.round(3))\n",
        "print(\"\\nVerify: Each row has L2 norm = 1\")\n",
        "print(\"Row norms:\", np.linalg.norm(X_l2, axis=1))\n",
        "\n",
        "# L1 Normalizer\n",
        "normalizer_l1 = Normalizer(norm='l1')\n",
        "X_l1 = normalizer_l1.fit_transform(X)\n",
        "\n",
        "print(\"\\nL1 Normalized:\")\n",
        "print(X_l1.round(3))\n",
        "print(\"\\nVerify: Each row sums to 1\")\n",
        "print(\"Row sums:\", X_l1.sum(axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "comparison",
      "metadata": {},
      "source": [
        "## Real-World Example: Wine Dataset\n",
        "\n",
        "Compare scaler effects on actual ML dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wine-example",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load wine dataset\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "print(\"Wine Dataset:\")\n",
        "print(f\"Samples: {X.shape[0]}, Features: {X.shape[1]}\")\n",
        "print(f\"\\nFeature ranges (unscaled):\")\n",
        "for i, name in enumerate(wine.feature_names[:5]):\n",
        "    print(f\"{name:30s}: [{X[:, i].min():.2f}, {X[:, i].max():.2f}]\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Test different scalers with SVM\n",
        "scalers = {\n",
        "    'No Scaling': None,\n",
        "    'StandardScaler': StandardScaler(),\n",
        "    'MinMaxScaler': MinMaxScaler(),\n",
        "    'RobustScaler': RobustScaler(),\n",
        "    'PowerTransformer': PowerTransformer()\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SVM Performance with Different Scalers\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, scaler in scalers.items():\n",
        "    if scaler is None:\n",
        "        X_train_scaled = X_train\n",
        "        X_test_scaled = X_test\n",
        "    else:\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Train SVM\n",
        "    svm = SVC(random_state=42)\n",
        "    svm.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Evaluate\n",
        "    train_acc = svm.score(X_train_scaled, y_train)\n",
        "    test_acc = svm.score(X_test_scaled, y_test)\n",
        "    \n",
        "    print(f\"\\n{name:20s}: Train={train_acc:.4f}, Test={test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "important-notes",
      "metadata": {},
      "source": [
        "## Important Concepts\n",
        "\n",
        "### 1. Fit vs Transform vs Fit_Transform\n",
        "\n",
        "```python\n",
        "# TRAINING DATA\n",
        "scaler.fit(X_train)              # Learn parameters (mean, std, min, max)\n",
        "X_train_scaled = scaler.transform(X_train)  # Apply scaling\n",
        "# OR in one step:\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# TEST DATA (IMPORTANT!)\n",
        "X_test_scaled = scaler.transform(X_test)    # Use SAME parameters from training\n",
        "# NEVER: scaler.fit_transform(X_test)  # This would cause data leakage!\n",
        "```\n",
        "\n",
        "### 2. Data Leakage Prevention\n",
        "\n",
        "**\u274c Wrong**:\n",
        "```python\n",
        "X_scaled = scaler.fit_transform(X)  # Scales all data together\n",
        "X_train, X_test = train_test_split(X_scaled)\n",
        "```\n",
        "Problem: Test data influences scaling parameters!\n",
        "\n",
        "**\u2713 Correct**:\n",
        "```python\n",
        "X_train, X_test = train_test_split(X)  # Split first\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # Fit on train only\n",
        "X_test_scaled = scaler.transform(X_test)        # Apply to test\n",
        "```\n",
        "\n",
        "### 3. Inverse Transform\n",
        "\n",
        "Get back original values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inverse-transform",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original data\n",
        "original = np.array([[25, 50000], [30, 60000]])\n",
        "print(\"Original:\")\n",
        "print(original)\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(original)\n",
        "print(\"\\nScaled:\")\n",
        "print(scaled)\n",
        "\n",
        "# Inverse transform\n",
        "back_to_original = scaler.inverse_transform(scaled)\n",
        "print(\"\\nInverse Transform:\")\n",
        "print(back_to_original)\n",
        "print(\"\\nAre they equal?\", np.allclose(original, back_to_original))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {},
      "source": [
        "## Quick Decision Guide\n",
        "\n",
        "```\n",
        "START\n",
        "  |\n",
        "  \u251c\u2500 Tree-based model? \u2192 NO SCALING NEEDED\n",
        "  |\n",
        "  \u251c\u2500 Has outliers?\n",
        "  \u2502   \u2514\u2500 Yes \u2192 RobustScaler\n",
        "  \u2502   \u2514\u2500 No \u2192 Continue\n",
        "  |\n",
        "  \u251c\u2500 Need specific range?\n",
        "  \u2502   \u2514\u2500 Yes \u2192 MinMaxScaler\n",
        "  \u2502   \u2514\u2500 No \u2192 Continue\n",
        "  |\n",
        "  \u251c\u2500 Data very skewed?\n",
        "  \u2502   \u2514\u2500 Yes \u2192 PowerTransformer\n",
        "  \u2502   \u2514\u2500 No \u2192 Continue\n",
        "  |\n",
        "  \u251c\u2500 Text/sparse data?\n",
        "  \u2502   \u2514\u2500 Yes \u2192 Normalizer\n",
        "  \u2502   \u2514\u2500 No \u2192 StandardScaler (default choice)\n",
        "```\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **Always scale** for distance-based algorithms (KNN, SVM, Neural Networks)\n",
        "2. **StandardScaler** is the default choice for most cases\n",
        "3. **RobustScaler** when you have outliers\n",
        "4. **MinMaxScaler** when you need bounded range\n",
        "5. **PowerTransformer** to reduce skewness\n",
        "6. **Fit on training data only** to prevent data leakage\n",
        "7. **Use pipelines** to ensure correct order of operations"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}