{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# Encoding Categorical Variables\n",
        "\n",
        "## The Problem\n",
        "\n",
        "Machine learning algorithms work with **numbers**, not text. We need to convert categorical data into numerical format.\n",
        "\n",
        "**Example**:\n",
        "```\n",
        "Color: ['Red', 'Blue', 'Green'] \u2192 ?\n",
        "```\n",
        "\n",
        "## Types of Categorical Data\n",
        "\n",
        "| Type | Definition | Examples |\n",
        "|------|------------|----------|\n",
        "| **Nominal** | No order/ranking | Colors, Countries, Gender |\n",
        "| **Ordinal** | Has meaningful order | Education (High School < Bachelor < Master), Ratings (Poor < Good < Excellent) |\n",
        "\n",
        "## Encoding Methods\n",
        "\n",
        "| Encoder | Use For | Output | When to Use |\n",
        "|---------|---------|--------|-------------|\n",
        "| **LabelEncoder** | Target variable (y) | Single column: [0, 1, 2, ...] | Classification labels only |\n",
        "| **OrdinalEncoder** | Ordinal features (X) | Ordered integers | When categories have meaningful order |\n",
        "| **OneHotEncoder** | Nominal features (X) | Multiple binary columns | Most common for features with no order |\n",
        "| **get_dummies** | Quick encoding | Multiple binary columns | Pandas convenience (not for production) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sample-data",
      "metadata": {},
      "source": [
        "## Sample Dataset: Customer Data\n",
        "\n",
        "Let's create a realistic dataset with different types of categorical variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "create-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create customer dataset\n",
        "data = {\n",
        "    'customer_id': range(1, 11),\n",
        "    'city': ['Mumbai', 'Delhi', 'Mumbai', 'Bangalore', 'Delhi', \n",
        "             'Chennai', 'Mumbai', 'Bangalore', 'Chennai', 'Delhi'],\n",
        "    'education': ['High School', 'Bachelor', 'Master', 'Bachelor', 'PhD',\n",
        "                  'High School', 'Master', 'Bachelor', 'PhD', 'Master'],\n",
        "    'product': ['Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone',\n",
        "                'Tablet', 'Laptop', 'Phone', 'Tablet', 'Laptop'],\n",
        "    'satisfaction': ['Good', 'Excellent', 'Poor', 'Good', 'Excellent',\n",
        "                     'Good', 'Excellent', 'Poor', 'Good', 'Excellent'],\n",
        "    'purchased': [1, 1, 0, 1, 1, 0, 1, 0, 1, 1]  # Target variable\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original Dataset:\")\n",
        "print(df)\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nCategorical Columns:\")\n",
        "print(df.select_dtypes(include='object').columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "label-encoder",
      "metadata": {},
      "source": [
        "## 1. LabelEncoder\n",
        "\n",
        "**Definition**: Converts each unique category to an integer (0, 1, 2, ...)\n",
        "\n",
        "**Use Case**: Encoding **target variable (y)** only\n",
        "\n",
        "**Warning**: \u26a0\ufe0f Don't use for features! Creates false ordering.\n",
        "\n",
        "**Example**:\n",
        "```\n",
        "['Red', 'Blue', 'Green', 'Red'] \u2192 [2, 0, 1, 2]\n",
        "```\n",
        "\n",
        "**Why not for features?**\n",
        "- Algorithm might think Blue(0) < Green(1) < Red(2)\n",
        "- No such relationship exists for colors!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "label-encoder-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LabelEncoder for target variable\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Example: Encode satisfaction levels\n",
        "satisfaction = df['satisfaction'].values\n",
        "print(\"Original:\", satisfaction)\n",
        "\n",
        "# Fit and transform\n",
        "satisfaction_encoded = le.fit_transform(satisfaction)\n",
        "print(\"Encoded: \", satisfaction_encoded)\n",
        "\n",
        "# See the mapping\n",
        "print(\"\\nMapping:\")\n",
        "for i, label in enumerate(le.classes_):\n",
        "    print(f\"  {label:12s} \u2192 {i}\")\n",
        "\n",
        "# Inverse transform (get back original)\n",
        "original_back = le.inverse_transform(satisfaction_encoded)\n",
        "print(\"\\nInverse transform:\", original_back)\n",
        "\n",
        "# \u26a0\ufe0f Problem with LabelEncoder for features\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"WHY NOT USE FOR FEATURES?\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "cities = ['Mumbai', 'Delhi', 'Bangalore', 'Chennai']\n",
        "le_city = LabelEncoder()\n",
        "encoded_cities = le_city.fit_transform(cities)\n",
        "\n",
        "print(\"\\nCities encoded with LabelEncoder:\")\n",
        "for city, code in zip(cities, encoded_cities):\n",
        "    print(f\"  {city:12s} \u2192 {code}\")\n",
        "\n",
        "print(\"\\n\u26a0\ufe0f Problem: Algorithm thinks Bangalore(0) < Chennai(1) < Delhi(2) < Mumbai(3)\")\n",
        "print(\"   But cities have NO inherent order!\")\n",
        "print(\"   Solution: Use OneHotEncoder for nominal features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ordinal-encoder",
      "metadata": {},
      "source": [
        "## 2. OrdinalEncoder\n",
        "\n",
        "**Definition**: Encodes categorical features with meaningful order\n",
        "\n",
        "**Use Case**: Features with **natural ordering** (ordinal data)\n",
        "\n",
        "**Examples**:\n",
        "- Education: High School < Bachelor < Master < PhD\n",
        "- Temperature: Cold < Warm < Hot\n",
        "- Rating: Poor < Fair < Good < Excellent\n",
        "\n",
        "**Advantage**: Preserves order information for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ordinal-encoder-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define custom order for education\n",
        "education_order = ['High School', 'Bachelor', 'Master', 'PhD']\n",
        "\n",
        "# OrdinalEncoder with custom order\n",
        "oe = OrdinalEncoder(categories=[education_order])\n",
        "\n",
        "# Reshape for sklearn (needs 2D array)\n",
        "education_data = df[['education']]\n",
        "print(\"Original Education:\")\n",
        "print(education_data.values.flatten())\n",
        "\n",
        "# Fit and transform\n",
        "education_encoded = oe.fit_transform(education_data)\n",
        "print(\"\\nEncoded (with order):\")\n",
        "print(education_encoded.flatten())\n",
        "\n",
        "print(\"\\nMapping (preserves order):\")\n",
        "for i, level in enumerate(education_order):\n",
        "    print(f\"  {i} \u2190 {level}\")\n",
        "\n",
        "# Multiple ordinal columns\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MULTIPLE ORDINAL COLUMNS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "satisfaction_order = ['Poor', 'Good', 'Excellent']\n",
        "\n",
        "# Create ordinal encoder for multiple columns\n",
        "oe_multi = OrdinalEncoder(categories=[education_order, satisfaction_order])\n",
        "\n",
        "# Encode both columns\n",
        "ordinal_features = df[['education', 'satisfaction']]\n",
        "ordinal_encoded = oe_multi.fit_transform(ordinal_features)\n",
        "\n",
        "result_df = pd.DataFrame(\n",
        "    ordinal_encoded,\n",
        "    columns=['education_encoded', 'satisfaction_encoded']\n",
        ")\n",
        "result_df = pd.concat([ordinal_features.reset_index(drop=True), result_df], axis=1)\n",
        "\n",
        "print(\"\\nOriginal vs Encoded:\")\n",
        "print(result_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "onehot-encoder",
      "metadata": {},
      "source": [
        "## 3. OneHotEncoder\n",
        "\n",
        "**Definition**: Creates binary column for each category\n",
        "\n",
        "**Use Case**: Nominal features with **no order**\n",
        "\n",
        "**Example**:\n",
        "```\n",
        "Color: ['Red', 'Blue', 'Green']\n",
        "\n",
        "Becomes:\n",
        "  Red  Blue  Green\n",
        "   1     0      0     (Red)\n",
        "   0     1      0     (Blue)\n",
        "   0     0      1     (Green)\n",
        "```\n",
        "\n",
        "**Advantages**:\n",
        "- No false ordering\n",
        "- Each category is independent\n",
        "\n",
        "**Disadvantage**: High cardinality (many categories) creates many columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "onehot-basic",
      "metadata": {},
      "outputs": [],
      "source": [
        "# OneHotEncoder for city (nominal feature)\n",
        "ohe = OneHotEncoder(sparse_output=False)  # sparse_output=False for readable output\n",
        "\n",
        "city_data = df[['city']]\n",
        "print(\"Original Cities:\")\n",
        "print(city_data.values.flatten())\n",
        "\n",
        "# Fit and transform\n",
        "city_encoded = ohe.fit_transform(city_data)\n",
        "print(\"\\nOne-Hot Encoded Shape:\", city_encoded.shape)\n",
        "print(\"\\nEncoded Matrix:\")\n",
        "print(city_encoded)\n",
        "\n",
        "# Get feature names\n",
        "feature_names = ohe.get_feature_names_out(['city'])\n",
        "print(\"\\nColumn Names:\", feature_names)\n",
        "\n",
        "# Create readable dataframe\n",
        "city_encoded_df = pd.DataFrame(city_encoded, columns=feature_names)\n",
        "city_encoded_df.insert(0, 'original_city', city_data.values)\n",
        "\n",
        "print(\"\\nReadable Format:\")\n",
        "print(city_encoded_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "onehot-multiple",
      "metadata": {},
      "outputs": [],
      "source": [
        "# OneHotEncoder for multiple columns\n",
        "print(\"=\"*60)\n",
        "print(\"ONE-HOT ENCODING MULTIPLE COLUMNS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Select nominal features\n",
        "nominal_features = df[['city', 'product']]\n",
        "print(\"\\nOriginal Data:\")\n",
        "print(nominal_features)\n",
        "\n",
        "# Encode\n",
        "ohe_multi = OneHotEncoder(sparse_output=False)\n",
        "encoded = ohe_multi.fit_transform(nominal_features)\n",
        "\n",
        "# Get column names\n",
        "column_names = ohe_multi.get_feature_names_out(['city', 'product'])\n",
        "print(\"\\nGenerated Columns:\", column_names)\n",
        "\n",
        "# Create dataframe\n",
        "encoded_df = pd.DataFrame(encoded, columns=column_names)\n",
        "print(\"\\nEncoded Result:\")\n",
        "print(encoded_df.head())\n",
        "print(f\"\\nShape: {nominal_features.shape} \u2192 {encoded_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "drop-first",
      "metadata": {},
      "source": [
        "## Important: drop='first' to Avoid Dummy Variable Trap\n",
        "\n",
        "**Problem**: OneHotEncoding creates multicollinearity\n",
        "\n",
        "**Example**: For 3 colors, we create 3 columns\n",
        "```\n",
        "Red  Blue  Green\n",
        " 1    0     0      If Red=0 AND Blue=0, we KNOW Green=1\n",
        " 0    1     0      One column is redundant!\n",
        " 0    0     1\n",
        "```\n",
        "\n",
        "**Solution**: Drop first column (or any one column)\n",
        "\n",
        "**When to use**:\n",
        "- Linear models (Linear/Logistic Regression)\n",
        "- Tree-based models: not necessary but saves memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "drop-first-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Without drop='first'\n",
        "ohe_full = OneHotEncoder(sparse_output=False)\n",
        "city_full = ohe_full.fit_transform(df[['city']])\n",
        "\n",
        "print(\"Without drop='first':\")\n",
        "print(f\"Columns: {ohe_full.get_feature_names_out()}\")\n",
        "print(f\"Shape: {city_full.shape}\")\n",
        "print(city_full[:3])\n",
        "\n",
        "# With drop='first' (recommended for linear models)\n",
        "ohe_drop = OneHotEncoder(sparse_output=False, drop='first')\n",
        "city_drop = ohe_drop.fit_transform(df[['city']])\n",
        "\n",
        "print(\"\\nWith drop='first':\")\n",
        "print(f\"Columns: {ohe_drop.get_feature_names_out()}\")\n",
        "print(f\"Shape: {city_drop.shape}\")\n",
        "print(city_drop[:3])\n",
        "print(\"\\n\u2713 First category (Bangalore) dropped\")\n",
        "print(\"  If all columns are 0 \u2192 Bangalore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "handle-unknown",
      "metadata": {},
      "source": [
        "## Handling Unknown Categories\n",
        "\n",
        "**Problem**: What if test data has categories not seen in training?\n",
        "\n",
        "**Solution**: Use `handle_unknown='ignore'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unknown-categories",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training data\n",
        "train_cities = np.array([['Mumbai'], ['Delhi'], ['Bangalore']])\n",
        "\n",
        "# Fit encoder\n",
        "ohe_unknown = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "ohe_unknown.fit(train_cities)\n",
        "\n",
        "print(\"Trained on:\", train_cities.flatten())\n",
        "print(\"Categories learned:\", ohe_unknown.categories_)\n",
        "\n",
        "# Test data with unknown category\n",
        "test_cities = np.array([['Mumbai'], ['Kolkata'], ['Delhi']])  # Kolkata is new!\n",
        "\n",
        "print(\"\\nTest data:\", test_cities.flatten())\n",
        "\n",
        "# Transform (without error)\n",
        "test_encoded = ohe_unknown.transform(test_cities)\n",
        "print(\"\\nEncoded:\")\n",
        "print(test_encoded)\n",
        "print(\"\\n'Kolkata' (unknown) \u2192 all zeros\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pandas-dummies",
      "metadata": {},
      "source": [
        "## Pandas get_dummies() - Quick Alternative\n",
        "\n",
        "**Use Case**: Quick exploratory data analysis\n",
        "\n",
        "**Limitations**:\n",
        "- Not compatible with sklearn pipelines\n",
        "- Can't handle unknown categories in test data\n",
        "- Not recommended for production\n",
        "\n",
        "**When to use**: Prototyping, notebooks, quick experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pandas-dummies-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original data\n",
        "print(\"Original DataFrame:\")\n",
        "print(df[['city', 'product', 'satisfaction']].head())\n",
        "\n",
        "# get_dummies - all categorical columns\n",
        "df_dummies = pd.get_dummies(df[['city', 'product', 'satisfaction']])\n",
        "print(\"\\nAfter get_dummies():\")\n",
        "print(df_dummies.head())\n",
        "print(f\"\\nShape: 3 columns \u2192 {df_dummies.shape[1]} columns\")\n",
        "\n",
        "# With drop_first\n",
        "df_dummies_drop = pd.get_dummies(\n",
        "    df[['city', 'product', 'satisfaction']], \n",
        "    drop_first=True\n",
        ")\n",
        "print(\"\\nWith drop_first=True:\")\n",
        "print(f\"Shape: {df_dummies_drop.shape[1]} columns\")\n",
        "print(df_dummies_drop.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "real-world-example",
      "metadata": {},
      "source": [
        "## Real-World Example: Predicting Purchases\n",
        "\n",
        "Complete pipeline with proper encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ml-example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create larger dataset\n",
        "np.random.seed(42)\n",
        "n_samples = 200\n",
        "\n",
        "cities = np.random.choice(['Mumbai', 'Delhi', 'Bangalore', 'Chennai'], n_samples)\n",
        "education = np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples)\n",
        "product = np.random.choice(['Laptop', 'Phone', 'Tablet'], n_samples)\n",
        "age = np.random.randint(20, 60, n_samples)\n",
        "salary = np.random.randint(30000, 150000, n_samples)\n",
        "\n",
        "# Target: purchased (influenced by salary and education)\n",
        "purchased = ((salary > 80000) & (education != 'High School')).astype(int)\n",
        "purchased = np.random.permutation(purchased)  # Add randomness\n",
        "\n",
        "data_large = pd.DataFrame({\n",
        "    'city': cities,\n",
        "    'education': education,\n",
        "    'product': product,\n",
        "    'age': age,\n",
        "    'salary': salary,\n",
        "    'purchased': purchased\n",
        "})\n",
        "\n",
        "print(\"Dataset:\")\n",
        "print(data_large.head(10))\n",
        "print(f\"\\nShape: {data_large.shape}\")\n",
        "print(f\"Purchase rate: {data_large['purchased'].mean():.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ml-pipeline",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = data_large.drop('purchased', axis=1)\n",
        "y = data_large['purchased']\n",
        "\n",
        "# Split data FIRST\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Training set:\", X_train.shape)\n",
        "print(\"Test set:    \", X_test.shape)\n",
        "\n",
        "# Identify column types\n",
        "nominal_cols = ['city', 'product']\n",
        "ordinal_cols = ['education']\n",
        "numeric_cols = ['age', 'salary']\n",
        "\n",
        "print(\"\\nColumn Types:\")\n",
        "print(f\"  Nominal: {nominal_cols}\")\n",
        "print(f\"  Ordinal: {ordinal_cols}\")\n",
        "print(f\"  Numeric: {numeric_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "encode-features",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode nominal features (city, product)\n",
        "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "X_train_nominal = ohe.fit_transform(X_train[nominal_cols])\n",
        "X_test_nominal = ohe.transform(X_test[nominal_cols])\n",
        "\n",
        "nominal_feature_names = ohe.get_feature_names_out(nominal_cols)\n",
        "print(\"Nominal features encoded:\")\n",
        "print(f\"  Original: {nominal_cols}\")\n",
        "print(f\"  Encoded:  {nominal_feature_names}\")\n",
        "print(f\"  Shape: {X_train[nominal_cols].shape} \u2192 {X_train_nominal.shape}\")\n",
        "\n",
        "# Encode ordinal features (education)\n",
        "education_order = ['High School', 'Bachelor', 'Master', 'PhD']\n",
        "oe = OrdinalEncoder(categories=[education_order])\n",
        "X_train_ordinal = oe.fit_transform(X_train[ordinal_cols])\n",
        "X_test_ordinal = oe.transform(X_test[ordinal_cols])\n",
        "\n",
        "print(\"\\nOrdinal features encoded:\")\n",
        "print(f\"  {ordinal_cols} with order: {education_order}\")\n",
        "\n",
        "# Get numeric features\n",
        "X_train_numeric = X_train[numeric_cols].values\n",
        "X_test_numeric = X_test[numeric_cols].values\n",
        "\n",
        "# Combine all features\n",
        "X_train_processed = np.hstack([\n",
        "    X_train_nominal,\n",
        "    X_train_ordinal,\n",
        "    X_train_numeric\n",
        "])\n",
        "\n",
        "X_test_processed = np.hstack([\n",
        "    X_test_nominal,\n",
        "    X_test_ordinal,\n",
        "    X_test_numeric\n",
        "])\n",
        "\n",
        "print(\"\\nFinal processed features:\")\n",
        "print(f\"  Training: {X_train_processed.shape}\")\n",
        "print(f\"  Test:     {X_test_processed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train-model",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_processed, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = rf.predict(X_train_processed)\n",
        "y_pred_test = rf.predict(X_test_processed)\n",
        "\n",
        "# Evaluate\n",
        "train_acc = accuracy_score(y_train, y_pred_train)\n",
        "test_acc = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL PERFORMANCE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Test Accuracy:     {test_acc:.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "all_feature_names = list(nominal_feature_names) + ordinal_cols + numeric_cols\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': all_feature_names,\n",
        "    'importance': rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Important Features:\")\n",
        "print(feature_importance.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "comparison",
      "metadata": {},
      "source": [
        "## Comparison: When to Use Each Encoder\n",
        "\n",
        "| Scenario | Encoder | Reason |\n",
        "|----------|---------|--------|\n",
        "| Target variable for classification | **LabelEncoder** | Converts classes to 0, 1, 2, ... |\n",
        "| Education level (High School \u2192 PhD) | **OrdinalEncoder** | Preserves natural order |\n",
        "| City/Country names | **OneHotEncoder** | No inherent order |\n",
        "| Product categories | **OneHotEncoder** | Independent categories |\n",
        "| Temperature (Cold/Warm/Hot) | **OrdinalEncoder** | Has meaningful order |\n",
        "| Size (S/M/L/XL) | **OrdinalEncoder** | Has size order |\n",
        "| Color (Red/Blue/Green) | **OneHotEncoder** | No natural order |\n",
        "| Rating (1-5 stars) | **OrdinalEncoder** | Ordered scale |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "high-cardinality",
      "metadata": {},
      "source": [
        "## Handling High Cardinality Features\n",
        "\n",
        "**Problem**: Feature with 100+ categories \u2192 100+ columns after OneHotEncoding\n",
        "\n",
        "**Solutions**:\n",
        "\n",
        "1. **Frequency Encoding**: Replace category with its frequency\n",
        "2. **Target Encoding**: Replace with mean of target for that category\n",
        "3. **Grouping**: Combine rare categories into 'Other'\n",
        "4. **Hashing**: Use FeatureHasher (covered in text features notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "high-cardinality-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: High cardinality feature\n",
        "cities_many = ['City_' + str(i) for i in range(50)]  # 50 cities\n",
        "city_sample = np.random.choice(cities_many, 100)\n",
        "\n",
        "print(f\"Number of unique cities: {len(np.unique(city_sample))}\")\n",
        "print(\"OneHotEncoding would create 50 columns!\\n\")\n",
        "\n",
        "# Solution 1: Frequency Encoding\n",
        "city_counts = pd.Series(city_sample).value_counts()\n",
        "city_freq_encoded = pd.Series(city_sample).map(city_counts)\n",
        "\n",
        "print(\"Frequency Encoding:\")\n",
        "print(f\"Original: {city_sample[:5]}\")\n",
        "print(f\"Encoded:  {city_freq_encoded[:5].values}\")\n",
        "print(\"Each city \u2192 its frequency count\")\n",
        "\n",
        "# Solution 2: Group rare categories\n",
        "top_10_cities = city_counts.head(10).index\n",
        "city_grouped = pd.Series(city_sample).apply(\n",
        "    lambda x: x if x in top_10_cities else 'Other'\n",
        ")\n",
        "\n",
        "print(f\"\\nGrouping: 50 categories \u2192 {len(city_grouped.unique())} categories\")\n",
        "print(f\"Top 10 cities kept, rest grouped as 'Other'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {},
      "source": [
        "## Decision Flow Chart\n",
        "\n",
        "```\n",
        "START: Have categorical variable\n",
        "  |\n",
        "  \u251c\u2500 Is it TARGET variable (y)?\n",
        "  \u2502   \u2514\u2500 YES \u2192 LabelEncoder\n",
        "  |\n",
        "  \u251c\u2500 Is it FEATURE (X)?\n",
        "  \u2502   |\n",
        "  \u2502   \u251c\u2500 Has natural ORDER?\n",
        "  \u2502   \u2502   \u2514\u2500 YES \u2192 OrdinalEncoder\n",
        "  \u2502   \u2502       (e.g., education, rating, temperature)\n",
        "  \u2502   |\n",
        "  \u2502   \u2514\u2500 NO ORDER (nominal)?\n",
        "  \u2502       \u2514\u2500 YES \u2192 OneHotEncoder\n",
        "  \u2502           (e.g., city, color, product)\n",
        "  \u2502       |\n",
        "  \u2502       \u251c\u2500 High cardinality (>50 categories)?\n",
        "  \u2502       \u2502   \u2514\u2500 Consider: Frequency/Target encoding or grouping\n",
        "  \u2502       |\n",
        "  \u2502       \u2514\u2500 Use drop='first' for linear models\n",
        "```\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **LabelEncoder**: Only for target variable (y)\n",
        "2. **OrdinalEncoder**: For features with meaningful order\n",
        "3. **OneHotEncoder**: For features without order (most common)\n",
        "4. **Always fit on training data**, transform on test\n",
        "5. **Use `drop='first'`** for linear models to avoid dummy variable trap\n",
        "6. **Use `handle_unknown='ignore'`** to handle new categories in test set\n",
        "7. **High cardinality**: Consider alternatives to OneHotEncoding\n",
        "8. **Pandas get_dummies**: Quick but not for production\n",
        "\n",
        "## Common Mistakes to Avoid\n",
        "\n",
        "\u274c Using LabelEncoder for features (creates false ordering)  \n",
        "\u274c Fitting encoder on test data  \n",
        "\u274c Encoding before train-test split  \n",
        "\u274c Not handling unknown categories  \n",
        "\u274c Forgetting to combine encoded features with numeric ones  \n",
        "\n",
        "\u2705 OneHotEncode nominal features  \n",
        "\u2705 Ordinal encode ordered features  \n",
        "\u2705 Fit on train, transform on test  \n",
        "\u2705 Use pipelines for proper workflow  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}