{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Regularization: Ridge, Lasso, and ElasticNet\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Regularization** adds a penalty term to the loss function to prevent overfitting and improve model generalization. It's particularly useful when:\n",
    "- You have many features (high-dimensional data)\n",
    "- Features are correlated (multicollinearity)\n",
    "- Training data is limited\n",
    "\n",
    "## Mathematical Foundation\n",
    "\n",
    "### Ordinary Least Squares (OLS)\n",
    "\\[\n",
    "\\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i\\beta)^2\n",
    "\\]\n",
    "\n",
    "### Ridge Regression (L2 Regularization)\n",
    "\\[\n",
    "\\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i\\beta)^2 + \\alpha \\sum_{j=1}^{p} \\beta_j^2\n",
    "\\]\n",
    "- **Penalty**: L2 norm (sum of squared coefficients)\n",
    "- **Effect**: Shrinks coefficients toward zero\n",
    "- **Result**: All features retained, but with smaller weights\n",
    "\n",
    "### Lasso Regression (L1 Regularization)\n",
    "\\[\n",
    "\\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i\\beta)^2 + \\alpha \\sum_{j=1}^{p} |\\beta_j|\n",
    "\\]\n",
    "- **Penalty**: L1 norm (sum of absolute coefficients)\n",
    "- **Effect**: Can shrink coefficients to exactly zero\n",
    "- **Result**: Feature selection (sparse model)\n",
    "\n",
    "### ElasticNet (L1 + L2)\n",
    "\\[\n",
    "\\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i\\beta)^2 + \\alpha \\rho \\sum_{j=1}^{p} |\\beta_j| + \\frac{\\alpha(1-\\rho)}{2} \\sum_{j=1}^{p} \\beta_j^2\n",
    "\\]\n",
    "- **Combines**: L1 and L2 penalties\n",
    "- **Parameter** \\(\\rho\\): Controls L1/L2 ratio (l1_ratio in sklearn)\n",
    "- **Result**: Feature selection + coefficient shrinkage\n",
    "\n",
    "## Topics Covered\n",
    "\n",
    "1. Ridge Regression (L2)\n",
    "2. Lasso Regression (L1)\n",
    "3. ElasticNet (L1 + L2)\n",
    "4. Coefficient paths\n",
    "5. Hyperparameter tuning (\\(\\alpha\\))\n",
    "6. Feature selection with Lasso\n",
    "7. Comparison and when to use each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.datasets import make_regression, load_diabetes, fetch_california_housing\n",
    "\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "problem-demo",
   "metadata": {},
   "source": [
    "## 1. The Problem: Overfitting and Multicollinearity\n",
    "\n",
    "### 1.1 Demonstrating the Need for Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "problem-setup",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'n_redundant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate data with many features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_regression(\n\u001b[1;32m      3\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      4\u001b[0m     n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m      5\u001b[0m     n_informative\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      6\u001b[0m     n_redundant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      7\u001b[0m     noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      8\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh-Dimensional Dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:194\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m params \u001b[38;5;241m=\u001b[39m func_sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    195\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/inspect.py:3304\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3300\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3302\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3303\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bind(args, kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/inspect.py:3293\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3284\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot some positional-only arguments passed as \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3285\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeyword arguments: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3290\u001b[0m             ),\n\u001b[1;32m   3291\u001b[0m         )\n\u001b[1;32m   3292\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3294\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   3295\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[1;32m   3297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[0;31mTypeError\u001b[0m: got an unexpected keyword argument 'n_redundant'"
     ]
    }
   ],
   "source": [
    "# Generate data with many features\n",
    "X, y = make_regression(\n",
    "    n_samples=100,\n",
    "    n_features=50,\n",
    "    n_informative=10,\n",
    "    n_redundant=20,\n",
    "    noise=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"High-Dimensional Dataset\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Samples: {X.shape[0]}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Ratio: {X.shape[1]/X.shape[0]:.2f} features per sample\")\n",
    "print(f\"\\n‚ö†Ô∏è More features than ideal relative to samples!\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTrain: {X_train.shape[0]} samples\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ols-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train regular linear regression (OLS)\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_ols = ols_model.predict(X_train_scaled)\n",
    "y_test_pred_ols = ols_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "train_r2_ols = r2_score(y_train, y_train_pred_ols)\n",
    "test_r2_ols = r2_score(y_test, y_test_pred_ols)\n",
    "train_mse_ols = mean_squared_error(y_train, y_train_pred_ols)\n",
    "test_mse_ols = mean_squared_error(y_test, y_test_pred_ols)\n",
    "\n",
    "print(\"Ordinary Least Squares (No Regularization)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTrain R¬≤: {train_r2_ols:.4f}\")\n",
    "print(f\"Test R¬≤:  {test_r2_ols:.4f}\")\n",
    "print(f\"\\nTrain MSE: {train_mse_ols:.2f}\")\n",
    "print(f\"Test MSE:  {test_mse_ols:.2f}\")\n",
    "print(f\"\\nCoefficient statistics:\")\n",
    "print(f\"  Mean: {np.mean(ols_model.coef_):.2f}\")\n",
    "print(f\"  Std: {np.std(ols_model.coef_):.2f}\")\n",
    "print(f\"  Max: {np.max(np.abs(ols_model.coef_)):.2f}\")\n",
    "\n",
    "if train_r2_ols - test_r2_ols > 0.1:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: Large gap between train and test R¬≤ ({train_r2_ols - test_r2_ols:.3f})\")\n",
    "    print(\"   ‚Üí Model may be overfitting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ridge",
   "metadata": {},
   "source": [
    "## 2. Ridge Regression (L2 Regularization)\n",
    "\n",
    "### 2.1 Basic Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ridge-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Ridge with different alpha values\n",
    "alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "ridge_results = []\n",
    "\n",
    "print(\"Ridge Regression with Different Alpha Values\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Train model\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = ridge.predict(X_train_scaled)\n",
    "    y_test_pred = ridge.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    ridge_results.append({\n",
    "        'Alpha': alpha,\n",
    "        'Train R¬≤': train_r2,\n",
    "        'Test R¬≤': test_r2,\n",
    "        'Coef Mean': np.mean(np.abs(ridge.coef_)),\n",
    "        'Coef Max': np.max(np.abs(ridge.coef_))\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nŒ± = {alpha:6.2f}: Train R¬≤ = {train_r2:.4f}, Test R¬≤ = {test_r2:.4f}\")\n",
    "\n",
    "ridge_df = pd.DataFrame(ridge_results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Summary:\")\n",
    "print(ridge_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ridge-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of alpha\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# R¬≤ scores\n",
    "axes[0].plot(ridge_df['Alpha'], ridge_df['Train R¬≤'], 'o-', label='Train R¬≤', linewidth=2)\n",
    "axes[0].plot(ridge_df['Alpha'], ridge_df['Test R¬≤'], 's-', label='Test R¬≤', linewidth=2)\n",
    "axes[0].axhline(y=test_r2_ols, color='r', linestyle='--', label='OLS Test R¬≤', alpha=0.5)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('Alpha (log scale)')\n",
    "axes[0].set_ylabel('R¬≤ Score')\n",
    "axes[0].set_title('Ridge: R¬≤ vs Alpha')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Coefficient magnitude\n",
    "axes[1].plot(ridge_df['Alpha'], ridge_df['Coef Mean'], 'o-', label='Mean |coef|', linewidth=2)\n",
    "axes[1].plot(ridge_df['Alpha'], ridge_df['Coef Max'], 's-', label='Max |coef|', linewidth=2)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_xlabel('Alpha (log scale)')\n",
    "axes[1].set_ylabel('Coefficient Magnitude')\n",
    "axes[1].set_title('Ridge: Coefficient Shrinkage')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(\"  - As Œ± increases, coefficients shrink toward zero\")\n",
    "print(\"  - Higher Œ± = more regularization = lower train R¬≤ but better test R¬≤\")\n",
    "print(\"  - Find optimal Œ± that balances bias-variance tradeoff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ridge-cv",
   "metadata": {},
   "source": [
    "### 2.2 Automatic Alpha Selection with RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9545be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RidgeCV to find best alpha automatically\n",
    "alphas_cv = np.logspace(-3, 3, 100)\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=alphas_cv, cv=5, scoring='r2')\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"RidgeCV: Automatic Alpha Selection\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBest alpha: {ridge_cv.alpha_:.4f}\")\n",
    "print(f\"Best CV score (R¬≤): {ridge_cv.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred_ridge = ridge_cv.predict(X_test_scaled)\n",
    "test_r2_ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "test_mse_ridge = mean_squared_error(y_test, y_test_pred_ridge)\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  R¬≤: {test_r2_ridge:.4f}\")\n",
    "print(f\"  MSE: {test_mse_ridge:.2f}\")\n",
    "\n",
    "print(f\"\\nComparison with OLS:\")\n",
    "print(f\"  OLS Test R¬≤: {test_r2_ols:.4f}\")\n",
    "print(f\"  Ridge Test R¬≤: {test_r2_ridge:.4f}\")\n",
    "print(f\"  Improvement: {test_r2_ridge - test_r2_ols:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasso",
   "metadata": {},
   "source": [
    "## 3. Lasso Regression (L1 Regularization)\n",
    "\n",
    "### 3.1 Basic Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasso-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Lasso with different alpha values\n",
    "alphas_lasso = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "lasso_results = []\n",
    "\n",
    "print(\"Lasso Regression with Different Alpha Values\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for alpha in alphas_lasso:\n",
    "    # Train model\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = lasso.predict(X_train_scaled)\n",
    "    y_test_pred = lasso.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Count non-zero coefficients\n",
    "    n_nonzero = np.sum(lasso.coef_ != 0)\n",
    "    \n",
    "    lasso_results.append({\n",
    "        'Alpha': alpha,\n",
    "        'Train R¬≤': train_r2,\n",
    "        'Test R¬≤': test_r2,\n",
    "        'Non-zero Coefs': n_nonzero,\n",
    "        'Zero Coefs': X.shape[1] - n_nonzero\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nŒ± = {alpha:6.3f}: Train R¬≤ = {train_r2:.4f}, Test R¬≤ = {test_r2:.4f}, \"\n",
    "          f\"Non-zero coefs = {n_nonzero}/{X.shape[1]}\")\n",
    "\n",
    "lasso_df = pd.DataFrame(lasso_results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Summary:\")\n",
    "print(lasso_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasso-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Lasso results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# R¬≤ scores\n",
    "axes[0].plot(lasso_df['Alpha'], lasso_df['Train R¬≤'], 'o-', label='Train R¬≤', linewidth=2)\n",
    "axes[0].plot(lasso_df['Alpha'], lasso_df['Test R¬≤'], 's-', label='Test R¬≤', linewidth=2)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('Alpha (log scale)')\n",
    "axes[0].set_ylabel('R¬≤ Score')\n",
    "axes[0].set_title('Lasso: R¬≤ vs Alpha')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Feature selection\n",
    "axes[1].plot(lasso_df['Alpha'], lasso_df['Non-zero Coefs'], 'o-', color='green', \n",
    "            linewidth=2, label='Non-zero coefficients')\n",
    "axes[1].plot(lasso_df['Alpha'], lasso_df['Zero Coefs'], 's-', color='red', \n",
    "            linewidth=2, label='Zero coefficients')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_xlabel('Alpha (log scale)')\n",
    "axes[1].set_ylabel('Number of Coefficients')\n",
    "axes[1].set_title('Lasso: Feature Selection')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Difference from Ridge:\")\n",
    "print(\"  - Lasso sets coefficients to EXACTLY zero\")\n",
    "print(\"  - Performs automatic feature selection\")\n",
    "print(\"  - Sparse solutions (fewer features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasso-cv",
   "metadata": {},
   "source": [
    "### 3.2 Automatic Alpha Selection with LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec933b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LassoCV to find best alpha\n",
    "lasso_cv = LassoCV(alphas=None, cv=5, max_iter=10000, random_state=42)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"LassoCV: Automatic Alpha Selection\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBest alpha: {lasso_cv.alpha_:.6f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred_lasso = lasso_cv.predict(X_test_scaled)\n",
    "test_r2_lasso = r2_score(y_test, y_test_pred_lasso)\n",
    "test_mse_lasso = mean_squared_error(y_test, y_test_pred_lasso)\n",
    "\n",
    "# Feature selection\n",
    "n_nonzero = np.sum(lasso_cv.coef_ != 0)\n",
    "selected_features = np.where(lasso_cv.coef_ != 0)[0]\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  R¬≤: {test_r2_lasso:.4f}\")\n",
    "print(f\"  MSE: {test_mse_lasso:.2f}\")\n",
    "\n",
    "print(f\"\\nFeature Selection:\")\n",
    "print(f\"  Total features: {X.shape[1]}\")\n",
    "print(f\"  Selected features: {n_nonzero}\")\n",
    "print(f\"  Eliminated features: {X.shape[1] - n_nonzero}\")\n",
    "print(f\"  Sparsity: {(1 - n_nonzero/X.shape[1])*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nSelected feature indices: {selected_features[:10]}...\" if len(selected_features) > 10 else f\"\\nSelected feature indices: {selected_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coefficient-paths",
   "metadata": {},
   "source": [
    "## 4. Coefficient Paths\n",
    "\n",
    "### 4.1 Ridge Coefficient Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ridge-path",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Ridge coefficients for many alphas\n",
    "alphas_path = np.logspace(-3, 3, 100)\n",
    "coefs_ridge = []\n",
    "\n",
    "for alpha in alphas_path:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    coefs_ridge.append(ridge.coef_)\n",
    "\n",
    "coefs_ridge = np.array(coefs_ridge)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(min(20, coefs_ridge.shape[1])):  # Plot first 20 features\n",
    "    plt.plot(alphas_path, coefs_ridge[:, i], alpha=0.7)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (log scale)', fontsize=12)\n",
    "plt.ylabel('Coefficient Value', fontsize=12)\n",
    "plt.title('Ridge Coefficient Path', fontsize=14)\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Ridge Coefficient Path:\")\n",
    "print(\"  - As Œ± increases, all coefficients shrink toward zero\")\n",
    "print(\"  - No coefficients reach exactly zero\")\n",
    "print(\"  - Smooth, continuous shrinkage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasso-path",
   "metadata": {},
   "source": [
    "### 4.2 Lasso Coefficient Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Lasso coefficients for many alphas\n",
    "alphas_path_lasso = np.logspace(-3, 1, 100)\n",
    "coefs_lasso = []\n",
    "\n",
    "for alpha in alphas_path_lasso:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    coefs_lasso.append(lasso.coef_)\n",
    "\n",
    "coefs_lasso = np.array(coefs_lasso)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(min(20, coefs_lasso.shape[1])):  # Plot first 20 features\n",
    "    plt.plot(alphas_path_lasso, coefs_lasso[:, i], alpha=0.7)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (log scale)', fontsize=12)\n",
    "plt.ylabel('Coefficient Value', fontsize=12)\n",
    "plt.title('Lasso Coefficient Path', fontsize=14)\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Lasso Coefficient Path:\")\n",
    "print(\"  - As Œ± increases, coefficients drop to zero\")\n",
    "print(\"  - Features eliminated at different Œ± values\")\n",
    "print(\"  - Piecewise linear paths (characteristic of L1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "side-by-side",
   "metadata": {},
   "source": [
    "### 4.3 Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Ridge and Lasso paths\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Ridge\n",
    "for i in range(min(15, coefs_ridge.shape[1])):\n",
    "    axes[0].plot(alphas_path, coefs_ridge[:, i], alpha=0.7)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('Alpha (log scale)', fontsize=12)\n",
    "axes[0].set_ylabel('Coefficient Value', fontsize=12)\n",
    "axes[0].set_title('Ridge: Continuous Shrinkage', fontsize=14)\n",
    "axes[0].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Lasso\n",
    "for i in range(min(15, coefs_lasso.shape[1])):\n",
    "    axes[1].plot(alphas_path_lasso, coefs_lasso[:, i], alpha=0.7)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_xlabel('Alpha (log scale)', fontsize=12)\n",
    "axes[1].set_ylabel('Coefficient Value', fontsize=12)\n",
    "axes[1].set_title('Lasso: Sparse Solutions', fontsize=14)\n",
    "axes[1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elasticnet",
   "metadata": {},
   "source": [
    "## 5. ElasticNet (L1 + L2)\n",
    "\n",
    "### 5.1 Basic ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elasticnet-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet with different l1_ratio values\n",
    "l1_ratios = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "alpha_en = 0.1\n",
    "\n",
    "en_results = []\n",
    "\n",
    "print(\"ElasticNet with Different L1 Ratios (Œ± = 0.1)\")\n",
    "print(\"=\"*70)\n",
    "print(\"l1_ratio = 0.0 ‚Üí Pure Ridge\")\n",
    "print(\"l1_ratio = 1.0 ‚Üí Pure Lasso\\n\")\n",
    "\n",
    "for l1_ratio in l1_ratios:\n",
    "    # Train model\n",
    "    en = ElasticNet(alpha=alpha_en, l1_ratio=l1_ratio, max_iter=10000)\n",
    "    en.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_test_pred = en.predict(X_test_scaled)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    n_nonzero = np.sum(en.coef_ != 0)\n",
    "    \n",
    "    en_results.append({\n",
    "        'L1 Ratio': l1_ratio,\n",
    "        'Test R¬≤': test_r2,\n",
    "        'Non-zero Coefs': n_nonzero,\n",
    "        'Sparsity %': (1 - n_nonzero/X.shape[1])*100\n",
    "    })\n",
    "    \n",
    "    print(f\"l1_ratio = {l1_ratio:.1f}: Test R¬≤ = {test_r2:.4f}, \"\n",
    "          f\"Non-zero = {n_nonzero}, Sparsity = {(1 - n_nonzero/X.shape[1])*100:.1f}%\")\n",
    "\n",
    "en_df = pd.DataFrame(en_results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Summary:\")\n",
    "print(en_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° ElasticNet Benefits:\")\n",
    "print(\"  - Combines Ridge and Lasso advantages\")\n",
    "print(\"  - More stable than Lasso when features are correlated\")\n",
    "print(\"  - Still performs feature selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elasticnet-cv",
   "metadata": {},
   "source": [
    "### 5.2 ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e9136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ElasticNetCV\n",
    "en_cv = ElasticNetCV(l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9], \n",
    "                     cv=5, max_iter=10000, random_state=42)\n",
    "en_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"ElasticNetCV: Automatic Hyperparameter Selection\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBest alpha: {en_cv.alpha_:.6f}\")\n",
    "print(f\"Best l1_ratio: {en_cv.l1_ratio_:.2f}\")\n",
    "\n",
    "# Evaluate\n",
    "y_test_pred_en = en_cv.predict(X_test_scaled)\n",
    "test_r2_en = r2_score(y_test, y_test_pred_en)\n",
    "test_mse_en = mean_squared_error(y_test, y_test_pred_en)\n",
    "n_nonzero_en = np.sum(en_cv.coef_ != 0)\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  R¬≤: {test_r2_en:.4f}\")\n",
    "print(f\"  MSE: {test_mse_en:.2f}\")\n",
    "print(f\"\\nFeature Selection:\")\n",
    "print(f\"  Selected: {n_nonzero_en}/{X.shape[1]} features\")\n",
    "print(f\"  Sparsity: {(1 - n_nonzero_en/X.shape[1])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "## 6. Complete Comparison\n",
    "\n",
    "### 6.1 Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all methods\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'OLS (No Regularization)',\n",
    "        'Train R¬≤': train_r2_ols,\n",
    "        'Test R¬≤': test_r2_ols,\n",
    "        'Test MSE': test_mse_ols,\n",
    "        'Non-zero Coefs': X.shape[1],\n",
    "        'Alpha': '-'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Ridge',\n",
    "        'Train R¬≤': ridge_cv.best_score_,\n",
    "        'Test R¬≤': test_r2_ridge,\n",
    "        'Test MSE': test_mse_ridge,\n",
    "        'Non-zero Coefs': X.shape[1],\n",
    "        'Alpha': f\"{ridge_cv.alpha_:.4f}\"\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Lasso',\n",
    "        'Train R¬≤': r2_score(y_train, lasso_cv.predict(X_train_scaled)),\n",
    "        'Test R¬≤': test_r2_lasso,\n",
    "        'Test MSE': test_mse_lasso,\n",
    "        'Non-zero Coefs': n_nonzero,\n",
    "        'Alpha': f\"{lasso_cv.alpha_:.6f}\"\n",
    "    },\n",
    "    {\n",
    "        'Method': 'ElasticNet',\n",
    "        'Train R¬≤': r2_score(y_train, en_cv.predict(X_train_scaled)),\n",
    "        'Test R¬≤': test_r2_en,\n",
    "        'Test MSE': test_mse_en,\n",
    "        'Non-zero Coefs': n_nonzero_en,\n",
    "        'Alpha': f\"{en_cv.alpha_:.6f}\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL COMPARISON: All Regularization Methods\")\n",
    "print(\"=\"*80)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Find best method\n",
    "best_idx = comparison['Test R¬≤'].idxmax()\n",
    "best_method = comparison.loc[best_idx]\n",
    "\n",
    "print(f\"\\nüèÜ Best Method: {best_method['Method']}\")\n",
    "print(f\"   Test R¬≤: {best_method['Test R¬≤']:.4f}\")\n",
    "print(f\"   Features used: {int(best_method['Non-zero Coefs'])}/{X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# R¬≤ scores\n",
    "methods = comparison['Method']\n",
    "x_pos = np.arange(len(methods))\n",
    "\n",
    "axes[0].bar(x_pos - 0.2, comparison['Train R¬≤'], 0.4, label='Train R¬≤', alpha=0.8)\n",
    "axes[0].bar(x_pos + 0.2, comparison['Test R¬≤'], 0.4, label='Test R¬≤', alpha=0.8)\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(methods, rotation=15, ha='right')\n",
    "axes[0].set_ylabel('R¬≤ Score')\n",
    "axes[0].set_title('Performance Comparison')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Feature usage\n",
    "axes[1].bar(x_pos, comparison['Non-zero Coefs'], alpha=0.8)\n",
    "axes[1].axhline(y=X.shape[1], color='r', linestyle='--', label=f'Total features ({X.shape[1]})')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(methods, rotation=15, ha='right')\n",
    "axes[1].set_ylabel('Number of Features')\n",
    "axes[1].set_title('Feature Selection')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real-dataset",
   "metadata": {},
   "source": [
    "## 7. Real Dataset Example: Diabetes\n",
    "\n",
    "### 7.1 Apply All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diabetes-all",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "X_db = diabetes.data\n",
    "y_db = diabetes.target\n",
    "\n",
    "# Split and scale\n",
    "X_train_db, X_test_db, y_train_db, y_test_db = train_test_split(\n",
    "    X_db, y_db, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler_db = StandardScaler()\n",
    "X_train_db_scaled = scaler_db.fit_transform(X_train_db)\n",
    "X_test_db_scaled = scaler_db.transform(X_test_db)\n",
    "\n",
    "print(\"Diabetes Dataset Regularization Comparison\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Features: {diabetes.feature_names}\")\n",
    "print(f\"Samples: {X_db.shape[0]}, Features: {X_db.shape[1]}\")\n",
    "\n",
    "# Train all models\n",
    "models = {\n",
    "    'OLS': LinearRegression(),\n",
    "    'Ridge': RidgeCV(alphas=np.logspace(-3, 3, 100), cv=5),\n",
    "    'Lasso': LassoCV(cv=5, max_iter=10000, random_state=42),\n",
    "    'ElasticNet': ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99], \n",
    "                               cv=5, max_iter=10000, random_state=42)\n",
    "}\n",
    "\n",
    "diabetes_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_db_scaled, y_train_db)\n",
    "    y_pred = model.predict(X_test_db_scaled)\n",
    "    \n",
    "    r2 = r2_score(y_test_db, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_db, y_pred))\n",
    "    mae = mean_absolute_error(y_test_db, y_pred)\n",
    "    \n",
    "    n_nonzero = np.sum(model.coef_ != 0) if hasattr(model, 'coef_') else X_db.shape[1]\n",
    "    \n",
    "    diabetes_results.append({\n",
    "        'Method': name,\n",
    "        'R¬≤': r2,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'Features': n_nonzero\n",
    "    })\n",
    "\n",
    "diabetes_df = pd.DataFrame(diabetes_results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(diabetes_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diabetes-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature selection\n",
    "feature_comparison = pd.DataFrame({\n",
    "    'Feature': diabetes.feature_names,\n",
    "    'OLS': models['OLS'].coef_,\n",
    "    'Ridge': models['Ridge'].coef_,\n",
    "    'Lasso': models['Lasso'].coef_,\n",
    "    'ElasticNet': models['ElasticNet'].coef_\n",
    "})\n",
    "\n",
    "print(\"\\nFeature Coefficients Comparison:\")\n",
    "print(\"=\"*70)\n",
    "print(feature_comparison.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x_pos = np.arange(len(diabetes.feature_names))\n",
    "width = 0.2\n",
    "\n",
    "ax.bar(x_pos - 1.5*width, feature_comparison['OLS'], width, label='OLS', alpha=0.8)\n",
    "ax.bar(x_pos - 0.5*width, feature_comparison['Ridge'], width, label='Ridge', alpha=0.8)\n",
    "ax.bar(x_pos + 0.5*width, feature_comparison['Lasso'], width, label='Lasso', alpha=0.8)\n",
    "ax.bar(x_pos + 1.5*width, feature_comparison['ElasticNet'], width, label='ElasticNet', alpha=0.8)\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(diabetes.feature_names, rotation=45, ha='right')\n",
    "ax.set_ylabel('Coefficient Value')\n",
    "ax.set_title('Diabetes: Coefficient Comparison Across Methods')\n",
    "ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Notice how Lasso/ElasticNet set some coefficients to zero!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Decision Guide\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "\n",
    "# Ridge (L2) - shrinks all coefficients\n",
    "ridge = RidgeCV(alphas=np.logspace(-3, 3, 100), cv=5)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Lasso (L1) - feature selection\n",
    "lasso = LassoCV(cv=5, max_iter=10000)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# ElasticNet (L1 + L2) - best of both\n",
    "elastic = ElasticNetCV(l1_ratio=[0.1, 0.5, 0.9], cv=5, max_iter=10000)\n",
    "elastic.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### When to Use Each Method\n",
    "\n",
    "| Scenario | Recommended Method | Reason |\n",
    "|----------|-------------------|--------|\n",
    "| Many features, all relevant | **Ridge** | Keeps all features, reduces coefficients |\n",
    "| Many features, some irrelevant | **Lasso** | Automatic feature selection |\n",
    "| Correlated features | **ElasticNet** | More stable than Lasso |\n",
    "| Small dataset, many features | **Ridge or ElasticNet** | Prevents overfitting |\n",
    "| Need interpretable model | **Lasso** | Sparse solution, clear feature importance |\n",
    "| Multicollinearity present | **Ridge** | Handles correlated features well |\n",
    "| Feature selection + stability | **ElasticNet** | Combines advantages of both |\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "| Property | Ridge (L2) | Lasso (L1) | ElasticNet |\n",
    "|----------|------------|------------|------------|\n",
    "| Penalty | \\(\\sum \\beta_j^2\\) | \\(\\sum |\\beta_j|\\) | L1 + L2 |\n",
    "| Sparsity | No | Yes | Yes |\n",
    "| Feature selection | No | Yes | Yes |\n",
    "| Correlated features | Keeps all | Picks one | Compromise |\n",
    "| Solution | Closed-form | Iterative | Iterative |\n",
    "| Interpretability | Moderate | High | High |\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "**Alpha (Œ±)**: Controls regularization strength\n",
    "- Œ± = 0: No regularization (OLS)\n",
    "- Small Œ±: Weak regularization\n",
    "- Large Œ±: Strong regularization\n",
    "- Use CV methods (RidgeCV, LassoCV) for automatic selection\n",
    "\n",
    "**L1 Ratio** (ElasticNet only): Balance between L1 and L2\n",
    "- l1_ratio = 0: Pure Ridge\n",
    "- l1_ratio = 1: Pure Lasso  \n",
    "- 0 < l1_ratio < 1: Combination\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Always standardize features** before regularization\n",
    "2. **Use CV methods** (RidgeCV, LassoCV) for automatic alpha selection\n",
    "3. **Plot coefficient paths** to understand feature importance\n",
    "4. **Start with ElasticNet** if unsure (combines both advantages)\n",
    "5. **Check feature selection** - Lasso/ElasticNet show which features matter\n",
    "6. **Compare with OLS** to see if regularization helps\n",
    "7. **Use appropriate metrics** - R¬≤, MSE, MAE for regression\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "- ‚ùå Not standardizing features before regularization\n",
    "- ‚ùå Using too large alpha (underfitting)\n",
    "- ‚ùå Using too small alpha (overfitting)\n",
    "- ‚ùå Not using CV for alpha selection\n",
    "- ‚ùå Expecting Lasso to work well with highly correlated features\n",
    "- ‚ùå Interpreting coefficients without standardization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Logistic Regression (classification)\n",
    "- Polynomial regression with regularization\n",
    "- Feature engineering\n",
    "- Advanced regularization techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
