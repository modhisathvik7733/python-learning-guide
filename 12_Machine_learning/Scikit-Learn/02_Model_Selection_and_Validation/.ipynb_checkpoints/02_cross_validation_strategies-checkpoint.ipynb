{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# Cross-Validation Strategies\n",
        "\n",
        "## Overview\n",
        "\n",
        "Different data scenarios require different CV strategies:\n",
        "\n",
        "| Strategy | Best For | Key Feature |\n",
        "|----------|----------|-------------|\n",
        "| **KFold** | General purpose | Random splits |\n",
        "| **StratifiedKFold** | Classification (imbalanced) | Preserves class distribution |\n",
        "| **GroupKFold** | Grouped data | Keeps groups together |\n",
        "| **TimeSeriesSplit** | Time series | Respects temporal order |\n",
        "| **LeaveOneOut (LOOCV)** | Very small datasets | K=n (one sample per fold) |\n",
        "| **LeavePOut** | Small datasets | Leave P samples out |\n",
        "| **ShuffleSplit** | Random subsampling | Multiple random splits |\n",
        "| **StratifiedShuffleSplit** | Classification + random | Stratified random splits |\n",
        "\n",
        "This notebook explores each strategy with practical examples."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup",
      "metadata": {},
      "source": [
        "## Setup and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, make_classification\n",
        "from sklearn.model_selection import (\n",
        "    KFold,\n",
        "    StratifiedKFold,\n",
        "    GroupKFold,\n",
        "    TimeSeriesSplit,\n",
        "    LeaveOneOut,\n",
        "    LeavePOut,\n",
        "    ShuffleSplit,\n",
        "    StratifiedShuffleSplit,\n",
        "    cross_val_score\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "np.random.seed(42)\n",
        "print(\"\u2713 Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kfold",
      "metadata": {},
      "source": [
        "## 1. KFold - Basic Random Splits\n",
        "\n",
        "**Use Case**: General-purpose CV for regression or balanced classification\n",
        "\n",
        "**Parameters**:\n",
        "- `n_splits`: Number of folds (K)\n",
        "- `shuffle`: Shuffle data before splitting (recommended)\n",
        "- `random_state`: Seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kfold-demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "print(\"Dataset: Iris\")\n",
        "print(f\"Samples: {len(X)}, Features: {X.shape[1]}\")\n",
        "print(f\"Classes: {np.unique(y)}\")\n",
        "\n",
        "# Create KFold splitter\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\nKFold Splits (K=5):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kfold.split(X), 1):\n",
        "    print(f\"\\nFold {fold}:\")\n",
        "    print(f\"  Train indices: {len(train_idx)} samples, first 5: {train_idx[:5]}\")\n",
        "    print(f\"  Test indices:  {len(test_idx)} samples, first 5: {test_idx[:5]}\")\n",
        "    print(f\"  Test class distribution: {np.bincount(y[test_idx])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kfold-visual",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize KFold splits\n",
        "def visualize_cv_splits(cv_splitter, X, y, title):\n",
        "    \"\"\"Visualize train/test splits\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 4))\n",
        "    \n",
        "    for i, (train, test) in enumerate(cv_splitter.split(X, y)):\n",
        "        # Create mask for visualization\n",
        "        mask = np.zeros(len(X))\n",
        "        mask[test] = 1\n",
        "        \n",
        "        ax.scatter(range(len(X)), [i] * len(X), c=mask, \n",
        "                  cmap='coolwarm', marker='|', s=200, alpha=0.8)\n",
        "    \n",
        "    ax.set_xlabel('Sample Index')\n",
        "    ax.set_ylabel('CV Iteration')\n",
        "    ax.set_title(title)\n",
        "    ax.set_yticks(range(cv_splitter.get_n_splits()))\n",
        "    ax.set_ylim(-0.5, cv_splitter.get_n_splits() - 0.5)\n",
        "    plt.colorbar(ax.collections[0], ax=ax, label='Train (0) / Test (1)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_cv_splits(kfold, X, y, 'KFold (K=5) - Random Splits')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kfold-usage",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use KFold with cross_val_score\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Method 1: Pass cv as integer\n",
        "scores1 = cross_val_score(model, X, y, cv=5)\n",
        "\n",
        "# Method 2: Pass cv object\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores2 = cross_val_score(model, X, y, cv=kfold)\n",
        "\n",
        "print(\"Cross-Validation Scores:\")\n",
        "print(f\"  cv=5 (default):        {scores1.mean():.4f} \u00b1 {scores1.std():.4f}\")\n",
        "print(f\"  cv=KFold(shuffle=True): {scores2.mean():.4f} \u00b1 {scores2.std():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stratifiedkfold",
      "metadata": {},
      "source": [
        "## 2. StratifiedKFold - Preserving Class Distribution\n",
        "\n",
        "**Use Case**: Classification with imbalanced classes\n",
        "\n",
        "**Why Important**: Regular KFold might create folds with very different class distributions, leading to unreliable estimates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stratified-demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create imbalanced dataset\n",
        "X_imb, y_imb = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_classes=3,\n",
        "    n_informative=15,\n",
        "    n_redundant=5,\n",
        "    weights=[0.6, 0.3, 0.1],  # Imbalanced!\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Imbalanced Dataset:\")\n",
        "print(f\"Total samples: {len(y_imb)}\")\n",
        "print(f\"Class distribution: {np.bincount(y_imb)}\")\n",
        "print(f\"Class percentages: {np.bincount(y_imb) / len(y_imb) * 100}\")\n",
        "\n",
        "# Compare KFold vs StratifiedKFold\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARISON: KFold vs StratifiedKFold\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Regular KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "print(\"\\nKFold (no stratification):\")\n",
        "for fold, (train_idx, test_idx) in enumerate(kfold.split(X_imb), 1):\n",
        "    test_dist = np.bincount(y_imb[test_idx])\n",
        "    test_pct = test_dist / len(test_idx) * 100\n",
        "    print(f\"  Fold {fold}: {test_dist} \u2192 {test_pct.round(1)}%\")\n",
        "\n",
        "# Stratified KFold\n",
        "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "print(\"\\nStratifiedKFold (preserves distribution):\")\n",
        "for fold, (train_idx, test_idx) in enumerate(skfold.split(X_imb, y_imb), 1):\n",
        "    test_dist = np.bincount(y_imb[test_idx])\n",
        "    test_pct = test_dist / len(test_idx) * 100\n",
        "    print(f\"  Fold {fold}: {test_dist} \u2192 {test_pct.round(1)}%\")\n",
        "\n",
        "print(\"\\n\u2713 StratifiedKFold maintains consistent class distribution across folds!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stratified-visual",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize both\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# KFold\n",
        "for i, (train, test) in enumerate(kfold.split(X_imb)):\n",
        "    test_classes = y_imb[test]\n",
        "    for cls in range(3):\n",
        "        count = (test_classes == cls).sum()\n",
        "        ax1.bar(i, count, bottom=sum((test_classes == c).sum() for c in range(cls)), \n",
        "               label=f'Class {cls}' if i == 0 else '')\n",
        "\n",
        "ax1.set_xlabel('Fold')\n",
        "ax1.set_ylabel('Number of Samples')\n",
        "ax1.set_title('KFold: Varying Class Distribution')\n",
        "ax1.legend()\n",
        "\n",
        "# StratifiedKFold\n",
        "for i, (train, test) in enumerate(skfold.split(X_imb, y_imb)):\n",
        "    test_classes = y_imb[test]\n",
        "    for cls in range(3):\n",
        "        count = (test_classes == cls).sum()\n",
        "        ax2.bar(i, count, bottom=sum((test_classes == c).sum() for c in range(cls)),\n",
        "               label=f'Class {cls}' if i == 0 else '')\n",
        "\n",
        "ax2.set_xlabel('Fold')\n",
        "ax2.set_ylabel('Number of Samples')\n",
        "ax2.set_title('StratifiedKFold: Consistent Class Distribution')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "groupkfold",
      "metadata": {},
      "source": [
        "## 3. GroupKFold - Keeping Groups Together\n",
        "\n",
        "**Use Case**: Data with natural groups (e.g., multiple samples from same patient, user, or location)\n",
        "\n",
        "**Important**: Prevents data leakage by ensuring same group doesn't appear in both train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "groupkfold-demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create grouped dataset (e.g., medical data from patients)\n",
        "n_samples = 100\n",
        "n_features = 20\n",
        "\n",
        "# Each patient has 5 measurements\n",
        "groups = np.repeat(np.arange(20), 5)  # 20 patients, 5 samples each\n",
        "X_grouped = np.random.randn(n_samples, n_features)\n",
        "y_grouped = np.random.randint(0, 2, n_samples)\n",
        "\n",
        "print(\"Grouped Dataset Example:\")\n",
        "print(f\"Total samples: {n_samples}\")\n",
        "print(f\"Number of groups (patients): {len(np.unique(groups))}\")\n",
        "print(f\"Samples per group: {n_samples // len(np.unique(groups))}\")\n",
        "print(f\"\\nFirst 10 group labels: {groups[:10]}\")\n",
        "\n",
        "# Regular KFold (WRONG for grouped data)\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"KFold (WRONG - groups in both train and test):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kfold.split(X_grouped), 1):\n",
        "    train_groups = set(groups[train_idx])\n",
        "    test_groups = set(groups[test_idx])\n",
        "    overlap = train_groups & test_groups\n",
        "    print(f\"Fold {fold}: {len(overlap)} groups appear in BOTH train and test! \u26a0\ufe0f\")\n",
        "\n",
        "# GroupKFold (CORRECT)\n",
        "gkfold = GroupKFold(n_splits=5)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"GroupKFold (CORRECT - groups kept separate):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(gkfold.split(X_grouped, y_grouped, groups), 1):\n",
        "    train_groups = set(groups[train_idx])\n",
        "    test_groups = set(groups[test_idx])\n",
        "    overlap = train_groups & test_groups\n",
        "    print(f\"Fold {fold}:\")\n",
        "    print(f\"  Train: {len(train_groups)} groups, {len(train_idx)} samples\")\n",
        "    print(f\"  Test:  {len(test_groups)} groups, {len(test_idx)} samples\")\n",
        "    print(f\"  Overlap: {len(overlap)} groups \u2713\")\n",
        "\n",
        "print(\"\\n\u2713 GroupKFold prevents data leakage in grouped scenarios!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "timeseriessplit",
      "metadata": {},
      "source": [
        "## 4. TimeSeriesSplit - Respecting Temporal Order\n",
        "\n",
        "**Use Case**: Time series forecasting, temporal data\n",
        "\n",
        "**Key Feature**: Training always on past data, testing on future data (no shuffle!)\n",
        "\n",
        "```\n",
        "Fold 1: [Train]               [Test]\n",
        "Fold 2: [Train Train]         [Test]\n",
        "Fold 3: [Train Train Train]   [Test]\n",
        "Fold 4: [Train Train Train Train] [Test]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "timeseries-demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create time series data (e.g., stock prices)\n",
        "n_timepoints = 100\n",
        "dates = pd.date_range('2020-01-01', periods=n_timepoints, freq='D')\n",
        "\n",
        "# Synthetic time series\n",
        "time_index = np.arange(n_timepoints)\n",
        "X_ts = np.column_stack([time_index, np.sin(time_index / 10), np.cos(time_index / 10)])\n",
        "y_ts = time_index + 10 * np.sin(time_index / 5) + np.random.randn(n_timepoints) * 2\n",
        "\n",
        "print(\"Time Series Dataset:\")\n",
        "print(f\"Timepoints: {n_timepoints}\")\n",
        "print(f\"Date range: {dates[0].date()} to {dates[-1].date()}\")\n",
        "\n",
        "# TimeSeriesSplit\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TimeSeriesSplit (expanding window):\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_ts), 1):\n",
        "    train_dates = dates[train_idx]\n",
        "    test_dates = dates[test_idx]\n",
        "    print(f\"\\nFold {fold}:\")\n",
        "    print(f\"  Train: {len(train_idx):3d} samples | {train_dates[0].date()} to {train_dates[-1].date()}\")\n",
        "    print(f\"  Test:  {len(test_idx):3d} samples | {test_dates[0].date()} to {test_dates[-1].date()}\")\n",
        "\n",
        "print(\"\\n\u2713 Training set grows over time, always predicting the future!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "timeseries-visual",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize TimeSeriesSplit\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "for i, (train, test) in enumerate(tscv.split(X_ts)):\n",
        "    # Plot train and test indices\n",
        "    ax.fill_between(train, i, i+0.8, color='skyblue', alpha=0.7, label='Train' if i == 0 else '')\n",
        "    ax.fill_between(test, i, i+0.8, color='coral', alpha=0.7, label='Test' if i == 0 else '')\n",
        "\n",
        "ax.set_xlabel('Time Index (Days)')\n",
        "ax.set_ylabel('CV Fold')\n",
        "ax.set_title('TimeSeriesSplit: Expanding Window')\n",
        "ax.set_ylim(-0.5, tscv.get_n_splits())\n",
        "ax.set_yticks(range(tscv.get_n_splits()))\n",
        "ax.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "timeseries-usage",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use TimeSeriesSplit for model evaluation\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "scores = cross_val_score(model, X_ts, y_ts, cv=tscv, scoring='r2')\n",
        "\n",
        "print(\"Time Series Cross-Validation Results:\")\n",
        "print(f\"Fold scores: {scores}\")\n",
        "print(f\"\\nMean R\u00b2: {scores.mean():.4f}\")\n",
        "print(f\"Std R\u00b2:  {scores.std():.4f}\")\n",
        "print(\"\\n\u26a0\ufe0f For time series: later folds often have higher scores (more training data)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "leaveoneout",
      "metadata": {},
      "source": [
        "## 5. LeaveOneOut (LOOCV) - Maximum Training Data\n",
        "\n",
        "**Use Case**: Very small datasets (<100 samples)\n",
        "\n",
        "**Trade-off**: Most training data per fold, but K=n iterations (very slow!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "loocv-demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Small dataset\n",
        "X_small = X[:30]  # Only 30 samples\n",
        "y_small = y[:30]\n",
        "\n",
        "print(f\"Small Dataset: {len(X_small)} samples\")\n",
        "\n",
        "# LeaveOneOut\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "print(f\"\\nLeaveOneOut: {loo.get_n_splits(X_small)} folds (one per sample)\")\n",
        "\n",
        "# Show first 5 folds\n",
        "print(\"\\nFirst 5 folds:\")\n",
        "for fold, (train_idx, test_idx) in enumerate(loo.split(X_small), 1):\n",
        "    if fold <= 5:\n",
        "        print(f\"Fold {fold:2d}: Train={len(train_idx)} samples, Test={len(test_idx)} sample (index {test_idx[0]})\")\n",
        "\n",
        "# Evaluate with LOOCV\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "scores_loo = cross_val_score(model, X_small, y_small, cv=loo)\n",
        "\n",
        "print(f\"\\nLOOCV Results:\")\n",
        "print(f\"  Number of folds: {len(scores_loo)}\")\n",
        "print(f\"  Mean accuracy: {scores_loo.mean():.4f}\")\n",
        "print(f\"  Std deviation: {scores_loo.std():.4f}\")\n",
        "\n",
        "# Compare with 5-fold\n",
        "scores_5fold = cross_val_score(model, X_small, y_small, cv=5)\n",
        "print(f\"\\n5-Fold CV (for comparison):\")\n",
        "print(f\"  Mean accuracy: {scores_5fold.mean():.4f}\")\n",
        "print(f\"  Std deviation: {scores_5fold.std():.4f}\")\n",
        "\n",
        "print(\"\\n\ud83d\udca1 LOOCV: Maximum training data but very expensive (K=n)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shufflesplit",
      "metadata": {},
      "source": [
        "## 6. ShuffleSplit - Random Subsampling\n",
        "\n",
        "**Use Case**: Want to control train/test split ratio independently of K\n",
        "\n",
        "**Advantage**: Flexible split sizes, overlapping test sets allowed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shufflesplit-demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ShuffleSplit\n",
        "ss = ShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
        "\n",
        "print(\"ShuffleSplit Configuration:\")\n",
        "print(f\"  Number of splits: 10\")\n",
        "print(f\"  Test size: 25%\")\n",
        "print(f\"  Train size: 75% (automatic)\")\n",
        "\n",
        "print(\"\\nSplits:\")\n",
        "for fold, (train_idx, test_idx) in enumerate(ss.split(X), 1):\n",
        "    if fold <= 5:\n",
        "        print(f\"Split {fold:2d}: Train={len(train_idx)}, Test={len(test_idx)}\")\n",
        "\n",
        "# Use with cross_val_score\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "scores = cross_val_score(model, X, y, cv=ss)\n",
        "\n",
        "print(f\"\\nShuffleSplit CV Results:\")\n",
        "print(f\"  Mean accuracy: {scores.mean():.4f} \u00b1 {scores.std():.4f}\")\n",
        "\n",
        "# StratifiedShuffleSplit (for classification)\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
        "scores_stratified = cross_val_score(model, X, y, cv=sss)\n",
        "\n",
        "print(f\"\\nStratifiedShuffleSplit CV Results:\")\n",
        "print(f\"  Mean accuracy: {scores_stratified.mean():.4f} \u00b1 {scores_stratified.std():.4f}\")\n",
        "\n",
        "print(\"\\n\ud83d\udca1 ShuffleSplit: Flexible but test sets can overlap\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "comparison",
      "metadata": {},
      "source": [
        "## 7. Strategy Comparison on Real Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "comparison-demo",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "X_cancer, y_cancer = cancer.data, cancer.target\n",
        "\n",
        "print(\"Breast Cancer Dataset:\")\n",
        "print(f\"Samples: {len(X_cancer)}\")\n",
        "print(f\"Features: {X_cancer.shape[1]}\")\n",
        "print(f\"Classes: {cancer.target_names}\")\n",
        "print(f\"Class distribution: {np.bincount(y_cancer)}\")\n",
        "\n",
        "# Compare different strategies\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "strategies = {\n",
        "    'KFold (K=5)': KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    'KFold (K=10)': KFold(n_splits=10, shuffle=True, random_state=42),\n",
        "    'StratifiedKFold (K=5)': StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    'StratifiedKFold (K=10)': StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
        "    'ShuffleSplit (n=10)': ShuffleSplit(n_splits=10, test_size=0.2, random_state=42),\n",
        "    'StratifiedShuffleSplit (n=10)': StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CROSS-VALIDATION STRATEGY COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "results = []\n",
        "for name, cv_strategy in strategies.items():\n",
        "    scores = cross_val_score(model, X_cancer, y_cancer, cv=cv_strategy)\n",
        "    results.append({\n",
        "        'Strategy': name,\n",
        "        'Mean': scores.mean(),\n",
        "        'Std': scores.std(),\n",
        "        'Min': scores.min(),\n",
        "        'Max': scores.max()\n",
        "    })\n",
        "    print(f\"\\n{name:30s}: {scores.mean():.4f} \u00b1 {scores.std():.4f}\")\n",
        "    print(f\"{'':30s}  Range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
        "\n",
        "# Create comparison DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Summary Table:\")\n",
        "print(\"=\" * 70)\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "choosing-strategy",
      "metadata": {},
      "source": [
        "## 8. Decision Guide: Choosing the Right Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "decision-guide",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive decision guide\n",
        "guide = pd.DataFrame({\n",
        "    'Data Type': [\n",
        "        'General (balanced)',\n",
        "        'Imbalanced classes',\n",
        "        'Time series',\n",
        "        'Grouped data',\n",
        "        'Very small (<100)',\n",
        "        'Large dataset',\n",
        "        'Want flexible splits',\n",
        "        'Imbalanced + flexible'\n",
        "    ],\n",
        "    'Recommended Strategy': [\n",
        "        'KFold(shuffle=True)',\n",
        "        'StratifiedKFold',\n",
        "        'TimeSeriesSplit',\n",
        "        'GroupKFold',\n",
        "        'LeaveOneOut or LeavePOut',\n",
        "        'ShuffleSplit (faster)',\n",
        "        'ShuffleSplit',\n",
        "        'StratifiedShuffleSplit'\n",
        "    ],\n",
        "    'Typical K': [\n",
        "        '5-10',\n",
        "        '5-10',\n",
        "        '5',\n",
        "        '3-5',\n",
        "        'n (samples)',\n",
        "        '3-5',\n",
        "        '10-20',\n",
        "        '10-20'\n",
        "    ],\n",
        "    'Key Parameter': [\n",
        "        'shuffle=True',\n",
        "        'shuffle=True',\n",
        "        'n_splits',\n",
        "        'n_splits',\n",
        "        '-',\n",
        "        'test_size',\n",
        "        'test_size',\n",
        "        'test_size'\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nDecision Guide: Choosing CV Strategy\")\n",
        "print(\"=\" * 90)\n",
        "print(guide.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"IMPORTANT NOTES:\")\n",
        "print(\"=\" * 90)\n",
        "notes = [\n",
        "    \"Always set random_state for reproducibility\",\n",
        "    \"Use shuffle=True for KFold unless data is ordered\",\n",
        "    \"StratifiedKFold is almost always better for classification\",\n",
        "    \"Never use regular KFold for time series (use TimeSeriesSplit)\",\n",
        "    \"GroupKFold is crucial when samples are not independent\",\n",
        "    \"LeaveOneOut is only for very small datasets (expensive!)\",\n",
        "    \"Higher K = more reliable but slower\",\n",
        "    \"ShuffleSplit allows overlapping test sets (different from KFold)\"\n",
        "]\n",
        "for i, note in enumerate(notes, 1):\n",
        "    print(f\"{i}. {note}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "### Strategy Comparison\n",
        "\n",
        "| Strategy | Pros | Cons | Use When |\n",
        "|----------|------|------|----------|\n",
        "| **KFold** | Simple, fast | May create imbalanced folds | General regression |\n",
        "| **StratifiedKFold** | Preserves class distribution | Only for classification | Classification (default) |\n",
        "| **GroupKFold** | Prevents leakage | Unequal fold sizes | Grouped data |\n",
        "| **TimeSeriesSplit** | Respects temporal order | Growing training set | Time series only |\n",
        "| **LeaveOneOut** | Maximum training data | Very slow (K=n) | Tiny datasets |\n",
        "| **ShuffleSplit** | Flexible, fast | Overlapping test sets | Large datasets |\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "```python\n",
        "# Default for classification\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Default for regression\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# For time series (NO SHUFFLE!)\n",
        "cv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# For grouped data\n",
        "cv = GroupKFold(n_splits=5)\n",
        "scores = cross_val_score(model, X, y, cv=cv, groups=groups)\n",
        "\n",
        "# For fast experimentation\n",
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### Common Mistakes to Avoid\n",
        "\n",
        "1. \u274c Using KFold for imbalanced classification \u2192 Use StratifiedKFold\n",
        "2. \u274c Using shuffle with time series \u2192 Use TimeSeriesSplit (no shuffle!)\n",
        "3. \u274c Not using GroupKFold for grouped data \u2192 Data leakage!\n",
        "4. \u274c Forgetting random_state \u2192 Unreproducible results\n",
        "5. \u274c Using LOOCV on large datasets \u2192 Too slow\n",
        "6. \u274c Not setting shuffle=True for KFold \u2192 May get ordered data issues"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}