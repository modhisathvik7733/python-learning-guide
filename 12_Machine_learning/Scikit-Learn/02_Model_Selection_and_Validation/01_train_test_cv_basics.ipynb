{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Train-Test Split and Cross-Validation Basics\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Why Split Data?**\n",
    "- Training on entire dataset â†’ Can't estimate real-world performance\n",
    "- Model might just memorize training data (overfitting)\n",
    "- Need **unseen data** to evaluate generalization\n",
    "\n",
    "**The Golden Rule**: Never test on training data!\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### 1. Train-Test Split\n",
    "- Simple split: 70-80% train, 20-30% test\n",
    "- Fast and straightforward\n",
    "- âš ï¸ High variance (depends on random split)\n",
    "\n",
    "### 2. Cross-Validation (CV)\n",
    "- Split data into K folds\n",
    "- Train on K-1 folds, test on remaining fold\n",
    "- Repeat K times, average results\n",
    "- âœ“ More reliable performance estimate\n",
    "- âœ“ Uses all data for both training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, load_wine, load_diabetes, load_breast_cancer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    cross_val_score, \n",
    "    cross_validate,\n",
    "    KFold\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-test-split",
   "metadata": {},
   "source": [
    "## 1. Train-Test Split Basics\n",
    "\n",
    "### Simple Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "basic-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "Total samples: 150\n",
      "Features: 4\n",
      "Classes: ['setosa' 'versicolor' 'virginica']\n",
      "Class distribution: [50 50 50]\n",
      "\n",
      "After Split:\n",
      "Training set: 120 samples (80.0%)\n",
      "Test set: 30 samples (20.0%)\n",
      "\n",
      "Train class distribution: [40 41 39]\n",
      "Test class distribution: [10  9 11]\n"
     ]
    }
   ],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Classes: {iris.target_names}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Basic split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42     # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"\\nAfter Split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X):.1%})\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X):.1%})\")\n",
    "print(f\"\\nTrain class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stratified-split",
   "metadata": {},
   "source": [
    "### Stratified Split (For Imbalanced Data)\n",
    "\n",
    "**Problem**: Random split might create unbalanced train/test sets\n",
    "\n",
    "**Solution**: `stratify` parameter maintains class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stratified",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced Dataset:\n",
      "Class distribution: [50 50]\n",
      "Class ratio: 50.0% vs 50.0%\n",
      "\n",
      "Without Stratification:\n",
      "Train: [33 37] â†’ 47.1% vs 52.9%\n",
      "Test:  [17 13] â†’ 56.7% vs 43.3%\n",
      "\n",
      "With Stratification:\n",
      "Train: [35 35] â†’ 50.0% vs 50.0%\n",
      "Test:  [15 15] â†’ 50.0% vs 50.0%\n",
      "\n",
      "âœ“ Stratification preserves class distribution!\n"
     ]
    }
   ],
   "source": [
    "# Create imbalanced dataset\n",
    "X_imbalanced = X[y != 2]  # Remove class 2\n",
    "y_imbalanced = y[y != 2]\n",
    "\n",
    "print(\"Imbalanced Dataset:\")\n",
    "print(f\"Class distribution: {np.bincount(y_imbalanced)}\")\n",
    "print(f\"Class ratio: {np.bincount(y_imbalanced)[0]/len(y_imbalanced):.1%} vs {np.bincount(y_imbalanced)[1]/len(y_imbalanced):.1%}\")\n",
    "\n",
    "# Split WITHOUT stratification\n",
    "X_tr1, X_te1, y_tr1, y_te1 = train_test_split(\n",
    "    X_imbalanced, y_imbalanced, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nWithout Stratification:\")\n",
    "print(f\"Train: {np.bincount(y_tr1)} â†’ {np.bincount(y_tr1)[0]/len(y_tr1):.1%} vs {np.bincount(y_tr1)[1]/len(y_tr1):.1%}\")\n",
    "print(f\"Test:  {np.bincount(y_te1)} â†’ {np.bincount(y_te1)[0]/len(y_te1):.1%} vs {np.bincount(y_te1)[1]/len(y_te1):.1%}\")\n",
    "\n",
    "# Split WITH stratification\n",
    "X_tr2, X_te2, y_tr2, y_te2 = train_test_split(\n",
    "    X_imbalanced, y_imbalanced, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    stratify=y_imbalanced  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(f\"\\nWith Stratification:\")\n",
    "print(f\"Train: {np.bincount(y_tr2)} â†’ {np.bincount(y_tr2)[0]/len(y_tr2):.1%} vs {np.bincount(y_tr2)[1]/len(y_tr2):.1%}\")\n",
    "print(f\"Test:  {np.bincount(y_te2)} â†’ {np.bincount(y_te2)[0]/len(y_te2):.1%} vs {np.bincount(y_te2)[1]/len(y_te2):.1%}\")\n",
    "\n",
    "print(\"\\nâœ“ Stratification preserves class distribution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-test-demo",
   "metadata": {},
   "source": [
    "### Training and Evaluating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "model-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Training accuracy: 0.9750\n",
      "Test accuracy: 1.0000\n",
      "\n",
      "Difference: 0.0250\n",
      "âœ“ Good generalization (test â‰¥ train)\n"
     ]
    }
   ],
   "source": [
    "# Train model on training set\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on both sets\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"Training accuracy: {train_score:.4f}\")\n",
    "print(f\"Test accuracy: {test_score:.4f}\")\n",
    "print(f\"\\nDifference: {abs(train_score - test_score):.4f}\")\n",
    "\n",
    "if train_score - test_score > 0.1:\n",
    "    print(\"âš ï¸ Warning: Possible overfitting (train >> test)\")\n",
    "elif test_score > train_score:\n",
    "    print(\"âœ“ Good generalization (test â‰¥ train)\")\n",
    "else:\n",
    "    print(\"âœ“ Model generalizes well\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-variance",
   "metadata": {},
   "source": [
    "### Problem with Single Train-Test Split\n",
    "\n",
    "Performance varies with different random splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "split-variance-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Across Different Splits:\n",
      "Scores: ['1.000', '0.967', '0.967', '1.000', '0.967', '0.967', '0.967', '0.867', '0.900', '1.000']\n",
      "\n",
      "Mean: 0.9600\n",
      "Std:  0.0416\n",
      "Range: [0.8667, 1.0000]\n",
      "\n",
      "âš ï¸ High variance! Need more reliable evaluation method...\n"
     ]
    }
   ],
   "source": [
    "# Test with different random states\n",
    "test_scores = []\n",
    "\n",
    "for seed in range(10):\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed\n",
    "    )\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    score = model.score(X_te, y_te)\n",
    "    test_scores.append(score)\n",
    "\n",
    "print(\"Test Accuracy Across Different Splits:\")\n",
    "print(f\"Scores: {[f'{s:.3f}' for s in test_scores]}\")\n",
    "print(f\"\\nMean: {np.mean(test_scores):.4f}\")\n",
    "print(f\"Std:  {np.std(test_scores):.4f}\")\n",
    "print(f\"Range: [{np.min(test_scores):.4f}, {np.max(test_scores):.4f}]\")\n",
    "\n",
    "print(\"\\nâš ï¸ High variance! Need more reliable evaluation method...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-validation",
   "metadata": {},
   "source": [
    "## 2. Cross-Validation: More Reliable Evaluation\n",
    "\n",
    "### How K-Fold CV Works\n",
    "\n",
    "```\n",
    "Fold 1: [Test] [Train] [Train] [Train] [Train]\n",
    "Fold 2: [Train] [Test] [Train] [Train] [Train]\n",
    "Fold 3: [Train] [Train] [Test] [Train] [Train]\n",
    "Fold 4: [Train] [Train] [Train] [Test] [Train]\n",
    "Fold 5: [Train] [Train] [Train] [Train] [Test]\n",
    "\n",
    "Final Score = Average of all fold scores\n",
    "```\n",
    "\n",
    "### Using cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cv-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Results:\n",
      "Fold scores: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "\n",
      "Mean accuracy: 0.9733\n",
      "Std deviation: 0.0249\n",
      "95% confidence interval: [0.9244, 1.0222]\n",
      "\n",
      "Comparison:\n",
      "Single split std: 0.0416\n",
      "CV std: 0.0249\n",
      "\n",
      "âœ“ Cross-validation provides more stable estimates!\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    model, X, y, \n",
    "    cv=5,              # 5 folds\n",
    "    scoring='accuracy' # Metric to compute\n",
    ")\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "print(f\"Fold scores: {cv_scores}\")\n",
    "print(f\"\\nMean accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std deviation: {cv_scores.std():.4f}\")\n",
    "print(f\"95% confidence interval: [{cv_scores.mean() - 1.96*cv_scores.std():.4f}, {cv_scores.mean() + 1.96*cv_scores.std():.4f}]\")\n",
    "\n",
    "# Compare with single split\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"Single split std: {np.std(test_scores):.4f}\")\n",
    "print(f\"CV std: {cv_scores.std():.4f}\")\n",
    "print(f\"\\nâœ“ Cross-validation provides more stable estimates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cv-different-k",
   "metadata": {},
   "source": [
    "### Effect of Different K Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cv-k-values",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation with Different K:\n",
      "==================================================\n",
      "\n",
      "K= 3: Mean=0.9733, Std=0.0094\n",
      "      Training size per fold: 100 samples\n",
      "\n",
      "K= 5: Mean=0.9733, Std=0.0249\n",
      "      Training size per fold: 120 samples\n",
      "\n",
      "K=10: Mean=0.9733, Std=0.0327\n",
      "      Training size per fold: 135 samples\n",
      "\n",
      "K=15: Mean=0.9733, Std=0.0442\n",
      "      Training size per fold: 140 samples\n",
      "\n",
      "ðŸ’¡ Trade-off:\n",
      "  - Higher K â†’ More training data per fold, but more computation\n",
      "  - Lower K â†’ Faster, but less stable estimates\n",
      "  - K=5 or K=10 are common choices\n"
     ]
    }
   ],
   "source": [
    "# Test different K values\n",
    "k_values = [3, 5, 10, 15]\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "print(\"Cross-Validation with Different K:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for k in k_values:\n",
    "    scores = cross_val_score(model, X, y, cv=k)\n",
    "    print(f\"\\nK={k:2d}: Mean={scores.mean():.4f}, Std={scores.std():.4f}\")\n",
    "    print(f\"      Training size per fold: {len(X) * (k-1) / k:.0f} samples\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Trade-off:\")\n",
    "print(\"  - Higher K â†’ More training data per fold, but more computation\")\n",
    "print(\"  - Lower K â†’ Faster, but less stable estimates\")\n",
    "print(\"  - K=5 or K=10 are common choices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-validate",
   "metadata": {},
   "source": [
    "## 3. cross_validate: More Information\n",
    "\n",
    "`cross_validate` returns more details than `cross_val_score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cross-validate-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Cross-Validation Results:\n",
      "==================================================\n",
      "\n",
      "Test scores:  [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Train scores: [0.96666667 0.96666667 0.98333333 0.98333333 0.975     ]\n",
      "\n",
      "Fit time (s): [0.01917219 0.02856588 0.01980019 0.02551484 0.03522682]\n",
      "Score time (s): [0.00039601 0.00048614 0.00032163 0.00038886 0.00035214]\n",
      "\n",
      "Summary:\n",
      "  Test accuracy:  0.9733 Â± 0.0249\n",
      "  Train accuracy: 0.9750 Â± 0.0075\n",
      "  Average fit time: 0.0257s\n",
      "\n",
      "âœ“ Model generalizes well\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Get detailed CV results\n",
    "cv_results = cross_validate(\n",
    "    model, X, y,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,  # Also return training scores\n",
    "    return_estimator=False     # Don't return fitted models (saves memory)\n",
    ")\n",
    "\n",
    "print(\"Detailed Cross-Validation Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTest scores:  {cv_results['test_score']}\")\n",
    "print(f\"Train scores: {cv_results['train_score']}\")\n",
    "print(f\"\\nFit time (s): {cv_results['fit_time']}\")\n",
    "print(f\"Score time (s): {cv_results['score_time']}\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Test accuracy:  {cv_results['test_score'].mean():.4f} Â± {cv_results['test_score'].std():.4f}\")\n",
    "print(f\"  Train accuracy: {cv_results['train_score'].mean():.4f} Â± {cv_results['train_score'].std():.4f}\")\n",
    "print(f\"  Average fit time: {cv_results['fit_time'].mean():.4f}s\")\n",
    "\n",
    "# Check for overfitting\n",
    "train_mean = cv_results['train_score'].mean()\n",
    "test_mean = cv_results['test_score'].mean()\n",
    "if train_mean - test_mean > 0.1:\n",
    "    print(\"\\nâš ï¸ Warning: Possible overfitting\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Model generalizes well\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-metrics",
   "metadata": {},
   "source": [
    "### Multiple Metrics at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "multiple-metrics-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Metrics Cross-Validation:\n",
      "==================================================\n",
      "\n",
      "ACCURACY:\n",
      "  Mean: 0.9733\n",
      "  Std:  0.0249\n",
      "\n",
      "PRECISION_MACRO:\n",
      "  Mean: 0.9768\n",
      "  Std:  0.0211\n",
      "\n",
      "RECALL_MACRO:\n",
      "  Mean: 0.9733\n",
      "  Std:  0.0249\n",
      "\n",
      "F1_MACRO:\n",
      "  Mean: 0.9732\n",
      "  Std:  0.0252\n"
     ]
    }
   ],
   "source": [
    "# Evaluate multiple metrics\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    model, X, y,\n",
    "    cv=5,\n",
    "    scoring=scoring\n",
    ")\n",
    "\n",
    "print(\"Multiple Metrics Cross-Validation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for metric in scoring:\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    print(f\"  Mean: {scores.mean():.4f}\")\n",
    "    print(f\"  Std:  {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real-example",
   "metadata": {},
   "source": [
    "## 4. Real-World Example: Wine Quality Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wine-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Dataset:\n",
      "Samples: 178\n",
      "Features: 13\n",
      "Classes: ['class_0' 'class_1' 'class_2']\n",
      "\n",
      "============================================================\n",
      "METHOD 1: Single Train-Test Split\n",
      "============================================================\n",
      "Logistic Regression      : 0.9815\n",
      "Decision Tree            : 0.9630\n",
      "Random Forest            : 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Load Wine dataset\n",
    "wine = load_wine()\n",
    "X_wine, y_wine = wine.data, wine.target\n",
    "\n",
    "print(\"Wine Dataset:\")\n",
    "print(f\"Samples: {len(X_wine)}\")\n",
    "print(f\"Features: {X_wine.shape[1]}\")\n",
    "print(f\"Classes: {wine.target_names}\")\n",
    "\n",
    "# Compare models with train-test split\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(\n",
    "    X_wine, y_wine, test_size=0.3, random_state=42, stratify=y_wine\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_w_scaled = scaler.fit_transform(X_train_w)\n",
    "X_test_w_scaled = scaler.transform(X_test_w)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"METHOD 1: Single Train-Test Split\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "split_results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_w_scaled, y_train_w)\n",
    "    test_score = model.score(X_test_w_scaled, y_test_w)\n",
    "    split_results[name] = test_score\n",
    "    print(f\"{name:25s}: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wine-cv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "METHOD 2: 5-Fold Cross-Validation\n",
      "============================================================\n",
      "Logistic Regression      : 0.9832 Â± 0.0137\n",
      "Decision Tree            : 0.8654 Â± 0.0440\n",
      "Random Forest            : 0.9778 Â± 0.0208\n",
      "\n",
      "============================================================\n",
      "COMPARISON\n",
      "============================================================\n",
      "Logistic Regression:\n",
      "  Single split: 0.9815\n",
      "  CV mean:      0.9832 Â± 0.0137\n",
      "\n",
      "Decision Tree:\n",
      "  Single split: 0.9630\n",
      "  CV mean:      0.8654 Â± 0.0440\n",
      "\n",
      "Random Forest:\n",
      "  Single split: 1.0000\n",
      "  CV mean:      0.9778 Â± 0.0208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare with cross-validation\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"METHOD 2: 5-Fold Cross-Validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cv_results = {}\n",
    "for name, model in models.items():\n",
    "    # Create pipeline with scaling\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(pipeline, X_wine, y_wine, cv=5)\n",
    "    cv_results[name] = scores\n",
    "    print(f\"{name:25s}: {scores.mean():.4f} Â± {scores.std():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "for name in models.keys():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Single split: {split_results[name]:.4f}\")\n",
    "    print(f\"  CV mean:      {cv_results[name].mean():.4f} Â± {cv_results[name].std():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regression-cv",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "regression-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes Dataset (Regression):\n",
      "Samples: 442\n",
      "Features: 10\n",
      "Target range: [25, 346]\n",
      "\n",
      "======================================================================\n",
      "REGRESSION CROSS-VALIDATION (RÂ² Score)\n",
      "======================================================================\n",
      "\n",
      "Linear Regression:\n",
      "  RÂ² Score:  0.4823 Â± 0.0493\n",
      "  RMSE:      54.69 Â± 1.37\n",
      "\n",
      "Ridge:\n",
      "  RÂ² Score:  0.4102 Â± 0.0450\n",
      "  RMSE:      58.45 Â± 2.00\n",
      "\n",
      "Lasso:\n",
      "  RÂ² Score:  0.3376 Â± 0.0287\n",
      "  RMSE:      62.01 Â± 2.40\n",
      "\n",
      "Random Forest:\n",
      "  RÂ² Score:  0.4184 Â± 0.0559\n",
      "  RMSE:      58.00 Â± 2.60\n"
     ]
    }
   ],
   "source": [
    "# Load Diabetes dataset (regression)\n",
    "diabetes = load_diabetes()\n",
    "X_diab, y_diab = diabetes.data, diabetes.target\n",
    "\n",
    "print(\"Diabetes Dataset (Regression):\")\n",
    "print(f\"Samples: {len(X_diab)}\")\n",
    "print(f\"Features: {X_diab.shape[1]}\")\n",
    "print(f\"Target range: [{y_diab.min():.0f}, {y_diab.max():.0f}]\")\n",
    "\n",
    "# Compare regression models\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"REGRESSION CROSS-VALIDATION (RÂ² Score)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, model in reg_models.items():\n",
    "    # Use negative MSE and RÂ² scoring\n",
    "    r2_scores = cross_val_score(model, X_diab, y_diab, cv=5, scoring='r2')\n",
    "    neg_mse_scores = cross_val_score(model, X_diab, y_diab, cv=5, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-neg_mse_scores)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  RÂ² Score:  {r2_scores.mean():.4f} Â± {r2_scores.std():.4f}\")\n",
    "    print(f\"  RMSE:      {rmse_scores.mean():.2f} Â± {rmse_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cv-tips",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "best-practices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Best Practices:\n",
      "======================================================================\n",
      "\n",
      "1. Always use stratified splits for classification\n",
      "   â†’ Use: cv=StratifiedKFold() or stratify=y\n",
      "\n",
      "2. Include preprocessing in pipeline\n",
      "   â†’ Prevents data leakage from scaling/imputation\n",
      "\n",
      "3. Set random_state for reproducibility\n",
      "   â†’ KFold(n_splits=5, shuffle=True, random_state=42)\n",
      "\n",
      "4. Choose K based on dataset size\n",
      "   â†’ Small: K=5, Medium: K=10, Large: K=3\n",
      "\n",
      "5. Report mean AND std deviation\n",
      "   â†’ Shows both performance and stability\n",
      "\n",
      "6. Use cross_validate for detailed info\n",
      "   â†’ Get train scores, timing, multiple metrics\n",
      "\n",
      "7. For time series, use TimeSeriesSplit\n",
      "   â†’ Respects temporal ordering\n",
      "\n",
      "8. For small datasets, consider LOOCV\n",
      "   â†’ Leave-One-Out: K=n (expensive but thorough)\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-Validation Best Practices:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "practices = [\n",
    "    (\"1. Always use stratified splits for classification\",\n",
    "     \"Use: cv=StratifiedKFold() or stratify=y\"),\n",
    "    \n",
    "    (\"2. Include preprocessing in pipeline\",\n",
    "     \"Prevents data leakage from scaling/imputation\"),\n",
    "    \n",
    "    (\"3. Set random_state for reproducibility\",\n",
    "     \"KFold(n_splits=5, shuffle=True, random_state=42)\"),\n",
    "    \n",
    "    (\"4. Choose K based on dataset size\",\n",
    "     \"Small: K=5, Medium: K=10, Large: K=3\"),\n",
    "    \n",
    "    (\"5. Report mean AND std deviation\",\n",
    "     \"Shows both performance and stability\"),\n",
    "    \n",
    "    (\"6. Use cross_validate for detailed info\",\n",
    "     \"Get train scores, timing, multiple metrics\"),\n",
    "    \n",
    "    (\"7. For time series, use TimeSeriesSplit\",\n",
    "     \"Respects temporal ordering\"),\n",
    "    \n",
    "    (\"8. For small datasets, consider LOOCV\",\n",
    "     \"Leave-One-Out: K=n (expensive but thorough)\")\n",
    "]\n",
    "\n",
    "for i, (practice, tip) in enumerate(practices, 1):\n",
    "    print(f\"\\n{practice}\")\n",
    "    print(f\"   â†’ {tip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "when-to-use",
   "metadata": {},
   "source": [
    "## 7. When to Use What?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "decision-guide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Guide: Which Method to Use?\n",
      "================================================================================\n",
      "                         Scenario              Recommended Method     K Value\n",
      "    Large dataset (>100k samples) Single train-test split (80-20)         N/A\n",
      "    Small dataset (<1000 samples)            5-fold or 10-fold CV        5-10\n",
      "Very small dataset (<100 samples)        Leave-One-Out CV (LOOCV)   n (LOOCV)\n",
      "               Imbalanced classes            Stratified K-Fold CV        5-10\n",
      "                 Time series data              TimeSeriesSplit CV           5\n",
      "            Quick experimentation       Single split or 3-fold CV    N/A or 3\n",
      "           Final model evaluation            5-fold or 10-fold CV        5-10\n",
      "            Hyperparameter tuning Nested CV or CV with GridSearch 3-5 (outer)\n"
     ]
    }
   ],
   "source": [
    "# Create decision guide\n",
    "guide = pd.DataFrame({\n",
    "    'Scenario': [\n",
    "        'Large dataset (>100k samples)',\n",
    "        'Small dataset (<1000 samples)',\n",
    "        'Very small dataset (<100 samples)',\n",
    "        'Imbalanced classes',\n",
    "        'Time series data',\n",
    "        'Quick experimentation',\n",
    "        'Final model evaluation',\n",
    "        'Hyperparameter tuning'\n",
    "    ],\n",
    "    'Recommended Method': [\n",
    "        'Single train-test split (80-20)',\n",
    "        '5-fold or 10-fold CV',\n",
    "        'Leave-One-Out CV (LOOCV)',\n",
    "        'Stratified K-Fold CV',\n",
    "        'TimeSeriesSplit CV',\n",
    "        'Single split or 3-fold CV',\n",
    "        '5-fold or 10-fold CV',\n",
    "        'Nested CV or CV with GridSearch'\n",
    "    ],\n",
    "    'K Value': [\n",
    "        'N/A',\n",
    "        '5-10',\n",
    "        'n (LOOCV)',\n",
    "        '5-10',\n",
    "        '5',\n",
    "        'N/A or 3',\n",
    "        '5-10',\n",
    "        '3-5 (outer)'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nDecision Guide: Which Method to Use?\")\n",
    "print(\"=\" * 80)\n",
    "print(guide.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Train-Test Split\n",
    "- âœ“ Fast and simple\n",
    "- âœ“ Good for large datasets\n",
    "- âœ— High variance (depends on split)\n",
    "- âœ— Wastes some data (test set not used for training)\n",
    "\n",
    "### Cross-Validation\n",
    "- âœ“ More reliable performance estimate\n",
    "- âœ“ Uses all data for both training and testing\n",
    "- âœ“ Lower variance\n",
    "- âœ— K times slower than single split\n",
    "- âœ— Not suitable for very large datasets\n",
    "\n",
    "### Critical Points\n",
    "\n",
    "1. **Never test on training data!**\n",
    "2. **Use stratification for imbalanced data**\n",
    "3. **Include preprocessing in pipeline** (prevents data leakage)\n",
    "4. **Report mean Â± std** (not just mean)\n",
    "5. **Choose K wisely**: 5-10 for most cases\n",
    "6. **Set random_state** for reproducibility\n",
    "\n",
    "### Common Workflows\n",
    "\n",
    "```python\n",
    "# Quick Experiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "\n",
    "# Proper Evaluation\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('model', model)])\n",
    "scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "print(f\"{scores.mean():.3f} Â± {scores.std():.3f}\")\n",
    "\n",
    "# Detailed Analysis\n",
    "cv_results = cross_validate(\n",
    "    pipeline, X, y, cv=5,\n",
    "    scoring=['accuracy', 'precision', 'recall'],\n",
    "    return_train_score=True\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
