{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af0647e-86db-461c-ac6f-3e02d23d6a22",
   "metadata": {},
   "source": [
    "# Math & Statistics in NumPy\n",
    "Essential aggregation methods:  \n",
    "- **Descriptive Stats**: `.sum()`, `.mean()`, `.std()`, `.var()`  \n",
    "- **Extrema**: `.min()`, `.max()`, `.argmin()`, `.argmax()`  \n",
    "\n",
    "Key features:  \n",
    "- Vectorized operations (fast)  \n",
    "- Axis parameter for dimension control  \n",
    "- Handle NaN values with `np.nan*` variants  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df3bbd4-1339-4385-8d0c-f4ed60f8b2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 15\n",
      "Mean: 3.0\n",
      "Std dev: 1.4142135623730951\n",
      "Variance: 2.0\n",
      "Min: 1\n",
      "Max: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Basic stats\n",
    "print(\"Sum:\", arr.sum())        # 15\n",
    "print(\"Mean:\", arr.mean())      # 3.0\n",
    "print(\"Std dev:\", arr.std())    # 1.414...\n",
    "print(\"Variance:\", arr.var())   # 2.0\n",
    "print(\"Min:\", arr.min())        # 1\n",
    "print(\"Max:\", arr.max())        # 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d008210-e4f6-4909-bce5-9d4a5280253f",
   "metadata": {},
   "source": [
    "### Axis Parameter (Crucial for Multidimensional Data)\n",
    "- `axis=0`: Column-wise (operate on rows)  \n",
    "- `axis=1`: Row-wise (operate on columns)  \n",
    "- `axis=None`: Global operation  \n",
    "\n",
    "Visualization:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6cf3b4-d53b-4d3b-9eb9-ad97366bb568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column sums: [ 9 12]\n",
      "Column means: [3. 4.]\n",
      "\n",
      "Row maxes: [2 4 6]\n",
      "Row std dev: [0.5 0.5 0.5]\n",
      "\n",
      "Global mean: 3.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### **Cell 4: Code - Axis-Based Operations**\n",
    "\n",
    "matrix = np.array([[1, 2], \n",
    "                   [3, 4],\n",
    "                   [5, 6]])\n",
    "\n",
    "# Column-wise operations\n",
    "print(\"Column sums:\", matrix.sum(axis=0))     # [9,12]\n",
    "print(\"Column means:\", matrix.mean(axis=0))   # [3,4]\n",
    "\n",
    "# Row-wise operations\n",
    "print(\"\\nRow maxes:\", matrix.max(axis=1))      # [2,4,6]\n",
    "print(\"Row std dev:\", matrix.std(axis=1))     # [0.5, 0.5, 0.5]\n",
    "\n",
    "# Global operation\n",
    "print(\"\\nGlobal mean:\", matrix.mean())         # 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6c56b-3802-426c-a539-f5925677af08",
   "metadata": {},
   "source": [
    "### Finding Extremum Locations\n",
    "- `.argmin()`: Index of minimum value  \n",
    "- `.argmax()`: Index of maximum value  \n",
    "- `.argsort()`: Indices that would sort array  \n",
    "\n",
    "Return **positions** rather than values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb560547-3e6e-40c6-852f-4d8a0abda871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min index: 1\n",
      "Max index: 4\n",
      "\n",
      "Column min indices: [0 2]\n",
      "Row max indices: [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([3, 1, 4, 2, 5])\n",
    "\n",
    "print(\"Min index:\", arr.argmin())  # 1 (value=1 at index1)\n",
    "print(\"Max index:\", arr.argmax())  # 4 (value=5 at index4)\n",
    "\n",
    "# 2D with axis\n",
    "matrix = np.array([[1, 9], \n",
    "                   [5, 3],\n",
    "                   [7, 2]])\n",
    "\n",
    "print(\"\\nColumn min indices:\", matrix.argmin(axis=0))  # [0,2]\n",
    "print(\"Row max indices:\", matrix.argmax(axis=1))      # [1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f990e1d-bc5d-4193-9181-8ec4235636a1",
   "metadata": {},
   "source": [
    "### Special NaN Variants\n",
    "Standard functions return NaN if any value is NaN:  \n",
    "```python\n",
    "np.array([1, np.nan]).mean() â†’ nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502c69f2-c2ec-48b7-b9df-051f9def8d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard mean: nan\n",
      "NaN-safe mean: 2.3333333333333335\n",
      "NaN-safe sum: 7.0\n",
      "NaN-safe max: 4.0\n",
      "NaN-safe min index: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### **Cell 8: Code - NaN Safe Operations**\n",
    "\n",
    "arr = np.array([1, 2, np.nan, 4])\n",
    "\n",
    "print(\"Standard mean:\", arr.mean())          # nan\n",
    "print(\"NaN-safe mean:\", np.nanmean(arr))     # 2.333...\n",
    "\n",
    "# Full set of nan variants\n",
    "print(\"NaN-safe sum:\", np.nansum(arr))       # 7.0\n",
    "print(\"NaN-safe max:\", np.nanmax(arr))       # 4.0\n",
    "print(\"NaN-safe min index:\", np.nanargmin(arr))  # 0 (value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45626236-6889-4581-b73a-ff16b22123f0",
   "metadata": {},
   "source": [
    "### Additional Statistical Functions\n",
    "- **Percentiles**: `np.percentile(arr, [25,50,75])`  \n",
    "- **Median**: `np.median(arr)`  \n",
    "- **Correlation**: `np.corrcoef(arr1, arr2)`  \n",
    "- **Histograms**: `np.histogram(arr, bins=10)`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20827b5-3ebf-4a23-a76e-a424a275f2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th/50th/75th percentiles: [-0.61068438  0.01503948  0.67054832]\n",
      "\n",
      "Median: 0.01503947653576517\n",
      "Mean: 0.017424610512133454\n",
      "\n",
      "Correlation: 0.7745966692414834\n",
      "\n",
      "Histogram counts: [  5  13  63 138 226 252 197  70  34   2]\n"
     ]
    }
   ],
   "source": [
    "data = np.random.normal(0, 1, 1000)  # 1000 normal samples\n",
    "\n",
    "# Percentiles\n",
    "quartiles = np.percentile(data, [25, 50, 75])\n",
    "print(\"25th/50th/75th percentiles:\", quartiles)\n",
    "\n",
    "# Median vs Mean\n",
    "print(\"\\nMedian:\", np.median(data))\n",
    "print(\"Mean:\", np.mean(data))\n",
    "\n",
    "# Correlation\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = np.array([2,4,5,4,5])\n",
    "corr = np.corrcoef(x, y)[0,1]\n",
    "print(\"\\nCorrelation:\", corr)  # ~0.79\n",
    "\n",
    "# Histogram\n",
    "counts, bins = np.histogram(data, bins=10)\n",
    "print(\"\\nHistogram counts:\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cef81-660d-4ce7-b686-f815326af9ed",
   "metadata": {},
   "source": [
    "### Why NumPy > Python Built-ins\n",
    "| Operation | Python List | NumPy | Speedup |  \n",
    "|-----------|-------------|-------|---------|  \n",
    "| sum()     | 100 ms      | 1 ms  | 100x    |  \n",
    "| mean()    | 120 ms      | 1.5 ms| 80x     |  \n",
    "| std()     | 150 ms      | 2 ms  | 75x     |  \n",
    "\n",
    "Benchmark for 10 million elements (Python 3.10, NumPy 1.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610743f0-f3d5-49cb-a372-b5329aa783db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sum: 0.05526 sec\n",
      "NumPy sum: 0.00674 sec\n",
      "Speed ratio: 8.2x\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "size = 10_000_000\n",
    "py_list = list(range(size))\n",
    "np_arr = np.arange(size)\n",
    "\n",
    "# Sum benchmark\n",
    "start = time.time()\n",
    "py_sum = sum(py_list)\n",
    "py_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "np_sum = np_arr.sum()\n",
    "np_time = time.time() - start\n",
    "\n",
    "print(f\"Python sum: {py_time:.5f} sec\")\n",
    "print(f\"NumPy sum: {np_time:.5f} sec\")\n",
    "print(f\"Speed ratio: {py_time/np_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca03111-38b9-44d4-8f67-1c922a0b57b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sum: 0.05449 sec\n",
      "NumPy sum: 0.00171 sec\n",
      "Speed ratio: 31.8x\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "size = 10_000_000\n",
    "py_list = list(range(size))\n",
    "np_arr = np.arange(size)\n",
    "\n",
    "# Sum benchmark\n",
    "start = time.time()\n",
    "py_sum = sum(py_list)\n",
    "py_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "np_sum = np_arr.sum()\n",
    "np_time = time.time() - start\n",
    "\n",
    "print(f\"Python sum: {py_time:.5f} sec\")\n",
    "print(f\"NumPy sum: {np_time:.5f} sec\")\n",
    "print(f\"Speed ratio: {py_time/np_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e75e1-594e-44c0-a4fd-e9bcebd17a70",
   "metadata": {},
   "source": [
    "### Real-World Use Cases\n",
    "1. **Data Analysis**:  \n",
    "   `df.values.mean(axis=0)` (Pandas DataFrames use NumPy)  \n",
    "2. **Feature Scaling**:  \n",
    "   `(data - data.mean()) / data.std()`  \n",
    "3. **Anomaly Detection**:  \n",
    "   `z_scores = np.abs(data - mean) / std`  \n",
    "4. **Model Evaluation**:  \n",
    "   `np.mean(y_pred == y_true)` (accuracy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554fe270-da27-406f-a288-f84a3105b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mean: [48.95 45.89 50.46]\n",
      "Scaled mean: [-1.25455202e-16 -4.44089210e-18 -5.88418203e-17]\n",
      "Scaled std: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Standardization (z-score normalization)\n",
    "data = np.random.randint(0, 100, (100, 3))  # 100 samples, 3 features\n",
    "\n",
    "mean = data.mean(axis=0)\n",
    "std = data.std(axis=0)\n",
    "scaled = (data - mean) / std\n",
    "\n",
    "print(\"Original mean:\", mean)\n",
    "print(\"Scaled mean:\", scaled.mean(axis=0))  # ~[0,0,0]\n",
    "print(\"Scaled std:\", scaled.std(axis=0))    # ~[1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae11ae5-6979-4de5-8dec-980cfb1c4e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
