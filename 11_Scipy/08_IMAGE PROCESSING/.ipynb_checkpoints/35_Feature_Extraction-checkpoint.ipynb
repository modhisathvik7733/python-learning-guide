{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# Image Feature Extraction\n- Corner detection, Blob detection, Texture features\n- Real examples: Object recognition, Image matching"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import numpy as np\nfrom scipy import ndimage\nimport matplotlib.pyplot as plt\nprint('Feature extraction module loaded')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Image Moments\n**Definition**: Weighted average of pixel intensities\n\n**Uses**:\n- Center of mass (centroid)\n- Area\n- Orientation\n- Shape descriptors"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Create shape\ny, x = np.ogrid[:200, :300]\nimg = ((y-100)**2/30**2 + (x-150)**2/50**2 < 1).astype(float)\n\n# Calculate moments\nm00 = img.sum()  # Area\nm10 = (img * x).sum()\nm01 = (img * y).sum()\n\n# Centroid\ncx = m10 / m00\ncy = m01 / m00\n\nprint(f'Image moments:')\nprint(f'  Area (m00): {m00:.0f} pixels')\nprint(f'  Centroid: ({cx:.1f}, {cy:.1f})')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Center of Mass\nFind geometric center of objects\nUseful for: tracking, alignment, robotics"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Using scipy function\ncom = ndimage.center_of_mass(img)\nprint(f'Center of mass: {com}')\nprint(f'Matches centroid calculation: {np.allclose([cy, cx], com)}')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Label Connected Components\nIdentify separate objects in binary image\nEach object gets unique label"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Multiple objects\nmulti_obj = np.zeros((200, 300), dtype=bool)\nmulti_obj[(y-60)**2 + (x-80)**2 < 30**2] = True\nmulti_obj[(y-140)**2 + (x-220)**2 < 25**2] = True\nmulti_obj[(y-100)**2 + (x-150)**2 < 20**2] = True\n\n# Label\nlabeled, num_features = ndimage.label(multi_obj)\nprint(f'Connected components: {num_features} objects detected')\n\n# Properties of each object\nfor i in range(1, num_features + 1):\n    obj_mask = labeled == i\n    area = obj_mask.sum()\n    com = ndimage.center_of_mass(obj_mask)\n    print(f'  Object {i}: Area={area} pixels, Center={com}')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Real Example: Cell Counting\nCount cells in microscopy image\nMeasure size distribution"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Simulate cell image\nnp.random.seed(42)\ncells = np.zeros((400, 400), dtype=bool)\nn_cells = 30\n\nfor _ in range(n_cells):\n    cy = np.random.randint(50, 350)\n    cx = np.random.randint(50, 350)\n    radius = np.random.randint(10, 25)\n    y, x = np.ogrid[:400, :400]\n    mask = (y-cy)**2 + (x-cx)**2 < radius**2\n    cells[mask] = True\n\n# Separate touching cells (watershed-like)\ncells = ndimage.binary_opening(cells, iterations=2)\n\n# Label and count\nlabeled_cells, n_cells_detected = ndimage.label(cells)\nprint(f'Cell counting results:')\nprint(f'  Total cells: {n_cells_detected}')\n\n# Measure properties\nareas = []\nfor i in range(1, n_cells_detected + 1):\n    cell_mask = labeled_cells == i\n    area = cell_mask.sum()\n    areas.append(area)\n\nareas = np.array(areas)\nprint(f'  Average cell size: {areas.mean():.1f} ± {areas.std():.1f} pixels')\nprint(f'  Size range: [{areas.min()}, {areas.max()}] pixels')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Texture Features\n**Local Binary Patterns (LBP)**: Compare pixel with neighbors\n**Histogram of Oriented Gradients (HOG)**: Edge orientations\n\nUseful for: classification, recognition"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Simple texture measure: Gradient variance\nimg_texture = np.random.rand(100, 100)\nsobel_x = ndimage.sobel(img_texture, axis=1)\nsobel_y = ndimage.sobel(img_texture, axis=0)\ngradient_mag = np.hypot(sobel_x, sobel_y)\n\ntexture_variance = gradient_mag.var()\nprint(f'Texture feature:')\nprint(f'  Gradient variance: {texture_variance:.4f}')\nprint(f'  High variance = rough texture')\nprint(f'  Low variance = smooth texture')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Summary\n\n### Feature Extraction Functions:\n```python\n# Moments and centroid\ncom = ndimage.center_of_mass(img)\n\n# Connected components\nlabeled, n_objects = ndimage.label(binary_img)\n\n# Object properties\nareas = ndimage.sum(binary_img, labeled, range(1, n_objects+1))\ncentroids = ndimage.center_of_mass(img, labeled, range(1, n_objects+1))\n```\n\n### Applications:\n✓ **Microscopy**: Cell counting, size measurement  \n✓ **Medical**: Tumor detection, organ segmentation  \n✓ **Industrial**: Defect detection, parts counting  \n✓ **Robotics**: Object localization, grasping  \n✓ **Astronomy**: Star detection, galaxy classification  "]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "name": "python3"},
    "language_info": {"version": "3.8.0"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}