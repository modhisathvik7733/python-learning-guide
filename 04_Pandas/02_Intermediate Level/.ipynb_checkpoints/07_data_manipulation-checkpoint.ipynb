{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Manipulation with Pandas\n",
        "\n",
        "## Overview\n",
        "\n",
        "**Data Manipulation** = Transforming, reshaping, and analyzing data\n",
        "\n",
        "### Key Operations We'll Cover\n",
        "\n",
        "| Category | Operations | Use Case |\n",
        "|----------|------------|----------|\n",
        "| **Transform** | `apply()`, `map()`, `applymap()` | Create new columns, custom logic |\n",
        "| **String** | `.str` methods | Clean text, extract patterns |\n",
        "| **DateTime** | `.dt` methods | Parse dates, extract components |\n",
        "| **Groupby** | `groupby()`, `agg()` | Summary statistics by category |\n",
        "| **Combine** | `merge()`, `join()`, `concat()` | Join multiple datasets |\n",
        "| **Reshape** | `pivot()`, `melt()`, `stack()` | Change data structure |\n",
        "| **Sort** | `sort_values()`, `sort_index()` | Order data |\n",
        "| **Filter** | Boolean indexing, `query()` | Select specific rows |\n",
        "\n",
        "### Why Data Manipulation?\n",
        "- \ud83d\udcca **Analysis**: Calculate metrics, trends\n",
        "- \ud83d\udd04 **Transform**: Prepare data for ML models\n",
        "- \ud83d\udcc8 **Insights**: Answer business questions\n",
        "- \ud83c\udfaf **Reporting**: Create summaries, dashboards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.precision', 2)\n",
        "\n",
        "print(\"\u2705 Pandas imported successfully\")\n",
        "print(f\"Version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Dataset: Sales Data\n",
        "\n",
        "We'll use a realistic sales dataset throughout this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample sales data\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate dates\n",
        "start_date = datetime(2024, 1, 1)\n",
        "dates = [start_date + timedelta(days=x) for x in range(100)]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'date': np.random.choice(dates, 100),\n",
        "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Headphones', 'Watch'], 100),\n",
        "    'category': np.random.choice(['Electronics', 'Accessories'], 100),\n",
        "    'quantity': np.random.randint(1, 10, 100),\n",
        "    'price': np.random.choice([299, 599, 899, 1299, 1999], 100),\n",
        "    'customer_name': np.random.choice(['John Smith', 'Alice Johnson', 'Bob Wilson', \n",
        "                                       'Emma Davis', 'Michael Brown'], 100),\n",
        "    'region': np.random.choice(['North', 'South', 'East', 'West'], 100),\n",
        "    'payment_method': np.random.choice(['Credit Card', 'Debit Card', 'UPI', 'Cash'], 100)\n",
        "})\n",
        "\n",
        "# Calculate revenue\n",
        "df['revenue'] = df['quantity'] * df['price']\n",
        "\n",
        "print(\"Sample Sales Data:\")\n",
        "print(df.head(10))\n",
        "print(f\"\\nShape: {df.shape}\")\n",
        "print(f\"\\nColumns: {df.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Transform Functions: apply(), map(), applymap()\n",
        "\n",
        "### Differences\n",
        "\n",
        "| Method | Works On | Purpose | Example |\n",
        "|--------|----------|---------|----------|\n",
        "| **`apply()`** | Series/DataFrame | Apply function to rows/columns | Calculate tax, categorize |\n",
        "| **`map()`** | Series only | Replace values, map dict | Category encoding |\n",
        "| **`applymap()`** | DataFrame | Apply to every cell | Format entire DataFrame |\n",
        "\n",
        "### When to Use\n",
        "- **`apply()`**: Custom calculations (commission, discounts)\n",
        "- **`map()`**: Simple value mapping (category codes)\n",
        "- **`applymap()`**: Format all cells (rarely used)\n",
        "\n",
        "### Syntax\n",
        "```python\n",
        "# apply() on Series\n",
        "df['column'].apply(function)\n",
        "\n",
        "# apply() on DataFrame\n",
        "df.apply(function, axis=0)  # axis=0: column-wise, axis=1: row-wise\n",
        "\n",
        "# map() on Series\n",
        "df['column'].map(mapping_dict)\n",
        "\n",
        "# applymap() on DataFrame\n",
        "df.applymap(function)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== APPLY() EXAMPLES ===\\n\")\n",
        "\n",
        "# Example 1: Apply function to Series\n",
        "print(\"Example 1: Calculate 18% tax on revenue\")\n",
        "df['tax'] = df['revenue'].apply(lambda x: x * 0.18)\n",
        "print(df[['revenue', 'tax']].head())\n",
        "print()\n",
        "\n",
        "# Example 2: Apply custom function\n",
        "print(\"Example 2: Categorize revenue (High/Medium/Low)\")\n",
        "def categorize_revenue(revenue):\n",
        "    if revenue > 10000:\n",
        "        return 'High'\n",
        "    elif revenue > 5000:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "df['revenue_category'] = df['revenue'].apply(categorize_revenue)\n",
        "print(df[['revenue', 'revenue_category']].head())\n",
        "print()\n",
        "\n",
        "# Example 3: Apply to DataFrame rows (axis=1)\n",
        "print(\"Example 3: Calculate discount based on quantity and price\")\n",
        "def calculate_discount(row):\n",
        "    if row['quantity'] >= 5:\n",
        "        return row['revenue'] * 0.10  # 10% discount for bulk\n",
        "    elif row['price'] > 1000:\n",
        "        return row['revenue'] * 0.05  # 5% for expensive items\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['discount'] = df.apply(calculate_discount, axis=1)\n",
        "print(df[['quantity', 'price', 'revenue', 'discount']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 4: Apply to column\n",
        "print(\"Example 4: Calculate total sum per column\")\n",
        "numeric_cols = df[['quantity', 'price', 'revenue']]\n",
        "totals = numeric_cols.apply(sum, axis=0)\n",
        "print(\"Column Totals:\")\n",
        "print(totals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== MAP() EXAMPLES ===\\n\")\n",
        "\n",
        "# Example 1: Map with dictionary\n",
        "print(\"Example 1: Map payment method to codes\")\n",
        "payment_mapping = {\n",
        "    'Credit Card': 'CC',\n",
        "    'Debit Card': 'DC',\n",
        "    'UPI': 'UP',\n",
        "    'Cash': 'CA'\n",
        "}\n",
        "\n",
        "df['payment_code'] = df['payment_method'].map(payment_mapping)\n",
        "print(df[['payment_method', 'payment_code']].head())\n",
        "print()\n",
        "\n",
        "# Example 2: Map with function\n",
        "print(\"Example 2: Convert product names to uppercase\")\n",
        "df['product_upper'] = df['product'].map(str.upper)\n",
        "print(df[['product', 'product_upper']].head())\n",
        "print()\n",
        "\n",
        "# Example 3: Map with lambda\n",
        "print(\"Example 3: Map price to price range\")\n",
        "df['price_range'] = df['price'].map(lambda x: f\"${x-100}-${x+100}\")\n",
        "print(df[['price', 'price_range']].head())\n",
        "print()\n",
        "\n",
        "# Example 4: Map vs Apply comparison\n",
        "print(\"Example 4: map() vs apply() - Performance\")\n",
        "print(\"map() is faster for simple value replacements\")\n",
        "print(\"apply() is more flexible for complex logic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. String Operations (.str methods)\n",
        "\n",
        "### Common String Methods\n",
        "\n",
        "| Method | Purpose | Example |\n",
        "|--------|---------|----------|\n",
        "| `.str.lower()` | Lowercase | 'HELLO' \u2192 'hello' |\n",
        "| `.str.upper()` | Uppercase | 'hello' \u2192 'HELLO' |\n",
        "| `.str.title()` | Title Case | 'john smith' \u2192 'John Smith' |\n",
        "| `.str.strip()` | Remove whitespace | ' text ' \u2192 'text' |\n",
        "| `.str.replace()` | Replace text | 'hello' \u2192 'hi' |\n",
        "| `.str.contains()` | Check if contains | Check if 'Smith' in name |\n",
        "| `.str.startswith()` | Starts with | Check if starts with 'J' |\n",
        "| `.str.endswith()` | Ends with | Check if ends with '.com' |\n",
        "| `.str.split()` | Split string | 'John Smith' \u2192 ['John', 'Smith'] |\n",
        "| `.str.len()` | String length | 'hello' \u2192 5 |\n",
        "| `.str.extract()` | Extract pattern | Extract digits from text |\n",
        "| `.str.slice()` | Slice string | Get first 3 characters |\n",
        "\n",
        "### Real-World Use Cases\n",
        "- Clean customer names\n",
        "- Extract email domains\n",
        "- Parse product codes\n",
        "- Validate phone numbers\n",
        "- Standardize addresses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== STRING OPERATIONS ===\\n\")\n",
        "\n",
        "# Example 1: Basic transformations\n",
        "print(\"Example 1: Basic string transformations\")\n",
        "print(\"Original names:\")\n",
        "print(df['customer_name'].head())\n",
        "print()\n",
        "print(\"Uppercase:\")\n",
        "print(df['customer_name'].str.upper().head())\n",
        "print()\n",
        "print(\"Lowercase:\")\n",
        "print(df['customer_name'].str.lower().head())\n",
        "print()\n",
        "\n",
        "# Example 2: String length\n",
        "print(\"Example 2: Calculate name length\")\n",
        "df['name_length'] = df['customer_name'].str.len()\n",
        "print(df[['customer_name', 'name_length']].head())\n",
        "print()\n",
        "\n",
        "# Example 3: Contains\n",
        "print(\"Example 3: Filter customers with 'Smith' in name\")\n",
        "smith_customers = df[df['customer_name'].str.contains('Smith', case=False)]\n",
        "print(f\"Found {len(smith_customers)} customers with 'Smith'\")\n",
        "print(smith_customers[['customer_name']].drop_duplicates())\n",
        "print()\n",
        "\n",
        "# Example 4: Split names\n",
        "print(\"Example 4: Split customer names into first and last\")\n",
        "df[['first_name', 'last_name']] = df['customer_name'].str.split(' ', n=1, expand=True)\n",
        "print(df[['customer_name', 'first_name', 'last_name']].head())\n",
        "print()\n",
        "\n",
        "# Example 5: String slicing\n",
        "print(\"Example 5: Extract first 3 characters of product name\")\n",
        "df['product_code'] = df['product'].str.slice(0, 3).str.upper()\n",
        "print(df[['product', 'product_code']].head())\n",
        "print()\n",
        "\n",
        "# Example 6: Starts with\n",
        "print(\"Example 6: Products starting with 'L'\")\n",
        "l_products = df[df['product'].str.startswith('L')]\n",
        "print(f\"Products starting with 'L': {l_products['product'].nunique()}\")\n",
        "print(l_products['product'].unique())\n",
        "print()\n",
        "\n",
        "# Example 7: Replace\n",
        "print(\"Example 7: Replace 'Phone' with 'Smartphone'\")\n",
        "df['product_renamed'] = df['product'].str.replace('Phone', 'Smartphone')\n",
        "print(df[['product', 'product_renamed']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. DateTime Operations (.dt methods)\n",
        "\n",
        "### Common DateTime Methods\n",
        "\n",
        "| Method | Purpose | Example |\n",
        "|--------|---------|----------|\n",
        "| `.dt.year` | Extract year | 2024 |\n",
        "| `.dt.month` | Extract month | 3 (March) |\n",
        "| `.dt.day` | Extract day | 15 |\n",
        "| `.dt.dayofweek` | Day of week | 0=Monday, 6=Sunday |\n",
        "| `.dt.day_name()` | Day name | 'Monday' |\n",
        "| `.dt.month_name()` | Month name | 'March' |\n",
        "| `.dt.quarter` | Quarter | 1, 2, 3, 4 |\n",
        "| `.dt.week` | Week number | 1-52 |\n",
        "| `.dt.weekday` | Weekday | 0-6 |\n",
        "| `.dt.is_month_end` | Is month end | True/False |\n",
        "| `.dt.is_month_start` | Is month start | True/False |\n",
        "| `.dt.date` | Date only | 2024-03-15 |\n",
        "\n",
        "### Time Calculations\n",
        "```python\n",
        "# Date arithmetic\n",
        "df['date'] + pd.Timedelta(days=7)  # Add 7 days\n",
        "df['date2'] - df['date1']  # Date difference\n",
        "\n",
        "# Date ranges\n",
        "pd.date_range('2024-01-01', periods=10, freq='D')\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "- Sales by month/quarter\n",
        "- Weekday vs weekend analysis\n",
        "- Time-based filtering\n",
        "- Calculate age, tenure\n",
        "- Seasonality analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== DATETIME OPERATIONS ===\\n\")\n",
        "\n",
        "# Ensure date column is datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Example 1: Extract components\n",
        "print(\"Example 1: Extract date components\")\n",
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "df['day'] = df['date'].dt.day\n",
        "df['day_name'] = df['date'].dt.day_name()\n",
        "df['month_name'] = df['date'].dt.month_name()\n",
        "\n",
        "print(df[['date', 'year', 'month', 'day', 'day_name', 'month_name']].head())\n",
        "print()\n",
        "\n",
        "# Example 2: Day of week (0=Monday, 6=Sunday)\n",
        "print(\"Example 2: Analyze weekday patterns\")\n",
        "df['is_weekend'] = df['date'].dt.dayofweek >= 5\n",
        "print(df[['date', 'day_name', 'is_weekend']].head())\n",
        "print()\n",
        "\n",
        "weekend_sales = df[df['is_weekend']]['revenue'].sum()\n",
        "weekday_sales = df[~df['is_weekend']]['revenue'].sum()\n",
        "print(f\"Weekend sales: ${weekend_sales:,.2f}\")\n",
        "print(f\"Weekday sales: ${weekday_sales:,.2f}\")\n",
        "print()\n",
        "\n",
        "# Example 3: Quarter\n",
        "print(\"Example 3: Extract quarter\")\n",
        "df['quarter'] = df['date'].dt.quarter\n",
        "print(df[['date', 'quarter']].head())\n",
        "print()\n",
        "\n",
        "# Example 4: Date filtering\n",
        "print(\"Example 4: Filter sales in March 2024\")\n",
        "march_sales = df[(df['date'].dt.month == 3) & (df['date'].dt.year == 2024)]\n",
        "print(f\"March sales count: {len(march_sales)}\")\n",
        "print(f\"March revenue: ${march_sales['revenue'].sum():,.2f}\")\n",
        "print()\n",
        "\n",
        "# Example 5: Calculate days since first sale\n",
        "print(\"Example 5: Calculate days since first sale\")\n",
        "first_sale_date = df['date'].min()\n",
        "df['days_since_first_sale'] = (df['date'] - first_sale_date).dt.days\n",
        "print(df[['date', 'days_since_first_sale']].head())\n",
        "print()\n",
        "\n",
        "# Example 6: Date arithmetic\n",
        "print(\"Example 6: Add 7 days to all dates (delivery date)\")\n",
        "df['delivery_date'] = df['date'] + pd.Timedelta(days=7)\n",
        "print(df[['date', 'delivery_date']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. GroupBy and Aggregations\n",
        "\n",
        "### What is GroupBy?\n",
        "\n",
        "**GroupBy** = Split-Apply-Combine pattern\n",
        "1. **Split**: Divide data into groups\n",
        "2. **Apply**: Apply function to each group\n",
        "3. **Combine**: Combine results\n",
        "\n",
        "```python\n",
        "df.groupby('column').agg(function)\n",
        "```\n",
        "\n",
        "### Common Aggregation Functions\n",
        "\n",
        "| Function | Purpose | Example |\n",
        "|----------|---------|----------|\n",
        "| `sum()` | Total | Total revenue by product |\n",
        "| `mean()` | Average | Average price by region |\n",
        "| `median()` | Middle value | Median revenue |\n",
        "| `count()` | Count | Number of sales |\n",
        "| `nunique()` | Unique count | Unique customers |\n",
        "| `min()` | Minimum | Lowest price |\n",
        "| `max()` | Maximum | Highest revenue |\n",
        "| `std()` | Standard deviation | Revenue variability |\n",
        "| `var()` | Variance | Price variance |\n",
        "| `first()` | First value | First sale date |\n",
        "| `last()` | Last value | Last sale date |\n",
        "\n",
        "### Multiple Aggregations\n",
        "\n",
        "```python\n",
        "# Single aggregation\n",
        "df.groupby('product')['revenue'].sum()\n",
        "\n",
        "# Multiple aggregations\n",
        "df.groupby('product')['revenue'].agg(['sum', 'mean', 'count'])\n",
        "\n",
        "# Different aggregations per column\n",
        "df.groupby('product').agg({\n",
        "    'revenue': ['sum', 'mean'],\n",
        "    'quantity': ['sum', 'max']\n",
        "})\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "- Sales by product/region/month\n",
        "- Customer lifetime value\n",
        "- Regional performance\n",
        "- Product performance analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== GROUPBY OPERATIONS ===\\n\")\n",
        "\n",
        "# Example 1: Simple groupby\n",
        "print(\"Example 1: Total revenue by product\")\n",
        "product_revenue = df.groupby('product')['revenue'].sum().sort_values(ascending=False)\n",
        "print(product_revenue)\n",
        "print()\n",
        "\n",
        "# Example 2: Multiple aggregations\n",
        "print(\"Example 2: Product statistics\")\n",
        "product_stats = df.groupby('product')['revenue'].agg(['sum', 'mean', 'count', 'max', 'min'])\n",
        "product_stats.columns = ['Total', 'Average', 'Count', 'Max', 'Min']\n",
        "print(product_stats)\n",
        "print()\n",
        "\n",
        "# Example 3: Group by multiple columns\n",
        "print(\"Example 3: Revenue by product and region\")\n",
        "product_region = df.groupby(['product', 'region'])['revenue'].sum().sort_values(ascending=False)\n",
        "print(product_region.head(10))\n",
        "print()\n",
        "\n",
        "# Example 4: Different aggregations per column\n",
        "print(\"Example 4: Complex aggregations\")\n",
        "complex_agg = df.groupby('product').agg({\n",
        "    'revenue': ['sum', 'mean'],\n",
        "    'quantity': ['sum', 'max'],\n",
        "    'customer_name': 'nunique'  # Unique customers\n",
        "})\n",
        "print(complex_agg)\n",
        "print()\n",
        "\n",
        "# Example 5: Custom aggregation function\n",
        "print(\"Example 5: Custom aggregation - Revenue range\")\n",
        "def revenue_range(x):\n",
        "    return x.max() - x.min()\n",
        "\n",
        "revenue_ranges = df.groupby('product')['revenue'].agg([\n",
        "    ('Total', 'sum'),\n",
        "    ('Average', 'mean'),\n",
        "    ('Range', revenue_range)\n",
        "])\n",
        "print(revenue_ranges)\n",
        "print()\n",
        "\n",
        "# Example 6: Group by date components\n",
        "print(\"Example 6: Monthly sales trend\")\n",
        "monthly_sales = df.groupby(df['date'].dt.to_period('M'))['revenue'].agg([\n",
        "    ('Total_Revenue', 'sum'),\n",
        "    ('Num_Orders', 'count'),\n",
        "    ('Avg_Order_Value', 'mean')\n",
        "])\n",
        "print(monthly_sales.head())\n",
        "print()\n",
        "\n",
        "# Example 7: Filter groups\n",
        "print(\"Example 7: Products with total revenue > $50,000\")\n",
        "high_revenue_products = df.groupby('product')['revenue'].sum()\n",
        "high_revenue_products = high_revenue_products[high_revenue_products > 50000]\n",
        "print(high_revenue_products)\n",
        "print()\n",
        "\n",
        "# Example 8: Transform (keep original DataFrame size)\n",
        "print(\"Example 8: Add group average to each row\")\n",
        "df['product_avg_revenue'] = df.groupby('product')['revenue'].transform('mean')\n",
        "print(df[['product', 'revenue', 'product_avg_revenue']].head())\n",
        "print()\n",
        "\n",
        "# Example 9: Rank within groups\n",
        "print(\"Example 9: Rank sales within each product\")\n",
        "df['revenue_rank'] = df.groupby('product')['revenue'].rank(ascending=False, method='dense')\n",
        "print(df[['product', 'revenue', 'revenue_rank']].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Combining DataFrames: merge(), join(), concat()\n",
        "\n",
        "### Types of Joins\n",
        "\n",
        "| Join Type | Description | SQL Equivalent |\n",
        "|-----------|-------------|----------------|\n",
        "| **inner** | Only matching rows | INNER JOIN |\n",
        "| **left** | All from left, matching from right | LEFT JOIN |\n",
        "| **right** | All from right, matching from left | RIGHT JOIN |\n",
        "| **outer** | All rows from both | FULL OUTER JOIN |\n",
        "\n",
        "### Methods\n",
        "\n",
        "**1. merge()** - SQL-style joins\n",
        "```python\n",
        "pd.merge(df1, df2, on='key', how='inner')\n",
        "```\n",
        "\n",
        "**2. join()** - Join on index\n",
        "```python\n",
        "df1.join(df2, how='left')\n",
        "```\n",
        "\n",
        "**3. concat()** - Stack DataFrames\n",
        "```python\n",
        "pd.concat([df1, df2], axis=0)  # Vertical stack\n",
        "pd.concat([df1, df2], axis=1)  # Horizontal stack\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "- Join customer data with orders\n",
        "- Merge product catalog with sales\n",
        "- Combine regional datasets\n",
        "- Add demographic information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== COMBINING DATAFRAMES ===\\n\")\n",
        "\n",
        "# Create additional datasets for merging\n",
        "print(\"Creating sample datasets...\\n\")\n",
        "\n",
        "# Customer info dataset\n",
        "customers = pd.DataFrame({\n",
        "    'customer_name': ['John Smith', 'Alice Johnson', 'Bob Wilson', 'Emma Davis', 'Michael Brown'],\n",
        "    'customer_id': [101, 102, 103, 104, 105],\n",
        "    'email': ['john@email.com', 'alice@email.com', 'bob@email.com', \n",
        "              'emma@email.com', 'michael@email.com'],\n",
        "    'loyalty_level': ['Gold', 'Silver', 'Platinum', 'Gold', 'Bronze']\n",
        "})\n",
        "\n",
        "# Product info dataset\n",
        "products = pd.DataFrame({\n",
        "    'product': ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Watch'],\n",
        "    'brand': ['Dell', 'Apple', 'Samsung', 'Sony', 'Apple'],\n",
        "    'warranty_months': [24, 12, 12, 6, 12]\n",
        "})\n",
        "\n",
        "print(\"Customers DataFrame:\")\n",
        "print(customers)\n",
        "print()\n",
        "print(\"Products DataFrame:\")\n",
        "print(products)\n",
        "print()\n",
        "\n",
        "# Example 1: Inner merge\n",
        "print(\"Example 1: INNER MERGE - Sales with customer info\")\n",
        "sales_with_customers = pd.merge(df, customers, on='customer_name', how='inner')\n",
        "print(sales_with_customers[['customer_name', 'email', 'loyalty_level', 'revenue']].head())\n",
        "print(f\"Rows: {len(df)} \u2192 {len(sales_with_customers)}\")\n",
        "print()\n",
        "\n",
        "# Example 2: Left merge\n",
        "print(\"Example 2: LEFT MERGE - Sales with product info\")\n",
        "sales_with_products = pd.merge(df, products, on='product', how='left')\n",
        "print(sales_with_products[['product', 'brand', 'warranty_months', 'revenue']].head())\n",
        "print()\n",
        "\n",
        "# Example 3: Merge on multiple columns\n",
        "print(\"Example 3: Merge on multiple keys\")\n",
        "# Create sample with multiple keys\n",
        "df_subset = df[['product', 'region', 'revenue']].head()\n",
        "region_info = pd.DataFrame({\n",
        "    'product': ['Laptop', 'Phone', 'Laptop'],\n",
        "    'region': ['North', 'North', 'South'],\n",
        "    'regional_discount': [0.05, 0.03, 0.10]\n",
        "})\n",
        "\n",
        "merged = pd.merge(df_subset, region_info, on=['product', 'region'], how='left')\n",
        "print(merged)\n",
        "print()\n",
        "\n",
        "# Example 4: concat() - Vertical stack\n",
        "print(\"Example 4: CONCAT - Stack DataFrames vertically\")\n",
        "df1 = df.head(5)\n",
        "df2 = df.tail(5)\n",
        "stacked = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
        "print(f\"df1: {len(df1)} rows, df2: {len(df2)} rows\")\n",
        "print(f\"Stacked: {len(stacked)} rows\")\n",
        "print()\n",
        "\n",
        "# Example 5: concat() - Horizontal stack\n",
        "print(\"Example 5: CONCAT - Stack DataFrames horizontally\")\n",
        "df_left = df[['product', 'quantity']].head()\n",
        "df_right = df[['price', 'revenue']].head()\n",
        "h_stacked = pd.concat([df_left, df_right], axis=1)\n",
        "print(h_stacked)\n",
        "print()\n",
        "\n",
        "# Example 6: merge with indicator\n",
        "print(\"Example 6: Merge with indicator (shows merge source)\")\n",
        "merged_indicator = pd.merge(df.head(5), customers, on='customer_name', \n",
        "                            how='outer', indicator=True)\n",
        "print(merged_indicator[['customer_name', 'loyalty_level', '_merge']].head())\n",
        "print(\"\\n_merge column values:\")\n",
        "print(\"  - 'both': Found in both DataFrames\")\n",
        "print(\"  - 'left_only': Only in left DataFrame\")\n",
        "print(\"  - 'right_only': Only in right DataFrame\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Pivot Tables and Reshaping\n",
        "\n",
        "### Pivot Table\n",
        "\n",
        "**Pivot** = Reshape data from long to wide format\n",
        "\n",
        "```python\n",
        "df.pivot_table(\n",
        "    values='column_to_aggregate',\n",
        "    index='row_labels',\n",
        "    columns='column_labels',\n",
        "    aggfunc='mean'  # or sum, count, etc.\n",
        ")\n",
        "```\n",
        "\n",
        "### Parameters\n",
        "\n",
        "| Parameter | Purpose | Example |\n",
        "|-----------|---------|----------|\n",
        "| `values` | Column to aggregate | 'revenue' |\n",
        "| `index` | Row labels | 'product' |\n",
        "| `columns` | Column labels | 'region' |\n",
        "| `aggfunc` | Aggregation function | 'sum', 'mean', 'count' |\n",
        "| `fill_value` | Fill missing values | 0 |\n",
        "| `margins` | Add row/column totals | True |\n",
        "\n",
        "### Related Operations\n",
        "\n",
        "**melt()** - Unpivot (wide to long)\n",
        "```python\n",
        "pd.melt(df, id_vars=['id'], value_vars=['col1', 'col2'])\n",
        "```\n",
        "\n",
        "**stack()** - Pivot column labels to row index\n",
        "```python\n",
        "df.stack()\n",
        "```\n",
        "\n",
        "**unstack()** - Pivot row index to column labels\n",
        "```python\n",
        "df.unstack()\n",
        "```\n",
        "\n",
        "### Real-World Use Cases\n",
        "- Create cross-tabulation reports\n",
        "- Sales by product \u00d7 region\n",
        "- Time series analysis (month \u00d7 product)\n",
        "- Excel-style pivot tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== PIVOT TABLES ===\\n\")\n",
        "\n",
        "# Example 1: Simple pivot table\n",
        "print(\"Example 1: Revenue by Product \u00d7 Region\")\n",
        "pivot1 = df.pivot_table(\n",
        "    values='revenue',\n",
        "    index='product',\n",
        "    columns='region',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0\n",
        ")\n",
        "print(pivot1)\n",
        "print()\n",
        "\n",
        "# Example 2: Pivot with margins (totals)\n",
        "print(\"Example 2: Pivot with row and column totals\")\n",
        "pivot2 = df.pivot_table(\n",
        "    values='revenue',\n",
        "    index='product',\n",
        "    columns='region',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0,\n",
        "    margins=True,\n",
        "    margins_name='Total'\n",
        ")\n",
        "print(pivot2)\n",
        "print()\n",
        "\n",
        "# Example 3: Multiple aggregations\n",
        "print(\"Example 3: Multiple aggregation functions\")\n",
        "pivot3 = df.pivot_table(\n",
        "    values='revenue',\n",
        "    index='product',\n",
        "    columns='region',\n",
        "    aggfunc=['sum', 'mean', 'count'],\n",
        "    fill_value=0\n",
        ")\n",
        "print(pivot3)\n",
        "print()\n",
        "\n",
        "# Example 4: Multiple values\n",
        "print(\"Example 4: Pivot multiple values\")\n",
        "pivot4 = df.pivot_table(\n",
        "    values=['revenue', 'quantity'],\n",
        "    index='product',\n",
        "    columns='region',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0\n",
        ")\n",
        "print(pivot4)\n",
        "print()\n",
        "\n",
        "# Example 5: Cross-tabulation (special pivot)\n",
        "print(\"Example 5: Cross-tabulation (product \u00d7 payment method)\")\n",
        "crosstab = pd.crosstab(\n",
        "    df['product'],\n",
        "    df['payment_method'],\n",
        "    values=df['revenue'],\n",
        "    aggfunc='sum',\n",
        "    margins=True\n",
        ")\n",
        "print(crosstab)\n",
        "print()\n",
        "\n",
        "# Example 6: Melt (unpivot)\n",
        "print(\"Example 6: MELT - Convert wide to long format\")\n",
        "# Create wide format\n",
        "wide_df = pd.DataFrame({\n",
        "    'product': ['Laptop', 'Phone', 'Tablet'],\n",
        "    'Q1_sales': [1000, 1500, 800],\n",
        "    'Q2_sales': [1200, 1600, 900],\n",
        "    'Q3_sales': [1100, 1700, 850]\n",
        "})\n",
        "print(\"Wide format:\")\n",
        "print(wide_df)\n",
        "print()\n",
        "\n",
        "# Melt to long format\n",
        "long_df = pd.melt(\n",
        "    wide_df,\n",
        "    id_vars=['product'],\n",
        "    value_vars=['Q1_sales', 'Q2_sales', 'Q3_sales'],\n",
        "    var_name='quarter',\n",
        "    value_name='sales'\n",
        ")\n",
        "print(\"Long format (melted):\")\n",
        "print(long_df)\n",
        "print()\n",
        "\n",
        "# Example 7: Stack and Unstack\n",
        "print(\"Example 7: STACK and UNSTACK\")\n",
        "pivot_for_stack = df.pivot_table(\n",
        "    values='revenue',\n",
        "    index='product',\n",
        "    columns='region',\n",
        "    aggfunc='sum'\n",
        ")\n",
        "print(\"Original pivot:\")\n",
        "print(pivot_for_stack.head())\n",
        "print()\n",
        "\n",
        "stacked = pivot_for_stack.stack()\n",
        "print(\"Stacked (long format):\")\n",
        "print(stacked.head())\n",
        "print()\n",
        "\n",
        "unstacked = stacked.unstack()\n",
        "print(\"Unstacked (back to wide):\")\n",
        "print(unstacked.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sorting and Filtering\n",
        "\n",
        "### Sorting\n",
        "\n",
        "**sort_values()** - Sort by column values\n",
        "```python\n",
        "df.sort_values('column', ascending=True)\n",
        "df.sort_values(['col1', 'col2'], ascending=[True, False])\n",
        "```\n",
        "\n",
        "**sort_index()** - Sort by index\n",
        "```python\n",
        "df.sort_index()\n",
        "```\n",
        "\n",
        "### Filtering (Boolean Indexing)\n",
        "\n",
        "**Single condition**\n",
        "```python\n",
        "df[df['revenue'] > 1000]\n",
        "```\n",
        "\n",
        "**Multiple conditions (AND)**\n",
        "```python\n",
        "df[(df['revenue'] > 1000) & (df['region'] == 'North')]\n",
        "```\n",
        "\n",
        "**Multiple conditions (OR)**\n",
        "```python\n",
        "df[(df['product'] == 'Laptop') | (df['product'] == 'Phone')]\n",
        "```\n",
        "\n",
        "**NOT condition**\n",
        "```python\n",
        "df[~(df['region'] == 'North')]\n",
        "```\n",
        "\n",
        "**isin()** - Check if in list\n",
        "```python\n",
        "df[df['product'].isin(['Laptop', 'Phone'])]\n",
        "```\n",
        "\n",
        "**query()** - SQL-like filtering\n",
        "```python\n",
        "df.query('revenue > 1000 and region == \"North\"')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== SORTING ===\\n\")\n",
        "\n",
        "# Example 1: Sort by single column\n",
        "print(\"Example 1: Sort by revenue (descending)\")\n",
        "sorted_df = df.sort_values('revenue', ascending=False)\n",
        "print(sorted_df[['product', 'revenue']].head())\n",
        "print()\n",
        "\n",
        "# Example 2: Sort by multiple columns\n",
        "print(\"Example 2: Sort by product (A-Z) then revenue (high to low)\")\n",
        "sorted_multi = df.sort_values(['product', 'revenue'], ascending=[True, False])\n",
        "print(sorted_multi[['product', 'revenue']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 3: Sort by index\n",
        "print(\"Example 3: Sort by index\")\n",
        "df_shuffled = df.sample(frac=1)  # Shuffle\n",
        "df_sorted_idx = df_shuffled.sort_index()\n",
        "print(f\"Before: {df_shuffled.index[:5].tolist()}\")\n",
        "print(f\"After: {df_sorted_idx.index[:5].tolist()}\")\n",
        "print()\n",
        "\n",
        "print(\"=== FILTERING ===\\n\")\n",
        "\n",
        "# Example 4: Simple filter\n",
        "print(\"Example 4: Revenue > $5000\")\n",
        "high_revenue = df[df['revenue'] > 5000]\n",
        "print(f\"Found {len(high_revenue)} high-revenue orders\")\n",
        "print(high_revenue[['product', 'revenue']].head())\n",
        "print()\n",
        "\n",
        "# Example 5: Multiple conditions (AND)\n",
        "print(\"Example 5: Laptops in North region\")\n",
        "laptop_north = df[(df['product'] == 'Laptop') & (df['region'] == 'North')]\n",
        "print(f\"Found {len(laptop_north)} matching orders\")\n",
        "print(laptop_north[['product', 'region', 'revenue']].head())\n",
        "print()\n",
        "\n",
        "# Example 6: Multiple conditions (OR)\n",
        "print(\"Example 6: Laptop OR Phone\")\n",
        "laptop_or_phone = df[(df['product'] == 'Laptop') | (df['product'] == 'Phone')]\n",
        "print(f\"Found {len(laptop_or_phone)} orders\")\n",
        "print(laptop_or_phone['product'].value_counts())\n",
        "print()\n",
        "\n",
        "# Example 7: NOT condition\n",
        "print(\"Example 7: NOT North region\")\n",
        "not_north = df[~(df['region'] == 'North')]\n",
        "print(f\"Orders not in North: {len(not_north)}\")\n",
        "print(not_north['region'].value_counts())\n",
        "print()\n",
        "\n",
        "# Example 8: isin() method\n",
        "print(\"Example 8: Products in specific list\")\n",
        "products_of_interest = ['Laptop', 'Phone', 'Tablet']\n",
        "filtered = df[df['product'].isin(products_of_interest)]\n",
        "print(f\"Found {len(filtered)} orders for: {products_of_interest}\")\n",
        "print(filtered['product'].value_counts())\n",
        "print()\n",
        "\n",
        "# Example 9: between() method\n",
        "print(\"Example 9: Revenue between $2000 and $8000\")\n",
        "mid_revenue = df[df['revenue'].between(2000, 8000)]\n",
        "print(f\"Found {len(mid_revenue)} mid-range orders\")\n",
        "print(mid_revenue[['product', 'revenue']].head())\n",
        "print()\n",
        "\n",
        "# Example 10: query() method\n",
        "print(\"Example 10: Using query() - SQL-like syntax\")\n",
        "queried = df.query('revenue > 5000 and region == \"North\"')\n",
        "print(f\"Query result: {len(queried)} rows\")\n",
        "print(queried[['product', 'region', 'revenue']].head())\n",
        "print()\n",
        "\n",
        "# Example 11: String contains in filter\n",
        "print(\"Example 11: Customers with 'Smith' in name\")\n",
        "smith_customers = df[df['customer_name'].str.contains('Smith')]\n",
        "print(f\"Found {len(smith_customers)} orders from Smith customers\")\n",
        "print(smith_customers['customer_name'].unique())\n",
        "print()\n",
        "\n",
        "# Example 12: nlargest() and nsmallest()\n",
        "print(\"Example 12: Top 5 and Bottom 5 by revenue\")\n",
        "print(\"\\nTop 5:\")\n",
        "print(df.nlargest(5, 'revenue')[['product', 'revenue']])\n",
        "print(\"\\nBottom 5:\")\n",
        "print(df.nsmallest(5, 'revenue')[['product', 'revenue']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Window Functions (Rolling, Expanding, Cumulative)\n",
        "\n",
        "### What are Window Functions?\n",
        "\n",
        "**Window Functions** = Perform calculations across a set of rows (window) related to current row\n",
        "\n",
        "### Types\n",
        "\n",
        "**1. Rolling (Moving Window)**\n",
        "- Fixed window size moves through data\n",
        "- Example: 7-day moving average\n",
        "\n",
        "```python\n",
        "df['rolling_avg'] = df['value'].rolling(window=7).mean()\n",
        "```\n",
        "\n",
        "**2. Expanding (Cumulative)**\n",
        "- Window grows from start\n",
        "- Example: Cumulative sum\n",
        "\n",
        "```python\n",
        "df['expanding_sum'] = df['value'].expanding().sum()\n",
        "```\n",
        "\n",
        "**3. Exponentially Weighted (EWM)**\n",
        "- Recent values have more weight\n",
        "- Example: Exponential moving average\n",
        "\n",
        "```python\n",
        "df['ewm_avg'] = df['value'].ewm(span=7).mean()\n",
        "```\n",
        "\n",
        "### Common Operations\n",
        "\n",
        "| Operation | Purpose | Example |\n",
        "|-----------|---------|----------|\n",
        "| `mean()` | Moving average | 7-day avg sales |\n",
        "| `sum()` | Moving sum | Running total |\n",
        "| `min()` | Moving minimum | Lowest price in 30 days |\n",
        "| `max()` | Moving maximum | Highest revenue |\n",
        "| `std()` | Moving std dev | Revenue volatility |\n",
        "\n",
        "### Real-World Use Cases\n",
        "- **Finance**: Moving averages, volatility\n",
        "- **Sales**: Trends, seasonality\n",
        "- **IoT**: Sensor smoothing\n",
        "- **Web**: Page view trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== WINDOW FUNCTIONS ===\\n\")\n",
        "\n",
        "# Create time series data\n",
        "print(\"Creating time series dataset...\\n\")\n",
        "date_range = pd.date_range('2024-01-01', periods=30, freq='D')\n",
        "ts_df = pd.DataFrame({\n",
        "    'date': date_range,\n",
        "    'sales': np.random.randint(100, 500, 30) + np.sin(np.arange(30)) * 50\n",
        "})\n",
        "ts_df['sales'] = ts_df['sales'].round(2)\n",
        "\n",
        "print(ts_df.head(10))\n",
        "print()\n",
        "\n",
        "# Example 1: Rolling mean (moving average)\n",
        "print(\"Example 1: 7-day moving average\")\n",
        "ts_df['rolling_7d_avg'] = ts_df['sales'].rolling(window=7).mean()\n",
        "print(ts_df[['date', 'sales', 'rolling_7d_avg']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 2: Rolling sum\n",
        "print(\"Example 2: 7-day rolling sum\")\n",
        "ts_df['rolling_7d_sum'] = ts_df['sales'].rolling(window=7).sum()\n",
        "print(ts_df[['date', 'sales', 'rolling_7d_sum']].tail())\n",
        "print()\n",
        "\n",
        "# Example 3: Rolling min and max\n",
        "print(\"Example 3: 7-day rolling min and max\")\n",
        "ts_df['rolling_min'] = ts_df['sales'].rolling(window=7).min()\n",
        "ts_df['rolling_max'] = ts_df['sales'].rolling(window=7).max()\n",
        "print(ts_df[['date', 'sales', 'rolling_min', 'rolling_max']].tail())\n",
        "print()\n",
        "\n",
        "# Example 4: Expanding (cumulative)\n",
        "print(\"Example 4: Cumulative sum and mean\")\n",
        "ts_df['cumsum'] = ts_df['sales'].expanding().sum()\n",
        "ts_df['cum_avg'] = ts_df['sales'].expanding().mean()\n",
        "print(ts_df[['date', 'sales', 'cumsum', 'cum_avg']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 5: Using cumsum() directly\n",
        "print(\"Example 5: Cumulative functions (direct)\")\n",
        "ts_df['cumsum_direct'] = ts_df['sales'].cumsum()\n",
        "ts_df['cumprod'] = ts_df['sales'].cumprod()  # Cumulative product\n",
        "ts_df['cummax'] = ts_df['sales'].cummax()  # Cumulative maximum\n",
        "print(ts_df[['date', 'sales', 'cumsum_direct', 'cummax']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 6: Exponential weighted moving average\n",
        "print(\"Example 6: Exponential weighted moving average (EWMA)\")\n",
        "ts_df['ewma'] = ts_df['sales'].ewm(span=7).mean()\n",
        "print(ts_df[['date', 'sales', 'rolling_7d_avg', 'ewma']].tail(10))\n",
        "print(\"\\nNote: EWMA gives more weight to recent values\")\n",
        "print()\n",
        "\n",
        "# Example 7: Shift (lag/lead)\n",
        "print(\"Example 7: Shift for lag and lead values\")\n",
        "ts_df['prev_day_sales'] = ts_df['sales'].shift(1)  # Lag 1\n",
        "ts_df['next_day_sales'] = ts_df['sales'].shift(-1)  # Lead 1\n",
        "ts_df['sales_change'] = ts_df['sales'] - ts_df['prev_day_sales']\n",
        "print(ts_df[['date', 'prev_day_sales', 'sales', 'next_day_sales', 'sales_change']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 8: Percentage change\n",
        "print(\"Example 8: Percentage change\")\n",
        "ts_df['pct_change'] = ts_df['sales'].pct_change() * 100\n",
        "print(ts_df[['date', 'sales', 'pct_change']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 9: Rolling with different window sizes\n",
        "print(\"Example 9: Multiple rolling windows\")\n",
        "ts_df['ma_3d'] = ts_df['sales'].rolling(window=3).mean()\n",
        "ts_df['ma_7d'] = ts_df['sales'].rolling(window=7).mean()\n",
        "ts_df['ma_14d'] = ts_df['sales'].rolling(window=14).mean()\n",
        "print(ts_df[['date', 'sales', 'ma_3d', 'ma_7d', 'ma_14d']].tail(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Additional Data Manipulation Techniques\n",
        "\n",
        "### Creating New Columns\n",
        "\n",
        "**Method 1: Direct assignment**\n",
        "```python\n",
        "df['new_col'] = df['col1'] + df['col2']\n",
        "```\n",
        "\n",
        "**Method 2: assign()**\n",
        "```python\n",
        "df.assign(new_col = lambda x: x['col1'] + x['col2'])\n",
        "```\n",
        "\n",
        "**Method 3: np.where() - Conditional**\n",
        "```python\n",
        "df['category'] = np.where(df['value'] > 100, 'High', 'Low')\n",
        "```\n",
        "\n",
        "**Method 4: np.select() - Multiple conditions**\n",
        "```python\n",
        "conditions = [df['value'] > 100, df['value'] > 50]\n",
        "choices = ['High', 'Medium']\n",
        "df['category'] = np.select(conditions, choices, default='Low')\n",
        "```\n",
        "\n",
        "### Binning\n",
        "\n",
        "**cut()** - Bin continuous data into intervals\n",
        "```python\n",
        "pd.cut(df['age'], bins=[0, 18, 35, 60, 100], \n",
        "       labels=['Child', 'Young', 'Middle', 'Senior'])\n",
        "```\n",
        "\n",
        "**qcut()** - Quantile-based binning\n",
        "```python\n",
        "pd.qcut(df['revenue'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
        "```\n",
        "\n",
        "### Ranking\n",
        "\n",
        "```python\n",
        "df['rank'] = df['revenue'].rank(ascending=False, method='dense')\n",
        "```\n",
        "\n",
        "### Sample\n",
        "\n",
        "```python\n",
        "df.sample(n=10)  # Random 10 rows\n",
        "df.sample(frac=0.1)  # Random 10% of data\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== ADDITIONAL TECHNIQUES ===\\n\")\n",
        "\n",
        "# Example 1: np.where() for conditional columns\n",
        "print(\"Example 1: Create category using np.where()\")\n",
        "df['revenue_level'] = np.where(df['revenue'] > 5000, 'High', 'Low')\n",
        "print(df[['revenue', 'revenue_level']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 2: np.select() for multiple conditions\n",
        "print(\"Example 2: Multiple conditions with np.select()\")\n",
        "conditions = [\n",
        "    df['revenue'] > 10000,\n",
        "    df['revenue'] > 5000,\n",
        "    df['revenue'] > 2000\n",
        "]\n",
        "choices = ['Premium', 'High', 'Medium']\n",
        "df['revenue_tier'] = np.select(conditions, choices, default='Low')\n",
        "print(df[['revenue', 'revenue_tier']].head(10))\n",
        "print()\n",
        "print(\"Revenue tier distribution:\")\n",
        "print(df['revenue_tier'].value_counts())\n",
        "print()\n",
        "\n",
        "# Example 3: cut() - Binning into intervals\n",
        "print(\"Example 3: Bin revenue into ranges\")\n",
        "df['revenue_bin'] = pd.cut(\n",
        "    df['revenue'],\n",
        "    bins=[0, 2000, 5000, 10000, 20000],\n",
        "    labels=['0-2k', '2k-5k', '5k-10k', '10k+'],\n",
        "    include_lowest=True\n",
        ")\n",
        "print(df[['revenue', 'revenue_bin']].head(10))\n",
        "print()\n",
        "print(\"Bin distribution:\")\n",
        "print(df['revenue_bin'].value_counts().sort_index())\n",
        "print()\n",
        "\n",
        "# Example 4: qcut() - Quantile-based binning\n",
        "print(\"Example 4: Quantile-based binning (quartiles)\")\n",
        "df['revenue_quartile'] = pd.qcut(\n",
        "    df['revenue'],\n",
        "    q=4,\n",
        "    labels=['Q1 (Lowest 25%)', 'Q2', 'Q3', 'Q4 (Top 25%)']\n",
        ")\n",
        "print(df[['revenue', 'revenue_quartile']].head(10))\n",
        "print()\n",
        "print(\"Quartile distribution:\")\n",
        "print(df['revenue_quartile'].value_counts().sort_index())\n",
        "print()\n",
        "\n",
        "# Example 5: Ranking\n",
        "print(\"Example 5: Rank orders by revenue\")\n",
        "df['revenue_rank'] = df['revenue'].rank(ascending=False, method='dense')\n",
        "top_orders = df.nsmallest(10, 'revenue_rank')[['product', 'revenue', 'revenue_rank']]\n",
        "print(\"Top 10 orders by revenue:\")\n",
        "print(top_orders)\n",
        "print()\n",
        "\n",
        "# Example 6: assign() method\n",
        "print(\"Example 6: Create multiple columns with assign()\")\n",
        "df_assigned = df.assign(\n",
        "    total_before_tax = lambda x: x['quantity'] * x['price'],\n",
        "    tax_amount = lambda x: x['revenue'] * 0.18,\n",
        "    total_with_tax = lambda x: x['revenue'] * 1.18\n",
        ")\n",
        "print(df_assigned[['revenue', 'tax_amount', 'total_with_tax']].head())\n",
        "print()\n",
        "\n",
        "# Example 7: Sampling\n",
        "print(\"Example 7: Random sampling\")\n",
        "random_10 = df.sample(n=10, random_state=42)\n",
        "print(f\"Sampled 10 random rows: indices {random_10.index.tolist()}\")\n",
        "print()\n",
        "\n",
        "random_10pct = df.sample(frac=0.1, random_state=42)\n",
        "print(f\"Sampled 10% of data: {len(random_10pct)} rows\")\n",
        "print()\n",
        "\n",
        "# Example 8: Clip values\n",
        "print(\"Example 8: Clip revenue (cap at min/max)\")\n",
        "df['revenue_clipped'] = df['revenue'].clip(lower=1000, upper=10000)\n",
        "print(\"Original revenue range:\", df['revenue'].min(), '-', df['revenue'].max())\n",
        "print(\"Clipped revenue range:\", df['revenue_clipped'].min(), '-', df['revenue_clipped'].max())\n",
        "print()\n",
        "\n",
        "# Example 9: Categorical encoding\n",
        "print(\"Example 9: Encode categories as numbers\")\n",
        "df['region_code'] = pd.Categorical(df['region']).codes\n",
        "print(df[['region', 'region_code']].drop_duplicates().sort_values('region_code'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Comprehensive Real-World Example\n",
        "\n",
        "### Business Scenario\n",
        "\n",
        "**Task**: Analyze sales data to answer key business questions:\n",
        "1. Which products are top performers?\n",
        "2. What are the regional trends?\n",
        "3. Who are the VIP customers?\n",
        "4. What's the sales trend over time?\n",
        "5. Which product-region combinations are most profitable?\n",
        "\n",
        "We'll combine multiple techniques learned in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"COMPREHENSIVE SALES ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "# Question 1: Top performing products\n",
        "print(\"1. TOP PERFORMING PRODUCTS\")\n",
        "print(\"-\" * 70)\n",
        "product_performance = df.groupby('product').agg({\n",
        "    'revenue': ['sum', 'mean', 'count'],\n",
        "    'quantity': 'sum',\n",
        "    'customer_name': 'nunique'\n",
        "}).round(2)\n",
        "\n",
        "product_performance.columns = ['Total_Revenue', 'Avg_Order_Value', \n",
        "                                'Num_Orders', 'Units_Sold', 'Unique_Customers']\n",
        "product_performance = product_performance.sort_values('Total_Revenue', ascending=False)\n",
        "\n",
        "print(product_performance)\n",
        "print()\n",
        "\n",
        "# Question 2: Regional trends\n",
        "print(\"2. REGIONAL PERFORMANCE\")\n",
        "print(\"-\" * 70)\n",
        "regional_pivot = df.pivot_table(\n",
        "    values='revenue',\n",
        "    index='region',\n",
        "    columns='product',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0,\n",
        "    margins=True\n",
        ")\n",
        "print(regional_pivot)\n",
        "print()\n",
        "\n",
        "# Question 3: VIP Customers (top 10 by total spend)\n",
        "print(\"3. VIP CUSTOMERS (Top 10 by Total Spend)\")\n",
        "print(\"-\" * 70)\n",
        "customer_analysis = df.groupby('customer_name').agg({\n",
        "    'revenue': ['sum', 'mean', 'count'],\n",
        "    'quantity': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "customer_analysis.columns = ['Total_Spend', 'Avg_Order', 'Num_Orders', 'Total_Items']\n",
        "customer_analysis['Customer_Value_Score'] = (\n",
        "    customer_analysis['Total_Spend'] * 0.5 + \n",
        "    customer_analysis['Num_Orders'] * 100\n",
        ").round(2)\n",
        "\n",
        "vip_customers = customer_analysis.sort_values('Total_Spend', ascending=False).head(10)\n",
        "print(vip_customers)\n",
        "print()\n",
        "\n",
        "# Question 4: Sales trend over time\n",
        "print(\"4. MONTHLY SALES TREND\")\n",
        "print(\"-\" * 70)\n",
        "df_sorted = df.sort_values('date')\n",
        "monthly_trend = df_sorted.groupby(df_sorted['date'].dt.to_period('M')).agg({\n",
        "    'revenue': ['sum', 'mean', 'count']\n",
        "}).round(2)\n",
        "\n",
        "monthly_trend.columns = ['Total_Revenue', 'Avg_Order_Value', 'Num_Orders']\n",
        "monthly_trend['MoM_Growth_%'] = monthly_trend['Total_Revenue'].pct_change() * 100\n",
        "monthly_trend['MoM_Growth_%'] = monthly_trend['MoM_Growth_%'].round(2)\n",
        "\n",
        "print(monthly_trend)\n",
        "print()\n",
        "\n",
        "# Question 5: Best product-region combinations\n",
        "print(\"5. TOP 10 PRODUCT-REGION COMBINATIONS\")\n",
        "print(\"-\" * 70)\n",
        "combo_analysis = df.groupby(['product', 'region'])['revenue'].agg(['sum', 'count']).round(2)\n",
        "combo_analysis.columns = ['Total_Revenue', 'Num_Orders']\n",
        "combo_analysis['Avg_Order'] = (combo_analysis['Total_Revenue'] / combo_analysis['Num_Orders']).round(2)\n",
        "combo_analysis = combo_analysis.sort_values('Total_Revenue', ascending=False).head(10)\n",
        "\n",
        "print(combo_analysis)\n",
        "print()\n",
        "\n",
        "# Bonus: Payment method analysis\n",
        "print(\"6. PAYMENT METHOD ANALYSIS\")\n",
        "print(\"-\" * 70)\n",
        "payment_analysis = pd.crosstab(\n",
        "    df['payment_method'],\n",
        "    df['product'],\n",
        "    values=df['revenue'],\n",
        "    aggfunc='sum',\n",
        "    margins=True\n",
        ").round(2)\n",
        "print(payment_analysis)\n",
        "print()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"=\"*70)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total Revenue: ${df['revenue'].sum():,.2f}\")\n",
        "print(f\"Average Order Value: ${df['revenue'].mean():,.2f}\")\n",
        "print(f\"Total Orders: {len(df):,}\")\n",
        "print(f\"Unique Products: {df['product'].nunique()}\")\n",
        "print(f\"Unique Customers: {df['customer_name'].nunique()}\")\n",
        "print(f\"Date Range: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\")\n",
        "print(f\"Best Selling Product: {df.groupby('product')['revenue'].sum().idxmax()}\")\n",
        "print(f\"Best Region: {df.groupby('region')['revenue'].sum().idxmax()}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Performance Tips & Best Practices\n",
        "\n",
        "### Performance Optimization\n",
        "\n",
        "**1. Vectorization > Loops**\n",
        "```python\n",
        "# \u274c Slow - Loop\n",
        "for i in range(len(df)):\n",
        "    df.loc[i, 'new_col'] = df.loc[i, 'col1'] * 2\n",
        "\n",
        "# \u2705 Fast - Vectorized\n",
        "df['new_col'] = df['col1'] * 2\n",
        "```\n",
        "\n",
        "**2. Use appropriate methods**\n",
        "```python\n",
        "# map() faster than apply() for simple replacements\n",
        "df['col'].map(mapping_dict)  # \u2705 Faster\n",
        "df['col'].apply(lambda x: mapping_dict.get(x))  # \u274c Slower\n",
        "```\n",
        "\n",
        "**3. Filter early, aggregate late**\n",
        "```python\n",
        "# \u2705 Filter first (smaller dataset)\n",
        "df[df['year'] == 2024].groupby('product')['revenue'].sum()\n",
        "\n",
        "# \u274c Aggregate everything first\n",
        "df.groupby('product')['revenue'].sum()[df['year'] == 2024]\n",
        "```\n",
        "\n",
        "**4. Use categorical for repeated strings**\n",
        "```python\n",
        "df['category'] = df['category'].astype('category')  # Saves memory\n",
        "```\n",
        "\n",
        "**5. Chain operations for readability**\n",
        "```python\n",
        "# \u2705 Method chaining\n",
        "result = (df\n",
        "    .query('revenue > 1000')\n",
        "    .groupby('product')['revenue']\n",
        "    .sum()\n",
        "    .sort_values(ascending=False)\n",
        ")\n",
        "```\n",
        "\n",
        "### Common Mistakes to Avoid\n",
        "\n",
        "1. **Using `inplace=True` unnecessarily** - Can prevent optimization\n",
        "2. **Not setting index for frequent lookups** - Slow row access\n",
        "3. **Using `apply()` when vectorization possible** - Much slower\n",
        "4. **Creating unnecessary copies** - Memory waste\n",
        "5. **Not using `query()` for complex filters** - Less readable\n",
        "\n",
        "### Memory Management\n",
        "\n",
        "```python\n",
        "# Check memory usage\n",
        "df.memory_usage(deep=True)\n",
        "\n",
        "# Optimize dtypes\n",
        "df['int_col'] = df['int_col'].astype('int32')  # Instead of int64\n",
        "df['cat_col'] = df['cat_col'].astype('category')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Quick Reference\n",
        "\n",
        "### Key Operations Covered\n",
        "\n",
        "| Operation | Method | Use Case |\n",
        "|-----------|--------|----------|\n",
        "| **Transform** | `apply()`, `map()` | Create new columns with logic |\n",
        "| **String** | `.str.` methods | Clean and parse text |\n",
        "| **DateTime** | `.dt.` methods | Extract date components |\n",
        "| **Group** | `groupby()`, `agg()` | Summary by category |\n",
        "| **Combine** | `merge()`, `concat()` | Join datasets |\n",
        "| **Reshape** | `pivot_table()`, `melt()` | Change structure |\n",
        "| **Sort** | `sort_values()` | Order data |\n",
        "| **Filter** | Boolean indexing, `query()` | Select rows |\n",
        "| **Window** | `rolling()`, `expanding()` | Moving calculations |\n",
        "| **Create** | `assign()`, `np.where()` | New columns |\n",
        "\n",
        "### Quick Reference Guide\n",
        "\n",
        "**Apply custom function:**\n",
        "```python\n",
        "df['new'] = df['col'].apply(lambda x: x * 2)\n",
        "df['new'] = df.apply(lambda row: row['col1'] + row['col2'], axis=1)\n",
        "```\n",
        "\n",
        "**String operations:**\n",
        "```python\n",
        "df['col'].str.lower().str.strip()\n",
        "df['col'].str.contains('pattern')\n",
        "df['col'].str.split(' ', expand=True)\n",
        "```\n",
        "\n",
        "**DateTime:**\n",
        "```python\n",
        "df['date'].dt.year\n",
        "df['date'].dt.day_name()\n",
        "df['date'].dt.quarter\n",
        "```\n",
        "\n",
        "**GroupBy:**\n",
        "```python\n",
        "df.groupby('col')['value'].sum()\n",
        "df.groupby('col').agg(['sum', 'mean', 'count'])\n",
        "df.groupby(['col1', 'col2'])['value'].sum()\n",
        "```\n",
        "\n",
        "**Merge:**\n",
        "```python\n",
        "pd.merge(df1, df2, on='key', how='inner')\n",
        "pd.concat([df1, df2], axis=0)\n",
        "```\n",
        "\n",
        "**Pivot:**\n",
        "```python\n",
        "df.pivot_table(values='val', index='row', columns='col', aggfunc='sum')\n",
        "```\n",
        "\n",
        "**Filter:**\n",
        "```python\n",
        "df[df['col'] > 100]\n",
        "df[(df['col1'] > 100) & (df['col2'] == 'A')]\n",
        "df.query('col1 > 100 and col2 == \"A\"')\n",
        "```\n",
        "\n",
        "**Window functions:**\n",
        "```python\n",
        "df['rolling_avg'] = df['value'].rolling(window=7).mean()\n",
        "df['cumsum'] = df['value'].cumsum()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Exercises\n",
        "\n",
        "**Try these on your own:**\n",
        "\n",
        "1. Create a pivot table showing average revenue by product and payment method\n",
        "2. Find the top 3 customers in each region by total spend\n",
        "3. Calculate 7-day moving average of daily sales\n",
        "4. Merge customer demographics with sales data\n",
        "5. Create revenue bins (Low, Medium, High) and analyze patterns\n",
        "6. Find month-over-month growth percentage for each product\n",
        "7. Extract customer first names and analyze by first letter\n",
        "8. Calculate cumulative revenue by date\n",
        "9. Find products that are popular on weekends vs weekdays\n",
        "10. Create a function that categorizes orders as \"Bulk\" (qty>5) or \"Regular\"\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "After mastering data manipulation:\n",
        "1. **Data Visualization** (Matplotlib, Seaborn)\n",
        "2. **Advanced Analytics** (Statistics, ML)\n",
        "3. **Time Series Analysis** (Forecasting)\n",
        "4. **Feature Engineering** (For ML models)\n",
        "5. **Big Data** (Dask, PySpark for large datasets)\n",
        "\n",
        "---\n",
        "\n",
        "### Remember:\n",
        "- \ud83c\udfaf **Practice regularly** with real datasets\n",
        "- \ud83d\udcda **Read documentation** - Pandas docs are excellent\n",
        "- \ud83d\udca1 **Think before coding** - Plan your analysis\n",
        "- \ud83d\udc1b **Debug systematically** - Check intermediate results\n",
        "- \ud83d\ude80 **Optimize when needed** - Vectorize, don't loop!\n",
        "\n",
        "**Happy Data Manipulation! \ud83d\udc3c**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}