{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab00253f",
   "metadata": {},
   "source": [
    "# Data Manipulation with Pandas\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Data Manipulation** = Transforming, reshaping, and analyzing data\n",
    "\n",
    "### Key Operations We'll Cover\n",
    "\n",
    "| Category | Operations | Use Case |\n",
    "|----------|------------|----------|\n",
    "| **Transform** | `apply()`, `map()`, `applymap()` | Create new columns, custom logic |\n",
    "| **String** | `.str` methods | Clean text, extract patterns |\n",
    "| **DateTime** | `.dt` methods | Parse dates, extract components |\n",
    "| **Groupby** | `groupby()`, `agg()` | Summary statistics by category |\n",
    "| **Combine** | `merge()`, `join()`, `concat()` | Join multiple datasets |\n",
    "| **Reshape** | `pivot()`, `melt()`, `stack()` | Change data structure |\n",
    "| **Sort** | `sort_values()`, `sort_index()` | Order data |\n",
    "| **Filter** | Boolean indexing, `query()` | Select specific rows |\n",
    "\n",
    "### Why Data Manipulation?\n",
    "- ðŸ“Š **Analysis**: Calculate metrics, trends\n",
    "- ðŸ”„ **Transform**: Prepare data for ML models\n",
    "- ðŸ“ˆ **Insights**: Answer business questions\n",
    "- ðŸŽ¯ **Reporting**: Create summaries, dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3656aad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pandas imported successfully\n",
      "Version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "print(\"âœ… Pandas imported successfully\")\n",
    "print(f\"Version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb7b09b",
   "metadata": {},
   "source": [
    "## Sample Dataset: Sales Data\n",
    "\n",
    "We'll use a realistic sales dataset throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b446f00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sales Data:\n",
      "        date     product     category  quantity  price  customer_name region  \\\n",
      "0 2024-02-21       Phone  Accessories         5    299  Alice Johnson   East   \n",
      "1 2024-04-02      Laptop  Electronics         5   1299     Bob Wilson   East   \n",
      "2 2024-01-15  Headphones  Accessories         7   1999     Emma Davis  South   \n",
      "3 2024-03-12  Headphones  Electronics         9   1299     John Smith   East   \n",
      "4 2024-03-01  Headphones  Electronics         9    299     John Smith   West   \n",
      "5 2024-01-21       Watch  Electronics         3   1299  Michael Brown  North   \n",
      "6 2024-03-23      Laptop  Electronics         3    899     Bob Wilson  South   \n",
      "7 2024-03-27       Watch  Accessories         3   1299     Bob Wilson  South   \n",
      "8 2024-03-15       Watch  Electronics         4    599  Michael Brown   West   \n",
      "9 2024-03-15      Laptop  Electronics         8    599     Emma Davis  North   \n",
      "\n",
      "  payment_method  revenue  \n",
      "0           Cash     1495  \n",
      "1    Credit Card     6495  \n",
      "2     Debit Card    13993  \n",
      "3            UPI    11691  \n",
      "4    Credit Card     2691  \n",
      "5    Credit Card     3897  \n",
      "6     Debit Card     2697  \n",
      "7            UPI     3897  \n",
      "8            UPI     2396  \n",
      "9    Credit Card     4792  \n",
      "\n",
      "Shape: (100, 9)\n",
      "\n",
      "Columns: ['date', 'product', 'category', 'quantity', 'price', 'customer_name', 'region', 'payment_method', 'revenue']\n"
     ]
    }
   ],
   "source": [
    "# Create sample sales data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate dates\n",
    "start_date = datetime(2024, 1, 1)\n",
    "dates = [start_date + timedelta(days=x) for x in range(100)]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': np.random.choice(dates, 100),\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Headphones', 'Watch'], 100),\n",
    "    'category': np.random.choice(['Electronics', 'Accessories'], 100),\n",
    "    'quantity': np.random.randint(1, 10, 100),\n",
    "    'price': np.random.choice([299, 599, 899, 1299, 1999], 100),\n",
    "    'customer_name': np.random.choice(['John Smith', 'Alice Johnson', 'Bob Wilson', \n",
    "                                       'Emma Davis', 'Michael Brown'], 100),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], 100),\n",
    "    'payment_method': np.random.choice(['Credit Card', 'Debit Card', 'UPI', 'Cash'], 100)\n",
    "})\n",
    "\n",
    "# Calculate revenue\n",
    "df['revenue'] = df['quantity'] * df['price']\n",
    "\n",
    "print(\"Sample Sales Data:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15441a45",
   "metadata": {},
   "source": [
    "## 1. Transform Functions: apply(), map(), applymap()\n",
    "\n",
    "### Differences\n",
    "\n",
    "| Method | Works On | Purpose | Example |\n",
    "|--------|----------|---------|----------|\n",
    "| **`apply()`** | Series/DataFrame | Apply function to rows/columns | Calculate tax, categorize |\n",
    "| **`map()`** | Series only | Replace values, map dict | Category encoding |\n",
    "| **`applymap()`** | DataFrame | Apply to every cell | Format entire DataFrame |\n",
    "\n",
    "### When to Use\n",
    "- **`apply()`**: Custom calculations (commission, discounts)\n",
    "- **`map()`**: Simple value mapping (category codes)\n",
    "- **`applymap()`**: Format all cells (rarely used)\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "# apply() on Series\n",
    "df['column'].apply(function)\n",
    "\n",
    "# apply() on DataFrame\n",
    "df.apply(function, axis=0)  # axis=0: column-wise, axis=1: row-wise\n",
    "\n",
    "# map() on Series\n",
    "df['column'].map(mapping_dict)\n",
    "\n",
    "# applymap() on DataFrame\n",
    "df.applymap(function)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5fe3d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APPLY() EXAMPLES ===\n",
      "\n",
      "Example 1: Calculate 18% tax on revenue\n",
      "   revenue      tax\n",
      "0     1495   269.10\n",
      "1     6495  1169.10\n",
      "2    13993  2518.74\n",
      "3    11691  2104.38\n",
      "4     2691   484.38\n",
      "\n",
      "Example 2: Categorize revenue (High/Medium/Low)\n",
      "   revenue revenue_category\n",
      "0     1495              Low\n",
      "1     6495           Medium\n",
      "2    13993             High\n",
      "3    11691             High\n",
      "4     2691              Low\n",
      "\n",
      "Example 3: Calculate discount based on quantity and price\n",
      "   quantity  price  revenue  discount\n",
      "0         5    299     1495    149.50\n",
      "1         5   1299     6495    649.50\n",
      "2         7   1999    13993   1399.30\n",
      "3         9   1299    11691   1169.10\n",
      "4         9    299     2691    269.10\n",
      "5         3   1299     3897    194.85\n",
      "6         3    899     2697      0.00\n",
      "7         3   1299     3897    194.85\n",
      "8         4    599     2396      0.00\n",
      "9         8    599     4792    479.20\n",
      "\n",
      "Example 4: Calculate total sum per column\n",
      "Column Totals:\n",
      "quantity       475\n",
      "price       109900\n",
      "revenue     522425\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=== APPLY() EXAMPLES ===\\n\")\n",
    "\n",
    "# Example 1: Apply function to Series\n",
    "print(\"Example 1: Calculate 18% tax on revenue\")\n",
    "df['tax'] = df['revenue'].apply(lambda x: x * 0.18)\n",
    "print(df[['revenue', 'tax']].head())\n",
    "print()\n",
    "\n",
    "# Example 2: Apply custom function\n",
    "print(\"Example 2: Categorize revenue (High/Medium/Low)\")\n",
    "def categorize_revenue(revenue):\n",
    "    if revenue > 10000:\n",
    "        return 'High'\n",
    "    elif revenue > 5000:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "df['revenue_category'] = df['revenue'].apply(categorize_revenue)\n",
    "print(df[['revenue', 'revenue_category']].head())\n",
    "print()\n",
    "\n",
    "# Example 3: Apply to DataFrame rows (axis=1)\n",
    "print(\"Example 3: Calculate discount based on quantity and price\")\n",
    "def calculate_discount(row):\n",
    "    if row['quantity'] >= 5:\n",
    "        return row['revenue'] * 0.10  # 10% discount for bulk\n",
    "    elif row['price'] > 1000:\n",
    "        return row['revenue'] * 0.05  # 5% for expensive items\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['discount'] = df.apply(calculate_discount, axis=1)\n",
    "print(df[['quantity', 'price', 'revenue', 'discount']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 4: Apply to column\n",
    "print(\"Example 4: Calculate total sum per column\")\n",
    "numeric_cols = df[['quantity', 'price', 'revenue']]\n",
    "totals = numeric_cols.apply(sum, axis=0)\n",
    "print(\"Column Totals:\")\n",
    "print(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0c4361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MAP() EXAMPLES ===\n",
      "\n",
      "Example 1: Map payment method to codes\n",
      "  payment_method payment_code\n",
      "0           Cash           CA\n",
      "1    Credit Card           CC\n",
      "2     Debit Card           DC\n",
      "3            UPI           UP\n",
      "4    Credit Card           CC\n",
      "\n",
      "Example 2: Convert product names to uppercase\n",
      "      product product_upper\n",
      "0       Phone         PHONE\n",
      "1      Laptop        LAPTOP\n",
      "2  Headphones    HEADPHONES\n",
      "3  Headphones    HEADPHONES\n",
      "4  Headphones    HEADPHONES\n",
      "\n",
      "Example 3: Map price to price range\n",
      "   price  price_range\n",
      "0    299    $199-$399\n",
      "1   1299  $1199-$1399\n",
      "2   1999  $1899-$2099\n",
      "3   1299  $1199-$1399\n",
      "4    299    $199-$399\n",
      "\n",
      "Example 4: map() vs apply() - Performance\n",
      "map() is faster for simple value replacements\n",
      "apply() is more flexible for complex logic\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MAP() EXAMPLES ===\\n\")\n",
    "\n",
    "# Example 1: Map with dictionary\n",
    "print(\"Example 1: Map payment method to codes\")\n",
    "payment_mapping = {\n",
    "    'Credit Card': 'CC',\n",
    "    'Debit Card': 'DC',\n",
    "    'UPI': 'UP',\n",
    "    'Cash': 'CA'\n",
    "}\n",
    "\n",
    "df['payment_code'] = df['payment_method'].map(payment_mapping)\n",
    "print(df[['payment_method', 'payment_code']].head())\n",
    "print()\n",
    "\n",
    "# Example 2: Map with function\n",
    "print(\"Example 2: Convert product names to uppercase\")\n",
    "df['product_upper'] = df['product'].map(str.upper)\n",
    "print(df[['product', 'product_upper']].head())\n",
    "print()\n",
    "\n",
    "# Example 3: Map with lambda\n",
    "print(\"Example 3: Map price to price range\")\n",
    "df['price_range'] = df['price'].map(lambda x: f\"${x-100}-${x+100}\")\n",
    "print(df[['price', 'price_range']].head())\n",
    "print()\n",
    "\n",
    "# Example 4: Map vs Apply comparison\n",
    "print(\"Example 4: map() vs apply() - Performance\")\n",
    "print(\"map() is faster for simple value replacements\")\n",
    "print(\"apply() is more flexible for complex logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da85bf3",
   "metadata": {},
   "source": [
    "## 2. String Operations (.str methods)\n",
    "\n",
    "### Common String Methods\n",
    "\n",
    "| Method | Purpose | Example |\n",
    "|--------|---------|----------|\n",
    "| `.str.lower()` | Lowercase | 'HELLO' â†’ 'hello' |\n",
    "| `.str.upper()` | Uppercase | 'hello' â†’ 'HELLO' |\n",
    "| `.str.title()` | Title Case | 'john smith' â†’ 'John Smith' |\n",
    "| `.str.strip()` | Remove whitespace | ' text ' â†’ 'text' |\n",
    "| `.str.replace()` | Replace text | 'hello' â†’ 'hi' |\n",
    "| `.str.contains()` | Check if contains | Check if 'Smith' in name |\n",
    "| `.str.startswith()` | Starts with | Check if starts with 'J' |\n",
    "| `.str.endswith()` | Ends with | Check if ends with '.com' |\n",
    "| `.str.split()` | Split string | 'John Smith' â†’ ['John', 'Smith'] |\n",
    "| `.str.len()` | String length | 'hello' â†’ 5 |\n",
    "| `.str.extract()` | Extract pattern | Extract digits from text |\n",
    "| `.str.slice()` | Slice string | Get first 3 characters |\n",
    "\n",
    "### Real-World Use Cases\n",
    "- Clean customer names\n",
    "- Extract email domains\n",
    "- Parse product codes\n",
    "- Validate phone numbers\n",
    "- Standardize addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4025c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STRING OPERATIONS ===\n",
      "\n",
      "Example 1: Basic string transformations\n",
      "Original names:\n",
      "0    Alice Johnson\n",
      "1       Bob Wilson\n",
      "2       Emma Davis\n",
      "3       John Smith\n",
      "4       John Smith\n",
      "Name: customer_name, dtype: object\n",
      "\n",
      "Uppercase:\n",
      "0    ALICE JOHNSON\n",
      "1       BOB WILSON\n",
      "2       EMMA DAVIS\n",
      "3       JOHN SMITH\n",
      "4       JOHN SMITH\n",
      "Name: customer_name, dtype: object\n",
      "\n",
      "Lowercase:\n",
      "0    alice johnson\n",
      "1       bob wilson\n",
      "2       emma davis\n",
      "3       john smith\n",
      "4       john smith\n",
      "Name: customer_name, dtype: object\n",
      "\n",
      "Example 2: Calculate name length\n",
      "   customer_name  name_length\n",
      "0  Alice Johnson           13\n",
      "1     Bob Wilson           10\n",
      "2     Emma Davis           10\n",
      "3     John Smith           10\n",
      "4     John Smith           10\n",
      "\n",
      "Example 3: Filter customers with 'Smith' in name\n",
      "Found 22 customers with 'Smith'\n",
      "  customer_name\n",
      "3    John Smith\n",
      "\n",
      "Example 4: Split customer names into first and last\n",
      "   customer_name first_name last_name\n",
      "0  Alice Johnson      Alice   Johnson\n",
      "1     Bob Wilson        Bob    Wilson\n",
      "2     Emma Davis       Emma     Davis\n",
      "3     John Smith       John     Smith\n",
      "4     John Smith       John     Smith\n",
      "\n",
      "Example 5: Extract first 3 characters of product name\n",
      "      product product_code\n",
      "0       Phone          PHO\n",
      "1      Laptop          LAP\n",
      "2  Headphones          HEA\n",
      "3  Headphones          HEA\n",
      "4  Headphones          HEA\n",
      "\n",
      "Example 6: Products starting with 'L'\n",
      "Products starting with 'L': 1\n",
      "['Laptop']\n",
      "\n",
      "Example 7: Replace 'Phone' with 'Smartphone'\n",
      "      product product_renamed\n",
      "0       Phone      Smartphone\n",
      "1      Laptop          Laptop\n",
      "2  Headphones      Headphones\n",
      "3  Headphones      Headphones\n",
      "4  Headphones      Headphones\n"
     ]
    }
   ],
   "source": [
    "print(\"=== STRING OPERATIONS ===\\n\")\n",
    "\n",
    "# Example 1: Basic transformations\n",
    "print(\"Example 1: Basic string transformations\")\n",
    "print(\"Original names:\")\n",
    "print(df['customer_name'].head())\n",
    "print()\n",
    "print(\"Uppercase:\")\n",
    "print(df['customer_name'].str.upper().head())\n",
    "print()\n",
    "print(\"Lowercase:\")\n",
    "print(df['customer_name'].str.lower().head())\n",
    "print()\n",
    "\n",
    "# Example 2: String length\n",
    "print(\"Example 2: Calculate name length\")\n",
    "df['name_length'] = df['customer_name'].str.len()\n",
    "print(df[['customer_name', 'name_length']].head())\n",
    "print()\n",
    "\n",
    "# Example 3: Contains\n",
    "print(\"Example 3: Filter customers with 'Smith' in name\")\n",
    "smith_customers = df[df['customer_name'].str.contains('Smith', case=False)]\n",
    "print(f\"Found {len(smith_customers)} customers with 'Smith'\")\n",
    "print(smith_customers[['customer_name']].drop_duplicates())\n",
    "print()\n",
    "\n",
    "# Example 4: Split names\n",
    "print(\"Example 4: Split customer names into first and last\")\n",
    "df[['first_name', 'last_name']] = df['customer_name'].str.split(' ', n=1, expand=True)\n",
    "print(df[['customer_name', 'first_name', 'last_name']].head())\n",
    "print()\n",
    "\n",
    "# Example 5: String slicing\n",
    "print(\"Example 5: Extract first 3 characters of product name\")\n",
    "df['product_code'] = df['product'].str.slice(0, 3).str.upper()\n",
    "print(df[['product', 'product_code']].head())\n",
    "print()\n",
    "\n",
    "# Example 6: Starts with\n",
    "print(\"Example 6: Products starting with 'L'\")\n",
    "l_products = df[df['product'].str.startswith('L')]\n",
    "print(f\"Products starting with 'L': {l_products['product'].nunique()}\")\n",
    "print(l_products['product'].unique())\n",
    "print()\n",
    "\n",
    "# Example 7: Replace\n",
    "print(\"Example 7: Replace 'Phone' with 'Smartphone'\")\n",
    "df['product_renamed'] = df['product'].str.replace('Phone', 'Smartphone')\n",
    "print(df[['product', 'product_renamed']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df21c6",
   "metadata": {},
   "source": [
    "## 3. DateTime Operations (.dt methods)\n",
    "\n",
    "### Common DateTime Methods\n",
    "\n",
    "| Method | Purpose | Example |\n",
    "|--------|---------|----------|\n",
    "| `.dt.year` | Extract year | 2024 |\n",
    "| `.dt.month` | Extract month | 3 (March) |\n",
    "| `.dt.day` | Extract day | 15 |\n",
    "| `.dt.dayofweek` | Day of week | 0=Monday, 6=Sunday |\n",
    "| `.dt.day_name()` | Day name | 'Monday' |\n",
    "| `.dt.month_name()` | Month name | 'March' |\n",
    "| `.dt.quarter` | Quarter | 1, 2, 3, 4 |\n",
    "| `.dt.week` | Week number | 1-52 |\n",
    "| `.dt.weekday` | Weekday | 0-6 |\n",
    "| `.dt.is_month_end` | Is month end | True/False |\n",
    "| `.dt.is_month_start` | Is month start | True/False |\n",
    "| `.dt.date` | Date only | 2024-03-15 |\n",
    "\n",
    "### Time Calculations\n",
    "```python\n",
    "# Date arithmetic\n",
    "df['date'] + pd.Timedelta(days=7)  # Add 7 days\n",
    "df['date2'] - df['date1']  # Date difference\n",
    "\n",
    "# Date ranges\n",
    "pd.date_range('2024-01-01', periods=10, freq='D')\n",
    "```\n",
    "\n",
    "### Real-World Use Cases\n",
    "- Sales by month/quarter\n",
    "- Weekday vs weekend analysis\n",
    "- Time-based filtering\n",
    "- Calculate age, tenure\n",
    "- Seasonality analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0004c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATETIME OPERATIONS ===\n",
      "\n",
      "Example 1: Extract date components\n",
      "        date  year  month  day   day_name month_name\n",
      "0 2024-02-21  2024      2   21  Wednesday   February\n",
      "1 2024-04-02  2024      4    2    Tuesday      April\n",
      "2 2024-01-15  2024      1   15     Monday    January\n",
      "3 2024-03-12  2024      3   12    Tuesday      March\n",
      "4 2024-03-01  2024      3    1     Friday      March\n",
      "\n",
      "Example 2: Analyze weekday patterns\n",
      "        date   day_name  is_weekend\n",
      "0 2024-02-21  Wednesday       False\n",
      "1 2024-04-02    Tuesday       False\n",
      "2 2024-01-15     Monday       False\n",
      "3 2024-03-12    Tuesday       False\n",
      "4 2024-03-01     Friday       False\n",
      "\n",
      "Weekend sales: $117,389.00\n",
      "Weekday sales: $405,036.00\n",
      "\n",
      "Example 3: Extract quarter\n",
      "        date  quarter\n",
      "0 2024-02-21        1\n",
      "1 2024-04-02        2\n",
      "2 2024-01-15        1\n",
      "3 2024-03-12        1\n",
      "4 2024-03-01        1\n",
      "\n",
      "Example 4: Filter sales in March 2024\n",
      "March sales count: 35\n",
      "March revenue: $206,820.00\n",
      "\n",
      "Example 5: Calculate days since first sale\n",
      "        date  days_since_first_sale\n",
      "0 2024-02-21                     50\n",
      "1 2024-04-02                     91\n",
      "2 2024-01-15                     13\n",
      "3 2024-03-12                     70\n",
      "4 2024-03-01                     59\n",
      "\n",
      "Example 6: Add 7 days to all dates (delivery date)\n",
      "        date delivery_date\n",
      "0 2024-02-21    2024-02-28\n",
      "1 2024-04-02    2024-04-09\n",
      "2 2024-01-15    2024-01-22\n",
      "3 2024-03-12    2024-03-19\n",
      "4 2024-03-01    2024-03-08\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATETIME OPERATIONS ===\\n\")\n",
    "\n",
    "# Ensure date column is datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Example 1: Extract components\n",
    "print(\"Example 1: Extract date components\")\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['day_name'] = df['date'].dt.day_name()\n",
    "df['month_name'] = df['date'].dt.month_name()\n",
    "\n",
    "print(df[['date', 'year', 'month', 'day', 'day_name', 'month_name']].head())\n",
    "print()\n",
    "\n",
    "# Example 2: Day of week (0=Monday, 6=Sunday)\n",
    "print(\"Example 2: Analyze weekday patterns\")\n",
    "df['is_weekend'] = df['date'].dt.dayofweek >= 5\n",
    "print(df[['date', 'day_name', 'is_weekend']].head())\n",
    "print()\n",
    "\n",
    "weekend_sales = df[df['is_weekend']]['revenue'].sum()\n",
    "weekday_sales = df[~df['is_weekend']]['revenue'].sum()\n",
    "print(f\"Weekend sales: ${weekend_sales:,.2f}\")\n",
    "print(f\"Weekday sales: ${weekday_sales:,.2f}\")\n",
    "print()\n",
    "\n",
    "# Example 3: Quarter\n",
    "print(\"Example 3: Extract quarter\")\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "print(df[['date', 'quarter']].head())\n",
    "print()\n",
    "\n",
    "# Example 4: Date filtering\n",
    "print(\"Example 4: Filter sales in March 2024\")\n",
    "march_sales = df[(df['date'].dt.month == 3) & (df['date'].dt.year == 2024)]\n",
    "print(f\"March sales count: {len(march_sales)}\")\n",
    "print(f\"March revenue: ${march_sales['revenue'].sum():,.2f}\")\n",
    "print()\n",
    "\n",
    "# Example 5: Calculate days since first sale\n",
    "print(\"Example 5: Calculate days since first sale\")\n",
    "first_sale_date = df['date'].min()\n",
    "df['days_since_first_sale'] = (df['date'] - first_sale_date).dt.days\n",
    "print(df[['date', 'days_since_first_sale']].head())\n",
    "print()\n",
    "\n",
    "# Example 6: Date arithmetic\n",
    "print(\"Example 6: Add 7 days to all dates (delivery date)\")\n",
    "df['delivery_date'] = df['date'] + pd.Timedelta(days=7)\n",
    "print(df[['date', 'delivery_date']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a73826",
   "metadata": {},
   "source": [
    "## 4. GroupBy and Aggregations\n",
    "\n",
    "### What is GroupBy?\n",
    "\n",
    "**GroupBy** = Split-Apply-Combine pattern\n",
    "1. **Split**: Divide data into groups\n",
    "2. **Apply**: Apply function to each group\n",
    "3. **Combine**: Combine results\n",
    "\n",
    "```python\n",
    "df.groupby('column').agg(function)\n",
    "```\n",
    "\n",
    "### Common Aggregation Functions\n",
    "\n",
    "| Function | Purpose | Example |\n",
    "|----------|---------|----------|\n",
    "| `sum()` | Total | Total revenue by product |\n",
    "| `mean()` | Average | Average price by region |\n",
    "| `median()` | Middle value | Median revenue |\n",
    "| `count()` | Count | Number of sales |\n",
    "| `nunique()` | Unique count | Unique customers |\n",
    "| `min()` | Minimum | Lowest price |\n",
    "| `max()` | Maximum | Highest revenue |\n",
    "| `std()` | Standard deviation | Revenue variability |\n",
    "| `var()` | Variance | Price variance |\n",
    "| `first()` | First value | First sale date |\n",
    "| `last()` | Last value | Last sale date |\n",
    "\n",
    "### Multiple Aggregations\n",
    "\n",
    "```python\n",
    "# Single aggregation\n",
    "df.groupby('product')['revenue'].sum()\n",
    "\n",
    "# Multiple aggregations\n",
    "df.groupby('product')['revenue'].agg(['sum', 'mean', 'count'])\n",
    "\n",
    "# Different aggregations per column\n",
    "df.groupby('product').agg({\n",
    "    'revenue': ['sum', 'mean'],\n",
    "    'quantity': ['sum', 'max']\n",
    "})\n",
    "```\n",
    "\n",
    "### Real-World Use Cases\n",
    "- Sales by product/region/month\n",
    "- Customer lifetime value\n",
    "- Regional performance\n",
    "- Product performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bd6e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GROUPBY OPERATIONS ===\n",
      "\n",
      "Example 1: Total revenue by product\n",
      "product\n",
      "Headphones    140180\n",
      "Laptop        120877\n",
      "Tablet        106011\n",
      "Watch          94220\n",
      "Phone          61137\n",
      "Name: revenue, dtype: int64\n",
      "\n",
      "Example 2: Product statistics\n",
      "             Total  Average  Count    Max  Min\n",
      "product                                       \n",
      "Headphones  140180  6094.78     23  17991  598\n",
      "Laptop      120877  4476.93     27  17991  599\n",
      "Phone        61137  5094.75     12  13993  299\n",
      "Tablet      106011  5048.14     21  11994  599\n",
      "Watch        94220  5542.35     17  15992  299\n",
      "\n",
      "Example 3: Revenue by product and region\n",
      "product     region\n",
      "Headphones  East      66147\n",
      "Laptop      North     49059\n",
      "            East      47367\n",
      "Tablet      North     41070\n",
      "Phone       West      40566\n",
      "Tablet      South     40372\n",
      "Headphones  South     38868\n",
      "Watch       North     38165\n",
      "            South     32778\n",
      "Headphones  West      28177\n",
      "Name: revenue, dtype: int64\n",
      "\n",
      "Example 4: Complex aggregations\n",
      "           revenue          quantity     customer_name\n",
      "               sum     mean      sum max       nunique\n",
      "product                                               \n",
      "Headphones  140180  6094.78      120   9             5\n",
      "Laptop      120877  4476.93      123   9             5\n",
      "Phone        61137  5094.75       63   9             5\n",
      "Tablet      106011  5048.14       89   8             5\n",
      "Watch        94220  5542.35       80   9             5\n",
      "\n",
      "Example 5: Custom aggregation - Revenue range\n",
      "             Total  Average  Range\n",
      "product                           \n",
      "Headphones  140180  6094.78  17393\n",
      "Laptop      120877  4476.93  17392\n",
      "Phone        61137  5094.75  13694\n",
      "Tablet      106011  5048.14  11395\n",
      "Watch        94220  5542.35  15693\n",
      "\n",
      "Example 6: Monthly sales trend\n",
      "         Total_Revenue  Num_Orders  Avg_Order_Value\n",
      "date                                               \n",
      "2024-01         138475          28          4945.54\n",
      "2024-02         145359          30          4845.30\n",
      "2024-03         206820          35          5909.14\n",
      "2024-04          31771           7          4538.71\n",
      "\n",
      "Example 7: Products with total revenue > $50,000\n",
      "product\n",
      "Headphones    140180\n",
      "Laptop        120877\n",
      "Phone          61137\n",
      "Tablet        106011\n",
      "Watch          94220\n",
      "Name: revenue, dtype: int64\n",
      "\n",
      "Example 8: Add group average to each row\n",
      "      product  revenue  product_avg_revenue\n",
      "0       Phone     1495              5094.75\n",
      "1      Laptop     6495              4476.93\n",
      "2  Headphones    13993              6094.78\n",
      "3  Headphones    11691              6094.78\n",
      "4  Headphones     2691              6094.78\n",
      "\n",
      "Example 9: Rank sales within each product\n",
      "      product  revenue  revenue_rank\n",
      "0       Phone     1495           8.0\n",
      "1      Laptop     6495           5.0\n",
      "2  Headphones    13993           3.0\n",
      "3  Headphones    11691           4.0\n",
      "4  Headphones     2691          12.0\n",
      "5       Watch     3897           9.0\n",
      "6      Laptop     2697          10.0\n",
      "7       Watch     3897           9.0\n",
      "8       Watch     2396          12.0\n",
      "9      Laptop     4792           9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== GROUPBY OPERATIONS ===\\n\")\n",
    "\n",
    "# Example 1: Simple groupby\n",
    "print(\"Example 1: Total revenue by product\")\n",
    "product_revenue = df.groupby('product')['revenue'].sum().sort_values(ascending=False)\n",
    "print(product_revenue)\n",
    "print()\n",
    "\n",
    "# Example 2: Multiple aggregations\n",
    "print(\"Example 2: Product statistics\")\n",
    "product_stats = df.groupby('product')['revenue'].agg(['sum', 'mean', 'count', 'max', 'min'])\n",
    "product_stats.columns = ['Total', 'Average', 'Count', 'Max', 'Min']\n",
    "print(product_stats)\n",
    "print()\n",
    "\n",
    "# Example 3: Group by multiple columns\n",
    "print(\"Example 3: Revenue by product and region\")\n",
    "product_region = df.groupby(['product', 'region'])['revenue'].sum().sort_values(ascending=False)\n",
    "print(product_region.head(10))\n",
    "print()\n",
    "\n",
    "# Example 4: Different aggregations per column\n",
    "print(\"Example 4: Complex aggregations\")\n",
    "complex_agg = df.groupby('product').agg({\n",
    "    'revenue': ['sum', 'mean'],\n",
    "    'quantity': ['sum', 'max'],\n",
    "    'customer_name': 'nunique'  # Unique customers\n",
    "})\n",
    "print(complex_agg)\n",
    "print()\n",
    "\n",
    "# Example 5: Custom aggregation function\n",
    "print(\"Example 5: Custom aggregation - Revenue range\")\n",
    "def revenue_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "revenue_ranges = df.groupby('product')['revenue'].agg([\n",
    "    ('Total', 'sum'),\n",
    "    ('Average', 'mean'),\n",
    "    ('Range', revenue_range)\n",
    "])\n",
    "print(revenue_ranges)\n",
    "print()\n",
    "\n",
    "# Example 6: Group by date components\n",
    "print(\"Example 6: Monthly sales trend\")\n",
    "monthly_sales = df.groupby(df['date'].dt.to_period('M'))['revenue'].agg([\n",
    "    ('Total_Revenue', 'sum'),\n",
    "    ('Num_Orders', 'count'),\n",
    "    ('Avg_Order_Value', 'mean')\n",
    "])\n",
    "print(monthly_sales.head())\n",
    "print()\n",
    "\n",
    "# Example 7: Filter groups\n",
    "print(\"Example 7: Products with total revenue > $50,000\")\n",
    "high_revenue_products = df.groupby('product')['revenue'].sum()\n",
    "high_revenue_products = high_revenue_products[high_revenue_products > 50000]\n",
    "print(high_revenue_products)\n",
    "print()\n",
    "\n",
    "# Example 8: Transform (keep original DataFrame size)\n",
    "print(\"Example 8: Add group average to each row\")\n",
    "df['product_avg_revenue'] = df.groupby('product')['revenue'].transform('mean')\n",
    "print(df[['product', 'revenue', 'product_avg_revenue']].head())\n",
    "print()\n",
    "\n",
    "# Example 9: Rank within groups\n",
    "print(\"Example 9: Rank sales within each product\")\n",
    "df['revenue_rank'] = df.groupby('product')['revenue'].rank(ascending=False, method='dense')\n",
    "print(df[['product', 'revenue', 'revenue_rank']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76261573",
   "metadata": {},
   "source": [
    "## 5. Combining DataFrames: merge(), join(), concat()\n",
    "\n",
    "### Types of Joins\n",
    "\n",
    "| Join Type | Description | SQL Equivalent |\n",
    "|-----------|-------------|----------------|\n",
    "| **inner** | Only matching rows | INNER JOIN |\n",
    "| **left** | All from left, matching from right | LEFT JOIN |\n",
    "| **right** | All from right, matching from left | RIGHT JOIN |\n",
    "| **outer** | All rows from both | FULL OUTER JOIN |\n",
    "\n",
    "### Methods\n",
    "\n",
    "**1. merge()** - SQL-style joins\n",
    "```python\n",
    "pd.merge(df1, df2, on='key', how='inner')\n",
    "```\n",
    "\n",
    "**2. join()** - Join on index\n",
    "```python\n",
    "df1.join(df2, how='left')\n",
    "```\n",
    "\n",
    "**3. concat()** - Stack DataFrames\n",
    "```python\n",
    "pd.concat([df1, df2], axis=0)  # Vertical stack\n",
    "pd.concat([df1, df2], axis=1)  # Horizontal stack\n",
    "```\n",
    "\n",
    "### Real-World Use Cases\n",
    "- Join customer data with orders\n",
    "- Merge product catalog with sales\n",
    "- Combine regional datasets\n",
    "- Add demographic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733765d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMBINING DATAFRAMES ===\n",
      "\n",
      "Creating sample datasets...\n",
      "\n",
      "Customers DataFrame:\n",
      "   customer_name  customer_id              email loyalty_level\n",
      "0     John Smith          101     john@email.com          Gold\n",
      "1  Alice Johnson          102    alice@email.com        Silver\n",
      "2     Bob Wilson          103      bob@email.com      Platinum\n",
      "3     Emma Davis          104     emma@email.com          Gold\n",
      "4  Michael Brown          105  michael@email.com        Bronze\n",
      "\n",
      "Products DataFrame:\n",
      "      product    brand  warranty_months\n",
      "0      Laptop     Dell               24\n",
      "1       Phone    Apple               12\n",
      "2      Tablet  Samsung               12\n",
      "3  Headphones     Sony                6\n",
      "4       Watch    Apple               12\n",
      "\n",
      "Example 1: INNER MERGE - Sales with customer info\n",
      "   customer_name            email loyalty_level  revenue\n",
      "0  Alice Johnson  alice@email.com        Silver     1495\n",
      "1     Bob Wilson    bob@email.com      Platinum     6495\n",
      "2     Emma Davis   emma@email.com          Gold    13993\n",
      "3     John Smith   john@email.com          Gold    11691\n",
      "4     John Smith   john@email.com          Gold     2691\n",
      "Rows: 100 â†’ 100\n",
      "\n",
      "Example 2: LEFT MERGE - Sales with product info\n",
      "      product  brand  warranty_months  revenue\n",
      "0       Phone  Apple               12     1495\n",
      "1      Laptop   Dell               24     6495\n",
      "2  Headphones   Sony                6    13993\n",
      "3  Headphones   Sony                6    11691\n",
      "4  Headphones   Sony                6     2691\n",
      "\n",
      "Example 3: Merge on multiple keys\n",
      "      product region  revenue  regional_discount\n",
      "0       Phone   East     1495                NaN\n",
      "1      Laptop   East     6495                NaN\n",
      "2  Headphones  South    13993                NaN\n",
      "3  Headphones   East    11691                NaN\n",
      "4  Headphones   West     2691                NaN\n",
      "\n",
      "Example 4: CONCAT - Stack DataFrames vertically\n",
      "df1: 5 rows, df2: 5 rows\n",
      "Stacked: 10 rows\n",
      "\n",
      "Example 5: CONCAT - Stack DataFrames horizontally\n",
      "      product  quantity  price  revenue\n",
      "0       Phone         5    299     1495\n",
      "1      Laptop         5   1299     6495\n",
      "2  Headphones         7   1999    13993\n",
      "3  Headphones         9   1299    11691\n",
      "4  Headphones         9    299     2691\n",
      "\n",
      "Example 6: Merge with indicator (shows merge source)\n",
      "   customer_name loyalty_level _merge\n",
      "0  Alice Johnson        Silver   both\n",
      "1     Bob Wilson      Platinum   both\n",
      "2     Emma Davis          Gold   both\n",
      "3     John Smith          Gold   both\n",
      "4     John Smith          Gold   both\n",
      "\n",
      "_merge column values:\n",
      "  - 'both': Found in both DataFrames\n",
      "  - 'left_only': Only in left DataFrame\n",
      "  - 'right_only': Only in right DataFrame\n"
     ]
    }
   ],
   "source": [
    "print(\"=== COMBINING DATAFRAMES ===\\n\")\n",
    "\n",
    "# Create additional datasets for merging\n",
    "print(\"Creating sample datasets...\\n\")\n",
    "\n",
    "# Customer info dataset\n",
    "customers = pd.DataFrame({\n",
    "    'customer_name': ['John Smith', 'Alice Johnson', 'Bob Wilson', 'Emma Davis', 'Michael Brown'],\n",
    "    'customer_id': [101, 102, 103, 104, 105],\n",
    "    'email': ['john@email.com', 'alice@email.com', 'bob@email.com', \n",
    "              'emma@email.com', 'michael@email.com'],\n",
    "    'loyalty_level': ['Gold', 'Silver', 'Platinum', 'Gold', 'Bronze']\n",
    "})\n",
    "\n",
    "# Product info dataset\n",
    "products = pd.DataFrame({\n",
    "    'product': ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Watch'],\n",
    "    'brand': ['Dell', 'Apple', 'Samsung', 'Sony', 'Apple'],\n",
    "    'warranty_months': [24, 12, 12, 6, 12]\n",
    "})\n",
    "\n",
    "print(\"Customers DataFrame:\")\n",
    "print(customers)\n",
    "print()\n",
    "print(\"Products DataFrame:\")\n",
    "print(products)\n",
    "print()\n",
    "\n",
    "# Example 1: Inner merge\n",
    "print(\"Example 1: INNER MERGE - Sales with customer info\")\n",
    "sales_with_customers = pd.merge(df, customers, on='customer_name', how='inner')\n",
    "print(sales_with_customers[['customer_name', 'email', 'loyalty_level', 'revenue']].head())\n",
    "print(f\"Rows: {len(df)} â†’ {len(sales_with_customers)}\")\n",
    "print()\n",
    "\n",
    "# Example 2: Left merge\n",
    "print(\"Example 2: LEFT MERGE - Sales with product info\")\n",
    "sales_with_products = pd.merge(df, products, on='product', how='left')\n",
    "print(sales_with_products[['product', 'brand', 'warranty_months', 'revenue']].head())\n",
    "print()\n",
    "\n",
    "# Example 3: Merge on multiple columns\n",
    "print(\"Example 3: Merge on multiple keys\")\n",
    "# Create sample with multiple keys\n",
    "df_subset = df[['product', 'region', 'revenue']].head()\n",
    "region_info = pd.DataFrame({\n",
    "    'product': ['Laptop', 'Phone', 'Laptop'],\n",
    "    'region': ['North', 'North', 'South'],\n",
    "    'regional_discount': [0.05, 0.03, 0.10]\n",
    "})\n",
    "\n",
    "merged = pd.merge(df_subset, region_info, on=['product', 'region'], how='left')\n",
    "print(merged)\n",
    "print()\n",
    "\n",
    "# Example 4: concat() - Vertical stack\n",
    "print(\"Example 4: CONCAT - Stack DataFrames vertically\")\n",
    "df1 = df.head(5)\n",
    "df2 = df.tail(5)\n",
    "stacked = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "print(f\"df1: {len(df1)} rows, df2: {len(df2)} rows\")\n",
    "print(f\"Stacked: {len(stacked)} rows\")\n",
    "print()\n",
    "\n",
    "# Example 5: concat() - Horizontal stack\n",
    "print(\"Example 5: CONCAT - Stack DataFrames horizontally\")\n",
    "df_left = df[['product', 'quantity']].head()\n",
    "df_right = df[['price', 'revenue']].head()\n",
    "h_stacked = pd.concat([df_left, df_right], axis=1)\n",
    "print(h_stacked)\n",
    "print()\n",
    "\n",
    "# Example 6: merge with indicator\n",
    "print(\"Example 6: Merge with indicator (shows merge source)\")\n",
    "merged_indicator = pd.merge(df.head(5), customers, on='customer_name', \n",
    "                            how='outer', indicator=True)\n",
    "print(merged_indicator[['customer_name', 'loyalty_level', '_merge']].head())\n",
    "print(\"\\n_merge column values:\")\n",
    "print(\"  - 'both': Found in both DataFrames\")\n",
    "print(\"  - 'left_only': Only in left DataFrame\")\n",
    "print(\"  - 'right_only': Only in right DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c8d03",
   "metadata": {},
   "source": [
    "## 6. Pivot Tables and Reshaping\n",
    "\n",
    "### Pivot Table\n",
    "\n",
    "**Pivot** = Reshape data from long to wide format\n",
    "\n",
    "```python\n",
    "df.pivot_table(\n",
    "    values='column_to_aggregate',\n",
    "    index='row_labels',\n",
    "    columns='column_labels',\n",
    "    aggfunc='mean'  # or sum, count, etc.\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "| Parameter | Purpose | Example |\n",
    "|-----------|---------|----------|\n",
    "| `values` | Column to aggregate | 'revenue' |\n",
    "| `index` | Row labels | 'product' |\n",
    "| `columns` | Column labels | 'region' |\n",
    "| `aggfunc` | Aggregation function | 'sum', 'mean', 'count' |\n",
    "| `fill_value` | Fill missing values | 0 |\n",
    "| `margins` | Add row/column totals | True |\n",
    "\n",
    "### Related Operations\n",
    "\n",
    "**melt()** - Unpivot (wide to long)\n",
    "```python\n",
    "pd.melt(df, id_vars=['id'], value_vars=['col1', 'col2'])\n",
    "```\n",
    "\n",
    "**stack()** - Pivot column labels to row index\n",
    "```python\n",
    "df.stack()\n",
    "```\n",
    "\n",
    "**unstack()** - Pivot row index to column labels\n",
    "```python\n",
    "df.unstack()\n",
    "```\n",
    "\n",
    "### Real-World Use Cases\n",
    "- Create cross-tabulation reports\n",
    "- Sales by product Ã— region\n",
    "- Time series analysis (month Ã— product)\n",
    "- Excel-style pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b799813c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PIVOT TABLES ===\n",
      "\n",
      "Example 1: Revenue by Product Ã— Region\n",
      "region       East  North  South   West\n",
      "product                               \n",
      "Headphones  66147   6988  38868  28177\n",
      "Laptop      47367  49059  12773  11678\n",
      "Phone        1495  19076      0  40566\n",
      "Tablet      17984  41070  40372   6585\n",
      "Watch       12885  38165  32778  10392\n",
      "\n",
      "Example 2: Pivot with row and column totals\n",
      "region        East   North   South   West   Total\n",
      "product                                          \n",
      "Headphones   66147    6988   38868  28177  140180\n",
      "Laptop       47367   49059   12773  11678  120877\n",
      "Phone         1495   19076       0  40566   61137\n",
      "Tablet       17984   41070   40372   6585  106011\n",
      "Watch        12885   38165   32778  10392   94220\n",
      "Total       145878  154358  124791  97398  522425\n",
      "\n",
      "Example 3: Multiple aggregation functions\n",
      "              sum                          mean                             \\\n",
      "region       East  North  South   West     East    North    South     West   \n",
      "product                                                                      \n",
      "Headphones  66147   6988  38868  28177  8268.38  2329.33  6478.00  4696.17   \n",
      "Laptop      47367  49059  12773  11678  6766.71  5451.00  2128.83  2335.60   \n",
      "Phone        1495  19076      0  40566  1495.00  3815.20     0.00  6761.00   \n",
      "Tablet      17984  41070  40372   6585  4496.00  5867.14  5767.43  2195.00   \n",
      "Watch       12885  38165  32778  10392  4295.00  5452.14  6555.60  5196.00   \n",
      "\n",
      "           count                   \n",
      "region      East North South West  \n",
      "product                            \n",
      "Headphones     8     3     6    6  \n",
      "Laptop         7     9     6    5  \n",
      "Phone          1     5     0    6  \n",
      "Tablet         4     7     7    3  \n",
      "Watch          3     7     5    2  \n",
      "\n",
      "Example 4: Pivot multiple values\n",
      "           quantity                  revenue                     \n",
      "region         East North South West    East  North  South   West\n",
      "product                                                          \n",
      "Headphones       53    12    32   23   66147   6988  38868  28177\n",
      "Laptop           33    41    27   22   47367  49059  12773  11678\n",
      "Phone             5    24     0   34    1495  19076      0  40566\n",
      "Tablet           16    30    28   15   17984  41070  40372   6585\n",
      "Watch            15    35    22    8   12885  38165  32778  10392\n",
      "\n",
      "Example 5: Cross-tabulation (product Ã— payment method)\n",
      "payment_method    Cash  Credit Card  Debit Card    UPI     All\n",
      "product                                                       \n",
      "Headphones        8089        45959       46369  39763  140180\n",
      "Laptop           23180        62932       22374  12391  120877\n",
      "Phone            19074        10089        9591  22383   61137\n",
      "Tablet           25769        37577       32078  10587  106011\n",
      "Watch            27875        45865       11490   8990   94220\n",
      "All             103987       202422      121902  94114  522425\n",
      "\n",
      "Example 6: MELT - Convert wide to long format\n",
      "Wide format:\n",
      "  product  Q1_sales  Q2_sales  Q3_sales\n",
      "0  Laptop      1000      1200      1100\n",
      "1   Phone      1500      1600      1700\n",
      "2  Tablet       800       900       850\n",
      "\n",
      "Long format (melted):\n",
      "  product   quarter  sales\n",
      "0  Laptop  Q1_sales   1000\n",
      "1   Phone  Q1_sales   1500\n",
      "2  Tablet  Q1_sales    800\n",
      "3  Laptop  Q2_sales   1200\n",
      "4   Phone  Q2_sales   1600\n",
      "5  Tablet  Q2_sales    900\n",
      "6  Laptop  Q3_sales   1100\n",
      "7   Phone  Q3_sales   1700\n",
      "8  Tablet  Q3_sales    850\n",
      "\n",
      "Example 7: STACK and UNSTACK\n",
      "Original pivot:\n",
      "region         East    North    South     West\n",
      "product                                       \n",
      "Headphones  66147.0   6988.0  38868.0  28177.0\n",
      "Laptop      47367.0  49059.0  12773.0  11678.0\n",
      "Phone        1495.0  19076.0      NaN  40566.0\n",
      "Tablet      17984.0  41070.0  40372.0   6585.0\n",
      "Watch       12885.0  38165.0  32778.0  10392.0\n",
      "\n",
      "Stacked (long format):\n",
      "product     region\n",
      "Headphones  East      66147.0\n",
      "            North      6988.0\n",
      "            South     38868.0\n",
      "            West      28177.0\n",
      "Laptop      East      47367.0\n",
      "dtype: float64\n",
      "\n",
      "Unstacked (back to wide):\n",
      "region         East    North    South     West\n",
      "product                                       \n",
      "Headphones  66147.0   6988.0  38868.0  28177.0\n",
      "Laptop      47367.0  49059.0  12773.0  11678.0\n",
      "Phone        1495.0  19076.0      NaN  40566.0\n",
      "Tablet      17984.0  41070.0  40372.0   6585.0\n",
      "Watch       12885.0  38165.0  32778.0  10392.0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PIVOT TABLES ===\\n\")\n",
    "\n",
    "# Example 1: Simple pivot table\n",
    "print(\"Example 1: Revenue by Product Ã— Region\")\n",
    "pivot1 = df.pivot_table(\n",
    "    values='revenue',\n",
    "    index='product',\n",
    "    columns='region',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "print(pivot1)\n",
    "print()\n",
    "\n",
    "# Example 2: Pivot with margins (totals)\n",
    "print(\"Example 2: Pivot with row and column totals\")\n",
    "pivot2 = df.pivot_table(\n",
    "    values='revenue',\n",
    "    index='product',\n",
    "    columns='region',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "print(pivot2)\n",
    "print()\n",
    "\n",
    "# Example 3: Multiple aggregations\n",
    "print(\"Example 3: Multiple aggregation functions\")\n",
    "pivot3 = df.pivot_table(\n",
    "    values='revenue',\n",
    "    index='product',\n",
    "    columns='region',\n",
    "    aggfunc=['sum', 'mean', 'count'],\n",
    "    fill_value=0\n",
    ")\n",
    "print(pivot3)\n",
    "print()\n",
    "\n",
    "# Example 4: Multiple values\n",
    "print(\"Example 4: Pivot multiple values\")\n",
    "pivot4 = df.pivot_table(\n",
    "    values=['revenue', 'quantity'],\n",
    "    index='product',\n",
    "    columns='region',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "print(pivot4)\n",
    "print()\n",
    "\n",
    "# Example 5: Cross-tabulation (special pivot)\n",
    "print(\"Example 5: Cross-tabulation (product Ã— payment method)\")\n",
    "crosstab = pd.crosstab(\n",
    "    df['product'],\n",
    "    df['payment_method'],\n",
    "    values=df['revenue'],\n",
    "    aggfunc='sum',\n",
    "    margins=True\n",
    ")\n",
    "print(crosstab)\n",
    "print()\n",
    "\n",
    "# Example 6: Melt (unpivot)\n",
    "print(\"Example 6: MELT - Convert wide to long format\")\n",
    "# Create wide format\n",
    "wide_df = pd.DataFrame({\n",
    "    'product': ['Laptop', 'Phone', 'Tablet'],\n",
    "    'Q1_sales': [1000, 1500, 800],\n",
    "    'Q2_sales': [1200, 1600, 900],\n",
    "    'Q3_sales': [1100, 1700, 850]\n",
    "})\n",
    "print(\"Wide format:\")\n",
    "print(wide_df)\n",
    "print()\n",
    "\n",
    "# Melt to long format\n",
    "long_df = pd.melt(\n",
    "    wide_df,\n",
    "    id_vars=['product'],\n",
    "    value_vars=['Q1_sales', 'Q2_sales', 'Q3_sales'],\n",
    "    var_name='quarter',\n",
    "    value_name='sales'\n",
    ")\n",
    "print(\"Long format (melted):\")\n",
    "print(long_df)\n",
    "print()\n",
    "\n",
    "# Example 7: Stack and Unstack\n",
    "print(\"Example 7: STACK and UNSTACK\")\n",
    "pivot_for_stack = df.pivot_table(\n",
    "    values='revenue',\n",
    "    index='product',\n",
    "    columns='region',\n",
    "    aggfunc='sum'\n",
    ")\n",
    "print(\"Original pivot:\")\n",
    "print(pivot_for_stack.head())\n",
    "print()\n",
    "\n",
    "stacked = pivot_for_stack.stack()\n",
    "print(\"Stacked (long format):\")\n",
    "print(stacked.head())\n",
    "print()\n",
    "\n",
    "unstacked = stacked.unstack()\n",
    "print(\"Unstacked (back to wide):\")\n",
    "print(unstacked.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04654f5",
   "metadata": {},
   "source": [
    "## 7. Sorting and Filtering\n",
    "\n",
    "### Sorting\n",
    "\n",
    "**sort_values()** - Sort by column values\n",
    "```python\n",
    "df.sort_values('column', ascending=True)\n",
    "df.sort_values(['col1', 'col2'], ascending=[True, False])\n",
    "```\n",
    "\n",
    "**sort_index()** - Sort by index\n",
    "```python\n",
    "df.sort_index()\n",
    "```\n",
    "\n",
    "### Filtering (Boolean Indexing)\n",
    "\n",
    "**Single condition**\n",
    "```python\n",
    "df[df['revenue'] > 1000]\n",
    "```\n",
    "\n",
    "**Multiple conditions (AND)**\n",
    "```python\n",
    "df[(df['revenue'] > 1000) & (df['region'] == 'North')]\n",
    "```\n",
    "\n",
    "**Multiple conditions (OR)**\n",
    "```python\n",
    "df[(df['product'] == 'Laptop') | (df['product'] == 'Phone')]\n",
    "```\n",
    "\n",
    "**NOT condition**\n",
    "```python\n",
    "df[~(df['region'] == 'North')]\n",
    "```\n",
    "\n",
    "**isin()** - Check if in list\n",
    "```python\n",
    "df[df['product'].isin(['Laptop', 'Phone'])]\n",
    "```\n",
    "\n",
    "**query()** - SQL-like filtering\n",
    "```python\n",
    "df.query('revenue > 1000 and region == \"North\"')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91964f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SORTING ===\n",
      "\n",
      "Example 1: Sort by revenue (descending)\n",
      "       product  revenue\n",
      "65      Laptop    17991\n",
      "91  Headphones    17991\n",
      "67  Headphones    15992\n",
      "82       Watch    15992\n",
      "13  Headphones    15992\n",
      "\n",
      "Example 2: Sort by product (A-Z) then revenue (high to low)\n",
      "       product  revenue\n",
      "91  Headphones    17991\n",
      "13  Headphones    15992\n",
      "67  Headphones    15992\n",
      "2   Headphones    13993\n",
      "3   Headphones    11691\n",
      "98  Headphones    10392\n",
      "69  Headphones     9995\n",
      "99  Headphones     9093\n",
      "81  Headphones     4792\n",
      "74  Headphones     4193\n",
      "\n",
      "Example 3: Sort by index\n",
      "Before: [27, 70, 63, 34, 66]\n",
      "After: [0, 1, 2, 3, 4]\n",
      "\n",
      "=== FILTERING ===\n",
      "\n",
      "Example 4: Revenue > $5000\n",
      "Found 41 high-revenue orders\n",
      "       product  revenue\n",
      "1       Laptop     6495\n",
      "2   Headphones    13993\n",
      "3   Headphones    11691\n",
      "10      Laptop     5394\n",
      "13  Headphones    15992\n",
      "\n",
      "Example 5: Laptops in North region\n",
      "Found 9 matching orders\n",
      "   product region  revenue\n",
      "9   Laptop  North     4792\n",
      "10  Laptop  North     5394\n",
      "24  Laptop  North    11691\n",
      "29  Laptop  North     5997\n",
      "76  Laptop  North     5997\n",
      "\n",
      "Example 6: Laptop OR Phone\n",
      "Found 39 orders\n",
      "product\n",
      "Laptop    27\n",
      "Phone     12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example 7: NOT North region\n",
      "Orders not in North: 69\n",
      "region\n",
      "South    24\n",
      "East     23\n",
      "West     22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example 8: Products in specific list\n",
      "Found 60 orders for: ['Laptop', 'Phone', 'Tablet']\n",
      "product\n",
      "Laptop    27\n",
      "Tablet    21\n",
      "Phone     12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example 9: Revenue between $2000 and $8000\n",
      "Found 54 mid-range orders\n",
      "      product  revenue\n",
      "1      Laptop     6495\n",
      "4  Headphones     2691\n",
      "5       Watch     3897\n",
      "6      Laptop     2697\n",
      "7       Watch     3897\n",
      "\n",
      "Example 10: Using query() - SQL-like syntax\n",
      "Query result: 14 rows\n",
      "   product region  revenue\n",
      "10  Laptop  North     5394\n",
      "17  Tablet  North     5196\n",
      "23   Phone  North     5997\n",
      "24  Laptop  North    11691\n",
      "29  Laptop  North     5997\n",
      "\n",
      "Example 11: Customers with 'Smith' in name\n",
      "Found 22 orders from Smith customers\n",
      "['John Smith']\n",
      "\n",
      "Example 12: Top 5 and Bottom 5 by revenue\n",
      "\n",
      "Top 5:\n",
      "       product  revenue\n",
      "65      Laptop    17991\n",
      "91  Headphones    17991\n",
      "13  Headphones    15992\n",
      "67  Headphones    15992\n",
      "82       Watch    15992\n",
      "\n",
      "Bottom 5:\n",
      "       product  revenue\n",
      "54       Watch      299\n",
      "90       Phone      299\n",
      "52  Headphones      598\n",
      "12      Laptop      599\n",
      "15      Tablet      599\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SORTING ===\\n\")\n",
    "\n",
    "# Example 1: Sort by single column\n",
    "print(\"Example 1: Sort by revenue (descending)\")\n",
    "sorted_df = df.sort_values('revenue', ascending=False)\n",
    "print(sorted_df[['product', 'revenue']].head())\n",
    "print()\n",
    "\n",
    "# Example 2: Sort by multiple columns\n",
    "print(\"Example 2: Sort by product (A-Z) then revenue (high to low)\")\n",
    "sorted_multi = df.sort_values(['product', 'revenue'], ascending=[True, False])\n",
    "print(sorted_multi[['product', 'revenue']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 3: Sort by index\n",
    "print(\"Example 3: Sort by index\")\n",
    "df_shuffled = df.sample(frac=1)  # Shuffle\n",
    "df_sorted_idx = df_shuffled.sort_index()\n",
    "print(f\"Before: {df_shuffled.index[:5].tolist()}\")\n",
    "print(f\"After: {df_sorted_idx.index[:5].tolist()}\")\n",
    "print()\n",
    "\n",
    "print(\"=== FILTERING ===\\n\")\n",
    "\n",
    "# Example 4: Simple filter\n",
    "print(\"Example 4: Revenue > $5000\")\n",
    "high_revenue = df[df['revenue'] > 5000]\n",
    "print(f\"Found {len(high_revenue)} high-revenue orders\")\n",
    "print(high_revenue[['product', 'revenue']].head())\n",
    "print()\n",
    "\n",
    "# Example 5: Multiple conditions (AND)\n",
    "print(\"Example 5: Laptops in North region\")\n",
    "laptop_north = df[(df['product'] == 'Laptop') & (df['region'] == 'North')]\n",
    "print(f\"Found {len(laptop_north)} matching orders\")\n",
    "print(laptop_north[['product', 'region', 'revenue']].head())\n",
    "print()\n",
    "\n",
    "# Example 6: Multiple conditions (OR)\n",
    "print(\"Example 6: Laptop OR Phone\")\n",
    "laptop_or_phone = df[(df['product'] == 'Laptop') | (df['product'] == 'Phone')]\n",
    "print(f\"Found {len(laptop_or_phone)} orders\")\n",
    "print(laptop_or_phone['product'].value_counts())\n",
    "print()\n",
    "\n",
    "# Example 7: NOT condition\n",
    "print(\"Example 7: NOT North region\")\n",
    "not_north = df[~(df['region'] == 'North')]\n",
    "print(f\"Orders not in North: {len(not_north)}\")\n",
    "print(not_north['region'].value_counts())\n",
    "print()\n",
    "\n",
    "# Example 8: isin() method\n",
    "print(\"Example 8: Products in specific list\")\n",
    "products_of_interest = ['Laptop', 'Phone', 'Tablet']\n",
    "filtered = df[df['product'].isin(products_of_interest)]\n",
    "print(f\"Found {len(filtered)} orders for: {products_of_interest}\")\n",
    "print(filtered['product'].value_counts())\n",
    "print()\n",
    "\n",
    "# Example 9: between() method\n",
    "print(\"Example 9: Revenue between $2000 and $8000\")\n",
    "mid_revenue = df[df['revenue'].between(2000, 8000)]\n",
    "print(f\"Found {len(mid_revenue)} mid-range orders\")\n",
    "print(mid_revenue[['product', 'revenue']].head())\n",
    "print()\n",
    "\n",
    "# Example 10: query() method\n",
    "print(\"Example 10: Using query() - SQL-like syntax\")\n",
    "queried = df.query('revenue > 5000 and region == \"North\"')\n",
    "print(f\"Query result: {len(queried)} rows\")\n",
    "print(queried[['product', 'region', 'revenue']].head())\n",
    "print()\n",
    "\n",
    "# Example 11: String contains in filter\n",
    "print(\"Example 11: Customers with 'Smith' in name\")\n",
    "smith_customers = df[df['customer_name'].str.contains('Smith')]\n",
    "print(f\"Found {len(smith_customers)} orders from Smith customers\")\n",
    "print(smith_customers['customer_name'].unique())\n",
    "print()\n",
    "\n",
    "# Example 12: nlargest() and nsmallest()\n",
    "print(\"Example 12: Top 5 and Bottom 5 by revenue\")\n",
    "print(\"\\nTop 5:\")\n",
    "print(df.nlargest(5, 'revenue')[['product', 'revenue']])\n",
    "print(\"\\nBottom 5:\")\n",
    "print(df.nsmallest(5, 'revenue')[['product', 'revenue']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ccb11",
   "metadata": {},
   "source": [
    "## 8. Window Functions (Rolling, Expanding, Cumulative)\n",
    "\n",
    "### What are Window Functions?\n",
    "\n",
    "**Window Functions** = Perform calculations across a set of rows (window) related to current row\n",
    "\n",
    "### Types\n",
    "\n",
    "**1. Rolling (Moving Window)**\n",
    "- Fixed window size moves through data\n",
    "- Example: 7-day moving average\n",
    "\n",
    "```python\n",
    "df['rolling_avg'] = df['value'].rolling(window=7).mean()\n",
    "```\n",
    "\n",
    "**2. Expanding (Cumulative)**\n",
    "- Window grows from start\n",
    "- Example: Cumulative sum\n",
    "\n",
    "```python\n",
    "df['expanding_sum'] = df['value'].expanding().sum()\n",
    "```\n",
    "\n",
    "**3. Exponentially Weighted (EWM)**\n",
    "- Recent values have more weight\n",
    "- Example: Exponential moving average\n",
    "\n",
    "```python\n",
    "df['ewm_avg'] = df['value'].ewm(span=7).mean()\n",
    "```\n",
    "\n",
    "### Common Operations\n",
    "\n",
    "| Operation | Purpose | Example |\n",
    "|-----------|---------|----------|\n",
    "| `mean()` | Moving average | 7-day avg sales |\n",
    "| `sum()` | Moving sum | Running total |\n",
    "| `min()` | Moving minimum | Lowest price in 30 days |\n",
    "| `max()` | Moving maximum | Highest revenue |\n",
    "| `std()` | Moving std dev | Revenue volatility |\n",
    "\n",
    "### Real-World Use Cases\n",
    "- **Finance**: Moving averages, volatility\n",
    "- **Sales**: Trends, seasonality\n",
    "- **IoT**: Sensor smoothing\n",
    "- **Web**: Page view trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d82c0459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WINDOW FUNCTIONS ===\n",
      "\n",
      "Creating time series dataset...\n",
      "\n",
      "        date   sales\n",
      "0 2024-01-01  192.00\n",
      "1 2024-01-02  301.07\n",
      "2 2024-01-03  205.46\n",
      "3 2024-01-04  228.06\n",
      "4 2024-01-05  112.16\n",
      "5 2024-01-06  328.05\n",
      "6 2024-01-07   90.03\n",
      "7 2024-01-08  223.85\n",
      "8 2024-01-09  318.47\n",
      "9 2024-01-10  436.61\n",
      "\n",
      "Example 1: 7-day moving average\n",
      "        date   sales  rolling_7d_avg\n",
      "0 2024-01-01  192.00             NaN\n",
      "1 2024-01-02  301.07             NaN\n",
      "2 2024-01-03  205.46             NaN\n",
      "3 2024-01-04  228.06             NaN\n",
      "4 2024-01-05  112.16             NaN\n",
      "5 2024-01-06  328.05             NaN\n",
      "6 2024-01-07   90.03          208.12\n",
      "7 2024-01-08  223.85          212.67\n",
      "8 2024-01-09  318.47          215.15\n",
      "9 2024-01-10  436.61          248.18\n",
      "\n",
      "Example 2: 7-day rolling sum\n",
      "         date   sales  rolling_7d_sum\n",
      "25 2024-01-26  139.38         1941.32\n",
      "26 2024-01-27  258.13         2014.96\n",
      "27 2024-01-28  360.82         2013.13\n",
      "28 2024-01-29  351.55         1922.85\n",
      "29 2024-01-30  121.82         1873.11\n",
      "\n",
      "Example 3: 7-day rolling min and max\n",
      "         date   sales  rolling_min  rolling_max\n",
      "25 2024-01-26  139.38       139.38       441.83\n",
      "26 2024-01-27  258.13       139.38       441.83\n",
      "27 2024-01-28  360.82       139.38       441.83\n",
      "28 2024-01-29  351.55       139.38       360.82\n",
      "29 2024-01-30  121.82       121.82       360.82\n",
      "\n",
      "Example 4: Cumulative sum and mean\n",
      "        date   sales   cumsum  cum_avg\n",
      "0 2024-01-01  192.00   192.00   192.00\n",
      "1 2024-01-02  301.07   493.07   246.53\n",
      "2 2024-01-03  205.46   698.53   232.84\n",
      "3 2024-01-04  228.06   926.59   231.65\n",
      "4 2024-01-05  112.16  1038.75   207.75\n",
      "5 2024-01-06  328.05  1366.80   227.80\n",
      "6 2024-01-07   90.03  1456.83   208.12\n",
      "7 2024-01-08  223.85  1680.68   210.09\n",
      "8 2024-01-09  318.47  1999.15   222.13\n",
      "9 2024-01-10  436.61  2435.76   243.58\n",
      "\n",
      "Example 5: Cumulative functions (direct)\n",
      "        date   sales  cumsum_direct  cummax\n",
      "0 2024-01-01  192.00         192.00  192.00\n",
      "1 2024-01-02  301.07         493.07  301.07\n",
      "2 2024-01-03  205.46         698.53  301.07\n",
      "3 2024-01-04  228.06         926.59  301.07\n",
      "4 2024-01-05  112.16        1038.75  301.07\n",
      "5 2024-01-06  328.05        1366.80  328.05\n",
      "6 2024-01-07   90.03        1456.83  328.05\n",
      "7 2024-01-08  223.85        1680.68  328.05\n",
      "8 2024-01-09  318.47        1999.15  328.05\n",
      "9 2024-01-10  436.61        2435.76  436.61\n",
      "\n",
      "Example 6: Exponential weighted moving average (EWMA)\n",
      "         date   sales  rolling_7d_avg    ewma\n",
      "20 2024-01-21  362.65          242.17  239.08\n",
      "21 2024-01-22  441.83          250.78  289.86\n",
      "22 2024-01-23  171.56          254.79  260.25\n",
      "23 2024-01-24  338.69          241.66  279.88\n",
      "24 2024-01-25  302.72          271.06  285.59\n",
      "25 2024-01-26  139.38          277.33  249.02\n",
      "26 2024-01-27  258.13          287.85  251.30\n",
      "27 2024-01-28  360.82          287.59  278.69\n",
      "28 2024-01-29  351.55          274.69  296.91\n",
      "29 2024-01-30  121.82          267.59  253.13\n",
      "\n",
      "Note: EWMA gives more weight to recent values\n",
      "\n",
      "Example 7: Shift for lag and lead values\n",
      "        date  prev_day_sales   sales  next_day_sales  sales_change\n",
      "0 2024-01-01             NaN  192.00          301.07           NaN\n",
      "1 2024-01-02          192.00  301.07          205.46        109.07\n",
      "2 2024-01-03          301.07  205.46          228.06        -95.61\n",
      "3 2024-01-04          205.46  228.06          112.16         22.60\n",
      "4 2024-01-05          228.06  112.16          328.05       -115.90\n",
      "5 2024-01-06          112.16  328.05           90.03        215.89\n",
      "6 2024-01-07          328.05   90.03          223.85       -238.02\n",
      "7 2024-01-08           90.03  223.85          318.47        133.82\n",
      "8 2024-01-09          223.85  318.47          436.61         94.62\n",
      "9 2024-01-10          318.47  436.61           93.80        118.14\n",
      "\n",
      "Example 8: Percentage change\n",
      "        date   sales  pct_change\n",
      "0 2024-01-01  192.00         NaN\n",
      "1 2024-01-02  301.07       56.81\n",
      "2 2024-01-03  205.46      -31.76\n",
      "3 2024-01-04  228.06       11.00\n",
      "4 2024-01-05  112.16      -50.82\n",
      "5 2024-01-06  328.05      192.48\n",
      "6 2024-01-07   90.03      -72.56\n",
      "7 2024-01-08  223.85      148.64\n",
      "8 2024-01-09  318.47       42.27\n",
      "9 2024-01-10  436.61       37.10\n",
      "\n",
      "Example 9: Multiple rolling windows\n",
      "         date   sales   ma_3d   ma_7d  ma_14d\n",
      "20 2024-01-21  362.65  214.20  242.17  247.79\n",
      "21 2024-01-22  441.83  329.66  250.78  263.36\n",
      "22 2024-01-23  171.56  325.35  254.79  252.87\n",
      "23 2024-01-24  338.69  317.36  241.66  245.87\n",
      "24 2024-01-25  302.72  270.99  271.06  260.80\n",
      "25 2024-01-26  139.38  260.26  277.33  243.97\n",
      "26 2024-01-27  258.13  233.41  287.85  257.18\n",
      "27 2024-01-28  360.82  252.78  287.59  264.88\n",
      "28 2024-01-29  351.55  323.50  274.69  262.74\n",
      "29 2024-01-30  121.82  278.06  267.59  261.19\n"
     ]
    }
   ],
   "source": [
    "print(\"=== WINDOW FUNCTIONS ===\\n\")\n",
    "\n",
    "# Create time series data\n",
    "print(\"Creating time series dataset...\\n\")\n",
    "date_range = pd.date_range('2024-01-01', periods=30, freq='D')\n",
    "ts_df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': np.random.randint(100, 500, 30) + np.sin(np.arange(30)) * 50\n",
    "})\n",
    "ts_df['sales'] = ts_df['sales'].round(2)\n",
    "\n",
    "print(ts_df.head(10))\n",
    "print()\n",
    "\n",
    "# Example 1: Rolling mean (moving average)\n",
    "print(\"Example 1: 7-day moving average\")\n",
    "ts_df['rolling_7d_avg'] = ts_df['sales'].rolling(window=7).mean()\n",
    "print(ts_df[['date', 'sales', 'rolling_7d_avg']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 2: Rolling sum\n",
    "print(\"Example 2: 7-day rolling sum\")\n",
    "ts_df['rolling_7d_sum'] = ts_df['sales'].rolling(window=7).sum()\n",
    "print(ts_df[['date', 'sales', 'rolling_7d_sum']].tail())\n",
    "print()\n",
    "\n",
    "# Example 3: Rolling min and max\n",
    "print(\"Example 3: 7-day rolling min and max\")\n",
    "ts_df['rolling_min'] = ts_df['sales'].rolling(window=7).min()\n",
    "ts_df['rolling_max'] = ts_df['sales'].rolling(window=7).max()\n",
    "print(ts_df[['date', 'sales', 'rolling_min', 'rolling_max']].tail())\n",
    "print()\n",
    "\n",
    "# Example 4: Expanding (cumulative)\n",
    "print(\"Example 4: Cumulative sum and mean\")\n",
    "ts_df['cumsum'] = ts_df['sales'].expanding().sum()\n",
    "ts_df['cum_avg'] = ts_df['sales'].expanding().mean()\n",
    "print(ts_df[['date', 'sales', 'cumsum', 'cum_avg']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 5: Using cumsum() directly\n",
    "print(\"Example 5: Cumulative functions (direct)\")\n",
    "ts_df['cumsum_direct'] = ts_df['sales'].cumsum()\n",
    "ts_df['cumprod'] = ts_df['sales'].cumprod()  # Cumulative product\n",
    "ts_df['cummax'] = ts_df['sales'].cummax()  # Cumulative maximum\n",
    "print(ts_df[['date', 'sales', 'cumsum_direct', 'cummax']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 6: Exponential weighted moving average\n",
    "print(\"Example 6: Exponential weighted moving average (EWMA)\")\n",
    "ts_df['ewma'] = ts_df['sales'].ewm(span=7).mean()\n",
    "print(ts_df[['date', 'sales', 'rolling_7d_avg', 'ewma']].tail(10))\n",
    "print(\"\\nNote: EWMA gives more weight to recent values\")\n",
    "print()\n",
    "\n",
    "# Example 7: Shift (lag/lead)\n",
    "print(\"Example 7: Shift for lag and lead values\")\n",
    "ts_df['prev_day_sales'] = ts_df['sales'].shift(1)  # Lag 1\n",
    "ts_df['next_day_sales'] = ts_df['sales'].shift(-1)  # Lead 1\n",
    "ts_df['sales_change'] = ts_df['sales'] - ts_df['prev_day_sales']\n",
    "print(ts_df[['date', 'prev_day_sales', 'sales', 'next_day_sales', 'sales_change']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 8: Percentage change\n",
    "print(\"Example 8: Percentage change\")\n",
    "ts_df['pct_change'] = ts_df['sales'].pct_change() * 100\n",
    "print(ts_df[['date', 'sales', 'pct_change']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 9: Rolling with different window sizes\n",
    "print(\"Example 9: Multiple rolling windows\")\n",
    "ts_df['ma_3d'] = ts_df['sales'].rolling(window=3).mean()\n",
    "ts_df['ma_7d'] = ts_df['sales'].rolling(window=7).mean()\n",
    "ts_df['ma_14d'] = ts_df['sales'].rolling(window=14).mean()\n",
    "print(ts_df[['date', 'sales', 'ma_3d', 'ma_7d', 'ma_14d']].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457da59d",
   "metadata": {},
   "source": [
    "## 9. Additional Data Manipulation Techniques\n",
    "\n",
    "### Creating New Columns\n",
    "\n",
    "**Method 1: Direct assignment**\n",
    "```python\n",
    "df['new_col'] = df['col1'] + df['col2']\n",
    "```\n",
    "\n",
    "**Method 2: assign()**\n",
    "```python\n",
    "df.assign(new_col = lambda x: x['col1'] + x['col2'])\n",
    "```\n",
    "\n",
    "**Method 3: np.where() - Conditional**\n",
    "```python\n",
    "df['category'] = np.where(df['value'] > 100, 'High', 'Low')\n",
    "```\n",
    "\n",
    "**Method 4: np.select() - Multiple conditions**\n",
    "```python\n",
    "conditions = [df['value'] > 100, df['value'] > 50]\n",
    "choices = ['High', 'Medium']\n",
    "df['category'] = np.select(conditions, choices, default='Low')\n",
    "```\n",
    "\n",
    "### Binning\n",
    "\n",
    "**cut()** - Bin continuous data into intervals\n",
    "```python\n",
    "pd.cut(df['age'], bins=[0, 18, 35, 60, 100], \n",
    "       labels=['Child', 'Young', 'Middle', 'Senior'])\n",
    "```\n",
    "\n",
    "**qcut()** - Quantile-based binning\n",
    "```python\n",
    "pd.qcut(df['revenue'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "```\n",
    "\n",
    "### Ranking\n",
    "\n",
    "```python\n",
    "df['rank'] = df['revenue'].rank(ascending=False, method='dense')\n",
    "```\n",
    "\n",
    "### Sample\n",
    "\n",
    "```python\n",
    "df.sample(n=10)  # Random 10 rows\n",
    "df.sample(frac=0.1)  # Random 10% of data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3581874e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ADDITIONAL TECHNIQUES ===\n",
      "\n",
      "Example 1: Create category using np.where()\n",
      "   revenue revenue_level\n",
      "0     1495           Low\n",
      "1     6495          High\n",
      "2    13993          High\n",
      "3    11691          High\n",
      "4     2691           Low\n",
      "5     3897           Low\n",
      "6     2697           Low\n",
      "7     3897           Low\n",
      "8     2396           Low\n",
      "9     4792           Low\n",
      "\n",
      "Example 2: Multiple conditions with np.select()\n",
      "   revenue revenue_tier\n",
      "0     1495          Low\n",
      "1     6495         High\n",
      "2    13993      Premium\n",
      "3    11691      Premium\n",
      "4     2691       Medium\n",
      "5     3897       Medium\n",
      "6     2697       Medium\n",
      "7     3897       Medium\n",
      "8     2396       Medium\n",
      "9     4792       Medium\n",
      "\n",
      "Revenue tier distribution:\n",
      "revenue_tier\n",
      "Medium     33\n",
      "High       27\n",
      "Low        26\n",
      "Premium    14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example 3: Bin revenue into ranges\n",
      "   revenue revenue_bin\n",
      "0     1495        0-2k\n",
      "1     6495      5k-10k\n",
      "2    13993        10k+\n",
      "3    11691        10k+\n",
      "4     2691       2k-5k\n",
      "5     3897       2k-5k\n",
      "6     2697       2k-5k\n",
      "7     3897       2k-5k\n",
      "8     2396       2k-5k\n",
      "9     4792       2k-5k\n",
      "\n",
      "Bin distribution:\n",
      "revenue_bin\n",
      "0-2k      26\n",
      "2k-5k     33\n",
      "5k-10k    27\n",
      "10k+      14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example 4: Quantile-based binning (quartiles)\n",
      "   revenue revenue_quartile\n",
      "0     1495  Q1 (Lowest 25%)\n",
      "1     6495               Q3\n",
      "2    13993     Q4 (Top 25%)\n",
      "3    11691     Q4 (Top 25%)\n",
      "4     2691               Q2\n",
      "5     3897               Q2\n",
      "6     2697               Q2\n",
      "7     3897               Q2\n",
      "8     2396               Q2\n",
      "9     4792               Q3\n",
      "\n",
      "Quartile distribution:\n",
      "revenue_quartile\n",
      "Q1 (Lowest 25%)    26\n",
      "Q2                 26\n",
      "Q3                 23\n",
      "Q4 (Top 25%)       25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example 5: Rank orders by revenue\n",
      "Top 10 orders by revenue:\n",
      "       product  revenue  revenue_rank\n",
      "65      Laptop    17991           1.0\n",
      "91  Headphones    17991           1.0\n",
      "13  Headphones    15992           2.0\n",
      "67  Headphones    15992           2.0\n",
      "82       Watch    15992           2.0\n",
      "2   Headphones    13993           3.0\n",
      "45       Phone    13993           3.0\n",
      "48      Tablet    11994           4.0\n",
      "79      Tablet    11994           4.0\n",
      "92      Tablet    11994           4.0\n",
      "\n",
      "Example 6: Create multiple columns with assign()\n",
      "   revenue  tax_amount  total_with_tax\n",
      "0     1495      269.10         1764.10\n",
      "1     6495     1169.10         7664.10\n",
      "2    13993     2518.74        16511.74\n",
      "3    11691     2104.38        13795.38\n",
      "4     2691      484.38         3175.38\n",
      "\n",
      "Example 7: Random sampling\n",
      "Sampled 10 random rows: indices [83, 53, 70, 45, 44, 39, 22, 80, 10, 0]\n",
      "\n",
      "Sampled 10% of data: 10 rows\n",
      "\n",
      "Example 8: Clip revenue (cap at min/max)\n",
      "Original revenue range: 299 - 17991\n",
      "Clipped revenue range: 1000 - 10000\n",
      "\n",
      "Example 9: Encode categories as numbers\n",
      "  region  region_code\n",
      "0   East            0\n",
      "5  North            1\n",
      "2  South            2\n",
      "4   West            3\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ADDITIONAL TECHNIQUES ===\\n\")\n",
    "\n",
    "# Example 1: np.where() for conditional columns\n",
    "print(\"Example 1: Create category using np.where()\")\n",
    "df['revenue_level'] = np.where(df['revenue'] > 5000, 'High', 'Low')\n",
    "print(df[['revenue', 'revenue_level']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 2: np.select() for multiple conditions\n",
    "print(\"Example 2: Multiple conditions with np.select()\")\n",
    "conditions = [\n",
    "    df['revenue'] > 10000,\n",
    "    df['revenue'] > 5000,\n",
    "    df['revenue'] > 2000\n",
    "]\n",
    "choices = ['Premium', 'High', 'Medium']\n",
    "df['revenue_tier'] = np.select(conditions, choices, default='Low')\n",
    "print(df[['revenue', 'revenue_tier']].head(10))\n",
    "print()\n",
    "print(\"Revenue tier distribution:\")\n",
    "print(df['revenue_tier'].value_counts())\n",
    "print()\n",
    "\n",
    "# Example 3: cut() - Binning into intervals\n",
    "print(\"Example 3: Bin revenue into ranges\")\n",
    "df['revenue_bin'] = pd.cut(\n",
    "    df['revenue'],\n",
    "    bins=[0, 2000, 5000, 10000, 20000],\n",
    "    labels=['0-2k', '2k-5k', '5k-10k', '10k+'],\n",
    "    include_lowest=True\n",
    ")\n",
    "print(df[['revenue', 'revenue_bin']].head(10))\n",
    "print()\n",
    "print(\"Bin distribution:\")\n",
    "print(df['revenue_bin'].value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "# Example 4: qcut() - Quantile-based binning\n",
    "print(\"Example 4: Quantile-based binning (quartiles)\")\n",
    "df['revenue_quartile'] = pd.qcut(\n",
    "    df['revenue'],\n",
    "    q=4,\n",
    "    labels=['Q1 (Lowest 25%)', 'Q2', 'Q3', 'Q4 (Top 25%)']\n",
    ")\n",
    "print(df[['revenue', 'revenue_quartile']].head(10))\n",
    "print()\n",
    "print(\"Quartile distribution:\")\n",
    "print(df['revenue_quartile'].value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "# Example 5: Ranking\n",
    "print(\"Example 5: Rank orders by revenue\")\n",
    "df['revenue_rank'] = df['revenue'].rank(ascending=False, method='dense')\n",
    "top_orders = df.nsmallest(10, 'revenue_rank')[['product', 'revenue', 'revenue_rank']]\n",
    "print(\"Top 10 orders by revenue:\")\n",
    "print(top_orders)\n",
    "print()\n",
    "\n",
    "# Example 6: assign() method\n",
    "print(\"Example 6: Create multiple columns with assign()\")\n",
    "df_assigned = df.assign(\n",
    "    total_before_tax = lambda x: x['quantity'] * x['price'],\n",
    "    tax_amount = lambda x: x['revenue'] * 0.18,\n",
    "    total_with_tax = lambda x: x['revenue'] * 1.18\n",
    ")\n",
    "print(df_assigned[['revenue', 'tax_amount', 'total_with_tax']].head())\n",
    "print()\n",
    "\n",
    "# Example 7: Sampling\n",
    "print(\"Example 7: Random sampling\")\n",
    "random_10 = df.sample(n=10, random_state=42)\n",
    "print(f\"Sampled 10 random rows: indices {random_10.index.tolist()}\")\n",
    "print()\n",
    "\n",
    "random_10pct = df.sample(frac=0.1, random_state=42)\n",
    "print(f\"Sampled 10% of data: {len(random_10pct)} rows\")\n",
    "print()\n",
    "\n",
    "# Example 8: Clip values\n",
    "print(\"Example 8: Clip revenue (cap at min/max)\")\n",
    "df['revenue_clipped'] = df['revenue'].clip(lower=1000, upper=10000)\n",
    "print(\"Original revenue range:\", df['revenue'].min(), '-', df['revenue'].max())\n",
    "print(\"Clipped revenue range:\", df['revenue_clipped'].min(), '-', df['revenue_clipped'].max())\n",
    "print()\n",
    "\n",
    "# Example 9: Categorical encoding\n",
    "print(\"Example 9: Encode categories as numbers\")\n",
    "df['region_code'] = pd.Categorical(df['region']).codes\n",
    "print(df[['region', 'region_code']].drop_duplicates().sort_values('region_code'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f876b2",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Real-World Example\n",
    "\n",
    "### Business Scenario\n",
    "\n",
    "**Task**: Analyze sales data to answer key business questions:\n",
    "1. Which products are top performers?\n",
    "2. What are the regional trends?\n",
    "3. Who are the VIP customers?\n",
    "4. What's the sales trend over time?\n",
    "5. Which product-region combinations are most profitable?\n",
    "\n",
    "We'll combine multiple techniques learned in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defce9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPREHENSIVE SALES ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "1. TOP PERFORMING PRODUCTS\n",
      "----------------------------------------------------------------------\n",
      "            Total_Revenue  Avg_Order_Value  Num_Orders  Units_Sold  \\\n",
      "product                                                              \n",
      "Headphones         140180          6094.78          23         120   \n",
      "Laptop             120877          4476.93          27         123   \n",
      "Tablet             106011          5048.14          21          89   \n",
      "Watch               94220          5542.35          17          80   \n",
      "Phone               61137          5094.75          12          63   \n",
      "\n",
      "            Unique_Customers  \n",
      "product                       \n",
      "Headphones                 5  \n",
      "Laptop                     5  \n",
      "Tablet                     5  \n",
      "Watch                      5  \n",
      "Phone                      5  \n",
      "\n",
      "2. REGIONAL PERFORMANCE\n",
      "----------------------------------------------------------------------\n",
      "product  Headphones  Laptop  Phone  Tablet  Watch     All\n",
      "region                                                   \n",
      "East          66147   47367   1495   17984  12885  145878\n",
      "North          6988   49059  19076   41070  38165  154358\n",
      "South         38868   12773      0   40372  32778  124791\n",
      "West          28177   11678  40566    6585  10392   97398\n",
      "All          140180  120877  61137  106011  94220  522425\n",
      "\n",
      "3. VIP CUSTOMERS (Top 10 by Total Spend)\n",
      "----------------------------------------------------------------------\n",
      "               Total_Spend  Avg_Order  Num_Orders  Total_Items  \\\n",
      "customer_name                                                    \n",
      "John Smith          135887    6176.68          22          113   \n",
      "Michael Brown       135784    5657.67          24          116   \n",
      "Bob Wilson           94215    4958.68          19           85   \n",
      "Emma Davis           79822    4434.56          18           78   \n",
      "Alice Johnson        76717    4512.76          17           83   \n",
      "\n",
      "               Customer_Value_Score  \n",
      "customer_name                        \n",
      "John Smith                  70143.5  \n",
      "Michael Brown               70292.0  \n",
      "Bob Wilson                  49007.5  \n",
      "Emma Davis                  41711.0  \n",
      "Alice Johnson               40058.5  \n",
      "\n",
      "4. MONTHLY SALES TREND\n",
      "----------------------------------------------------------------------\n",
      "         Total_Revenue  Avg_Order_Value  Num_Orders  MoM_Growth_%\n",
      "date                                                             \n",
      "2024-01         138475          4945.54          28           NaN\n",
      "2024-02         145359          4845.30          30          4.97\n",
      "2024-03         206820          5909.14          35         42.28\n",
      "2024-04          31771          4538.71           7        -84.64\n",
      "\n",
      "5. TOP 10 PRODUCT-REGION COMBINATIONS\n",
      "----------------------------------------------------------------------\n",
      "                   Total_Revenue  Num_Orders  Avg_Order\n",
      "product    region                                      \n",
      "Headphones East            66147           8    8268.38\n",
      "Laptop     North           49059           9    5451.00\n",
      "           East            47367           7    6766.71\n",
      "Tablet     North           41070           7    5867.14\n",
      "Phone      West            40566           6    6761.00\n",
      "Tablet     South           40372           7    5767.43\n",
      "Headphones South           38868           6    6478.00\n",
      "Watch      North           38165           7    5452.14\n",
      "           South           32778           5    6555.60\n",
      "Headphones West            28177           6    4696.17\n",
      "\n",
      "6. PAYMENT METHOD ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "product         Headphones  Laptop  Phone  Tablet  Watch     All\n",
      "payment_method                                                  \n",
      "Cash                  8089   23180  19074   25769  27875  103987\n",
      "Credit Card          45959   62932  10089   37577  45865  202422\n",
      "Debit Card           46369   22374   9591   32078  11490  121902\n",
      "UPI                  39763   12391  22383   10587   8990   94114\n",
      "All                 140180  120877  61137  106011  94220  522425\n",
      "\n",
      "======================================================================\n",
      "SUMMARY STATISTICS\n",
      "======================================================================\n",
      "Total Revenue: $522,425.00\n",
      "Average Order Value: $5,224.25\n",
      "Total Orders: 100\n",
      "Unique Products: 5\n",
      "Unique Customers: 5\n",
      "Date Range: 2024-01-02 to 2024-04-09\n",
      "Best Selling Product: Headphones\n",
      "Best Region: North\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMPREHENSIVE SALES ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Question 1: Top performing products\n",
    "print(\"1. TOP PERFORMING PRODUCTS\")\n",
    "print(\"-\" * 70)\n",
    "product_performance = df.groupby('product').agg({\n",
    "    'revenue': ['sum', 'mean', 'count'],\n",
    "    'quantity': 'sum',\n",
    "    'customer_name': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "product_performance.columns = ['Total_Revenue', 'Avg_Order_Value', \n",
    "                                'Num_Orders', 'Units_Sold', 'Unique_Customers']\n",
    "product_performance = product_performance.sort_values('Total_Revenue', ascending=False)\n",
    "\n",
    "print(product_performance)\n",
    "print()\n",
    "\n",
    "# Question 2: Regional trends\n",
    "print(\"2. REGIONAL PERFORMANCE\")\n",
    "print(\"-\" * 70)\n",
    "regional_pivot = df.pivot_table(\n",
    "    values='revenue',\n",
    "    index='region',\n",
    "    columns='product',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True\n",
    ")\n",
    "print(regional_pivot)\n",
    "print()\n",
    "\n",
    "# Question 3: VIP Customers (top 10 by total spend)\n",
    "print(\"3. VIP CUSTOMERS (Top 10 by Total Spend)\")\n",
    "print(\"-\" * 70)\n",
    "customer_analysis = df.groupby('customer_name').agg({\n",
    "    'revenue': ['sum', 'mean', 'count'],\n",
    "    'quantity': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "customer_analysis.columns = ['Total_Spend', 'Avg_Order', 'Num_Orders', 'Total_Items']\n",
    "customer_analysis['Customer_Value_Score'] = (\n",
    "    customer_analysis['Total_Spend'] * 0.5 + \n",
    "    customer_analysis['Num_Orders'] * 100\n",
    ").round(2)\n",
    "\n",
    "vip_customers = customer_analysis.sort_values('Total_Spend', ascending=False).head(10)\n",
    "print(vip_customers)\n",
    "print()\n",
    "\n",
    "# Question 4: Sales trend over time\n",
    "print(\"4. MONTHLY SALES TREND\")\n",
    "print(\"-\" * 70)\n",
    "df_sorted = df.sort_values('date')\n",
    "monthly_trend = df_sorted.groupby(df_sorted['date'].dt.to_period('M')).agg({\n",
    "    'revenue': ['sum', 'mean', 'count']\n",
    "}).round(2)\n",
    "\n",
    "monthly_trend.columns = ['Total_Revenue', 'Avg_Order_Value', 'Num_Orders']\n",
    "monthly_trend['MoM_Growth_%'] = monthly_trend['Total_Revenue'].pct_change() * 100\n",
    "monthly_trend['MoM_Growth_%'] = monthly_trend['MoM_Growth_%'].round(2)\n",
    "\n",
    "print(monthly_trend)\n",
    "print()\n",
    "\n",
    "# Question 5: Best product-region combinations\n",
    "print(\"5. TOP 10 PRODUCT-REGION COMBINATIONS\")\n",
    "print(\"-\" * 70)\n",
    "combo_analysis = df.groupby(['product', 'region'])['revenue'].agg(['sum', 'count']).round(2)\n",
    "combo_analysis.columns = ['Total_Revenue', 'Num_Orders']\n",
    "combo_analysis['Avg_Order'] = (combo_analysis['Total_Revenue'] / combo_analysis['Num_Orders']).round(2)\n",
    "combo_analysis = combo_analysis.sort_values('Total_Revenue', ascending=False).head(10)\n",
    "\n",
    "print(combo_analysis)\n",
    "print()\n",
    "\n",
    "# Bonus: Payment method analysis\n",
    "print(\"6. PAYMENT METHOD ANALYSIS\")\n",
    "print(\"-\" * 70)\n",
    "payment_analysis = pd.crosstab(\n",
    "    df['payment_method'],\n",
    "    df['product'],\n",
    "    values=df['revenue'],\n",
    "    aggfunc='sum',\n",
    "    margins=True\n",
    ").round(2)\n",
    "print(payment_analysis)\n",
    "print()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"=\"*70)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Revenue: ${df['revenue'].sum():,.2f}\")\n",
    "print(f\"Average Order Value: ${df['revenue'].mean():,.2f}\")\n",
    "print(f\"Total Orders: {len(df):,}\")\n",
    "print(f\"Unique Products: {df['product'].nunique()}\")\n",
    "print(f\"Unique Customers: {df['customer_name'].nunique()}\")\n",
    "print(f\"Date Range: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Best Selling Product: {df.groupby('product')['revenue'].sum().idxmax()}\")\n",
    "print(f\"Best Region: {df.groupby('region')['revenue'].sum().idxmax()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c00e4",
   "metadata": {},
   "source": [
    "## 11. Performance Tips & Best Practices\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "**1. Vectorization > Loops**\n",
    "```python\n",
    "# âŒ Slow - Loop\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'new_col'] = df.loc[i, 'col1'] * 2\n",
    "\n",
    "# âœ… Fast - Vectorized\n",
    "df['new_col'] = df['col1'] * 2\n",
    "```\n",
    "\n",
    "**2. Use appropriate methods**\n",
    "```python\n",
    "# map() faster than apply() for simple replacements\n",
    "df['col'].map(mapping_dict)  # âœ… Faster\n",
    "df['col'].apply(lambda x: mapping_dict.get(x))  # âŒ Slower\n",
    "```\n",
    "\n",
    "**3. Filter early, aggregate late**\n",
    "```python\n",
    "# âœ… Filter first (smaller dataset)\n",
    "df[df['year'] == 2024].groupby('product')['revenue'].sum()\n",
    "\n",
    "# âŒ Aggregate everything first\n",
    "df.groupby('product')['revenue'].sum()[df['year'] == 2024]\n",
    "```\n",
    "\n",
    "**4. Use categorical for repeated strings**\n",
    "```python\n",
    "df['category'] = df['category'].astype('category')  # Saves memory\n",
    "```\n",
    "\n",
    "**5. Chain operations for readability**\n",
    "```python\n",
    "# âœ… Method chaining\n",
    "result = (df\n",
    "    .query('revenue > 1000')\n",
    "    .groupby('product')['revenue']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "```\n",
    "\n",
    "### Common Mistakes to Avoid\n",
    "\n",
    "1. **Using `inplace=True` unnecessarily** - Can prevent optimization\n",
    "2. **Not setting index for frequent lookups** - Slow row access\n",
    "3. **Using `apply()` when vectorization possible** - Much slower\n",
    "4. **Creating unnecessary copies** - Memory waste\n",
    "5. **Not using `query()` for complex filters** - Less readable\n",
    "\n",
    "### Memory Management\n",
    "\n",
    "```python\n",
    "# Check memory usage\n",
    "df.memory_usage(deep=True)\n",
    "\n",
    "# Optimize dtypes\n",
    "df['int_col'] = df['int_col'].astype('int32')  # Instead of int64\n",
    "df['cat_col'] = df['cat_col'].astype('category')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3358e8",
   "metadata": {},
   "source": [
    "## Summary & Quick Reference\n",
    "\n",
    "### Key Operations Covered\n",
    "\n",
    "| Operation | Method | Use Case |\n",
    "|-----------|--------|----------|\n",
    "| **Transform** | `apply()`, `map()` | Create new columns with logic |\n",
    "| **String** | `.str.` methods | Clean and parse text |\n",
    "| **DateTime** | `.dt.` methods | Extract date components |\n",
    "| **Group** | `groupby()`, `agg()` | Summary by category |\n",
    "| **Combine** | `merge()`, `concat()` | Join datasets |\n",
    "| **Reshape** | `pivot_table()`, `melt()` | Change structure |\n",
    "| **Sort** | `sort_values()` | Order data |\n",
    "| **Filter** | Boolean indexing, `query()` | Select rows |\n",
    "| **Window** | `rolling()`, `expanding()` | Moving calculations |\n",
    "| **Create** | `assign()`, `np.where()` | New columns |\n",
    "\n",
    "### Quick Reference Guide\n",
    "\n",
    "**Apply custom function:**\n",
    "```python\n",
    "df['new'] = df['col'].apply(lambda x: x * 2)\n",
    "df['new'] = df.apply(lambda row: row['col1'] + row['col2'], axis=1)\n",
    "```\n",
    "\n",
    "**String operations:**\n",
    "```python\n",
    "df['col'].str.lower().str.strip()\n",
    "df['col'].str.contains('pattern')\n",
    "df['col'].str.split(' ', expand=True)\n",
    "```\n",
    "\n",
    "**DateTime:**\n",
    "```python\n",
    "df['date'].dt.year\n",
    "df['date'].dt.day_name()\n",
    "df['date'].dt.quarter\n",
    "```\n",
    "\n",
    "**GroupBy:**\n",
    "```python\n",
    "df.groupby('col')['value'].sum()\n",
    "df.groupby('col').agg(['sum', 'mean', 'count'])\n",
    "df.groupby(['col1', 'col2'])['value'].sum()\n",
    "```\n",
    "\n",
    "**Merge:**\n",
    "```python\n",
    "pd.merge(df1, df2, on='key', how='inner')\n",
    "pd.concat([df1, df2], axis=0)\n",
    "```\n",
    "\n",
    "**Pivot:**\n",
    "```python\n",
    "df.pivot_table(values='val', index='row', columns='col', aggfunc='sum')\n",
    "```\n",
    "\n",
    "**Filter:**\n",
    "```python\n",
    "df[df['col'] > 100]\n",
    "df[(df['col1'] > 100) & (df['col2'] == 'A')]\n",
    "df.query('col1 > 100 and col2 == \"A\"')\n",
    "```\n",
    "\n",
    "**Window functions:**\n",
    "```python\n",
    "df['rolling_avg'] = df['value'].rolling(window=7).mean()\n",
    "df['cumsum'] = df['value'].cumsum()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "**Try these on your own:**\n",
    "\n",
    "1. Create a pivot table showing average revenue by product and payment method\n",
    "2. Find the top 3 customers in each region by total spend\n",
    "3. Calculate 7-day moving average of daily sales\n",
    "4. Merge customer demographics with sales data\n",
    "5. Create revenue bins (Low, Medium, High) and analyze patterns\n",
    "6. Find month-over-month growth percentage for each product\n",
    "7. Extract customer first names and analyze by first letter\n",
    "8. Calculate cumulative revenue by date\n",
    "9. Find products that are popular on weekends vs weekdays\n",
    "10. Create a function that categorizes orders as \"Bulk\" (qty>5) or \"Regular\"\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "After mastering data manipulation:\n",
    "1. **Data Visualization** (Matplotlib, Seaborn)\n",
    "2. **Advanced Analytics** (Statistics, ML)\n",
    "3. **Time Series Analysis** (Forecasting)\n",
    "4. **Feature Engineering** (For ML models)\n",
    "5. **Big Data** (Dask, PySpark for large datasets)\n",
    "\n",
    "---\n",
    "\n",
    "### Remember:\n",
    "- ðŸŽ¯ **Practice regularly** with real datasets\n",
    "- ðŸ“š **Read documentation** - Pandas docs are excellent\n",
    "- ðŸ’¡ **Think before coding** - Plan your analysis\n",
    "- ðŸ› **Debug systematically** - Check intermediate results\n",
    "- ðŸš€ **Optimize when needed** - Vectorize, don't loop!\n",
    "\n",
    "**Happy Data Manipulation! ðŸ¼**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57449fbf-4971-430f-8429-0a6fbeb008a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
