{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7761e85e",
   "metadata": {},
   "source": [
    "# GroupBy and Aggregation in Pandas\n",
    "\n",
    "## Overview\n",
    "\n",
    "**GroupBy** = Split-Apply-Combine strategy for data analysis\n",
    "\n",
    "### The Split-Apply-Combine Pattern\n",
    "\n",
    "```\n",
    "1. SPLIT    → Divide data into groups\n",
    "2. APPLY    → Apply function to each group\n",
    "3. COMBINE  → Combine results back together\n",
    "```\n",
    "\n",
    "### Visual Example\n",
    "\n",
    "```\n",
    "Original Data:\n",
    "Product   Region   Sales\n",
    "Laptop    North    1000\n",
    "Phone     South     500\n",
    "Laptop    South     800\n",
    "Phone     North     600\n",
    "\n",
    "           ↓ SPLIT by Product\n",
    "\n",
    "Group 1: Laptop    [1000, 800]\n",
    "Group 2: Phone     [500, 600]\n",
    "\n",
    "           ↓ APPLY sum()\n",
    "\n",
    "Laptop: 1800\n",
    "Phone:  1100\n",
    "\n",
    "           ↓ COMBINE\n",
    "\n",
    "Product   Total_Sales\n",
    "Laptop    1800\n",
    "Phone     1100\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Description | Example |\n",
    "|---------|-------------|----------|\n",
    "| **GroupBy** | Split data into groups | `df.groupby('category')` |\n",
    "| **Aggregation** | Summarize each group | `sum()`, `mean()`, `count()` |\n",
    "| **Transform** | Return same shape | Add group mean to each row |\n",
    "| **Filter** | Keep/remove groups | Keep groups with sum > 1000 |\n",
    "| **Apply** | Custom operations | Any function |\n",
    "\n",
    "### What We'll Learn\n",
    "1. ✅ Basic groupby operations\n",
    "2. ✅ Single and multiple aggregations\n",
    "3. ✅ Multiple groupby columns\n",
    "4. ✅ Transform vs aggregation\n",
    "5. ✅ Filtering groups\n",
    "6. ✅ Custom aggregation functions\n",
    "7. ✅ Named aggregations\n",
    "8. ✅ Real-world business analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f48f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported\n",
      "Pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "print(\"✅ Libraries imported\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f47028",
   "metadata": {},
   "source": [
    "## Sample Dataset: E-commerce Sales\n",
    "\n",
    "We'll use a comprehensive sales dataset to demonstrate groupby operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dcc1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales Dataset:\n",
      "    order_id       date     product     category region customer_type  \\\n",
      "0       1001 2024-02-21       Phone  Accessories   West     Returning   \n",
      "1       1002 2024-01-15      Tablet  Electronics  South     Returning   \n",
      "2       1003 2024-03-12      Laptop  Electronics  North     Returning   \n",
      "3       1004 2024-03-01       Watch  Electronics  South     Returning   \n",
      "4       1005 2024-01-21      Laptop  Accessories  North     Returning   \n",
      "5       1006 2024-03-23      Laptop  Accessories   East           VIP   \n",
      "6       1007 2024-03-27      Tablet  Accessories  North           New   \n",
      "7       1008 2024-03-15      Laptop  Accessories   West           New   \n",
      "8       1009 2024-03-15       Phone  Electronics   West           VIP   \n",
      "9       1010 2024-03-28       Phone  Electronics  North           VIP   \n",
      "10      1011 2024-01-24  Headphones  Accessories  North     Returning   \n",
      "11      1012 2024-01-03      Camera  Electronics  North     Returning   \n",
      "12      1013 2024-01-22       Watch  Electronics  North           New   \n",
      "13      1014 2024-02-22      Laptop  Accessories   West           New   \n",
      "14      1015 2024-01-02      Laptop  Electronics  South     Returning   \n",
      "\n",
      "    quantity  unit_price  discount_%  subtotal  discount_amount  total_amount  \\\n",
      "0          1         599           5       599            29.95        569.05   \n",
      "1          3        1999           0      5997             0.00       5997.00   \n",
      "2          1         299          10       299            29.90        269.10   \n",
      "3          2         299          10       598            59.80        538.20   \n",
      "4          3        1299          20      3897           779.40       3117.60   \n",
      "5          2         299           0       598             0.00        598.00   \n",
      "6          3         299           5       897            44.85        852.15   \n",
      "7          5        1299           5      6495           324.75       6170.25   \n",
      "8          4        2999           0     11996             0.00      11996.00   \n",
      "9          5        2999           0     14995             0.00      14995.00   \n",
      "10         2        1299           5      2598           129.90       2468.10   \n",
      "11         4        1999          10      7996           799.60       7196.40   \n",
      "12         3         299           5       897            44.85        852.15   \n",
      "13         4         299           5      1196            59.80       1136.20   \n",
      "14         1        1999           0      1999             0.00       1999.00   \n",
      "\n",
      "       month  year  \n",
      "0   February  2024  \n",
      "1    January  2024  \n",
      "2      March  2024  \n",
      "3      March  2024  \n",
      "4    January  2024  \n",
      "5      March  2024  \n",
      "6      March  2024  \n",
      "7      March  2024  \n",
      "8      March  2024  \n",
      "9      March  2024  \n",
      "10   January  2024  \n",
      "11   January  2024  \n",
      "12   January  2024  \n",
      "13  February  2024  \n",
      "14   January  2024  \n",
      "\n",
      "Shape: (200, 14)\n",
      "\n",
      "Columns: ['order_id', 'date', 'product', 'category', 'region', 'customer_type', 'quantity', 'unit_price', 'discount_%', 'subtotal', 'discount_amount', 'total_amount', 'month', 'year']\n",
      "\n",
      "Data types:\n",
      "order_id                    int64\n",
      "date               datetime64[ns]\n",
      "product                    object\n",
      "category                   object\n",
      "region                     object\n",
      "customer_type              object\n",
      "quantity                    int64\n",
      "unit_price                  int64\n",
      "discount_%                  int64\n",
      "subtotal                    int64\n",
      "discount_amount           float64\n",
      "total_amount              float64\n",
      "month                      object\n",
      "year                        int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create realistic e-commerce sales data\n",
    "np.random.seed(42)\n",
    "\n",
    "n_orders = 200\n",
    "\n",
    "# Generate dates over 3 months\n",
    "start_date = datetime(2024, 1, 1)\n",
    "dates = [start_date + timedelta(days=np.random.randint(0, 90)) for _ in range(n_orders)]\n",
    "\n",
    "sales_df = pd.DataFrame({\n",
    "    'order_id': range(1001, 1001 + n_orders),\n",
    "    'date': dates,\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Headphones', 'Watch', 'Camera'], n_orders),\n",
    "    'category': np.random.choice(['Electronics', 'Accessories'], n_orders),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_orders),\n",
    "    'customer_type': np.random.choice(['New', 'Returning', 'VIP'], n_orders, p=[0.4, 0.4, 0.2]),\n",
    "    'quantity': np.random.randint(1, 6, n_orders),\n",
    "    'unit_price': np.random.choice([299, 599, 899, 1299, 1999, 2999], n_orders),\n",
    "    'discount_%': np.random.choice([0, 5, 10, 15, 20], n_orders, p=[0.4, 0.25, 0.2, 0.1, 0.05])\n",
    "})\n",
    "\n",
    "# Calculate derived columns\n",
    "sales_df['subtotal'] = sales_df['quantity'] * sales_df['unit_price']\n",
    "sales_df['discount_amount'] = sales_df['subtotal'] * sales_df['discount_%'] / 100\n",
    "sales_df['total_amount'] = sales_df['subtotal'] - sales_df['discount_amount']\n",
    "sales_df['month'] = pd.to_datetime(sales_df['date']).dt.month_name()\n",
    "sales_df['year'] = pd.to_datetime(sales_df['date']).dt.year\n",
    "\n",
    "print(\"Sales Dataset:\")\n",
    "print(sales_df.head(15))\n",
    "print(f\"\\nShape: {sales_df.shape}\")\n",
    "print(f\"\\nColumns: {sales_df.columns.tolist()}\")\n",
    "print(f\"\\nData types:\\n{sales_df.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64e6c1",
   "metadata": {},
   "source": [
    "## 1. GroupBy Basics\n",
    "\n",
    "### What is GroupBy?\n",
    "\n",
    "**GroupBy** creates a grouped object that splits data by unique values in a column.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "# Basic groupby\n",
    "grouped = df.groupby('column')\n",
    "\n",
    "# Apply aggregation\n",
    "result = df.groupby('column')['value_column'].sum()\n",
    "```\n",
    "\n",
    "### Understanding the GroupBy Object\n",
    "\n",
    "```python\n",
    "grouped = df.groupby('product')\n",
    "# This creates a GroupBy object (not a DataFrame yet)\n",
    "\n",
    "# To see results, apply an aggregation:\n",
    "grouped.sum()      # Sum for each group\n",
    "grouped.mean()     # Mean for each group\n",
    "grouped.count()    # Count for each group\n",
    "```\n",
    "\n",
    "### Basic Workflow\n",
    "\n",
    "```python\n",
    "# Step 1: Group by category\n",
    "df.groupby('category')\n",
    "\n",
    "# Step 2: Select column to aggregate\n",
    "df.groupby('category')['sales']\n",
    "\n",
    "# Step 3: Apply aggregation\n",
    "df.groupby('category')['sales'].sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da1b39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GROUPBY BASICS ===\n",
      "\n",
      "Example 1: Total sales by product\n",
      "product\n",
      "Laptop        181627.65\n",
      "Phone         149261.70\n",
      "Tablet        146091.55\n",
      "Camera        108263.20\n",
      "Headphones    103322.00\n",
      "Watch          96575.45\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Type: <class 'pandas.core.series.Series'>\n",
      "\n",
      "Example 2: Number of orders by product\n",
      "product\n",
      "Laptop        43\n",
      "Tablet        37\n",
      "Camera        34\n",
      "Headphones    34\n",
      "Phone         28\n",
      "Watch         24\n",
      "Name: order_id, dtype: int64\n",
      "\n",
      "Example 3: Average order value by region\n",
      "region\n",
      "West     4109.91\n",
      "East     4039.02\n",
      "North    4025.54\n",
      "South    3393.49\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Example 4: Understanding the GroupBy object\n",
      "GroupBy object: <pandas.core.groupby.generic.DataFrameGroupBy object at 0x1375ead70>\n",
      "Number of groups: 6\n",
      "Group names: ['Camera', 'Headphones', 'Laptop', 'Phone', 'Tablet', 'Watch']\n",
      "\n",
      "Example 5: First order for each product\n",
      "                 date  quantity  total_amount\n",
      "product                                      \n",
      "Camera     2024-01-03         4       7196.40\n",
      "Headphones 2024-01-24         2       2468.10\n",
      "Laptop     2024-03-12         1        269.10\n",
      "Phone      2024-02-21         1        569.05\n",
      "Tablet     2024-01-15         3       5997.00\n",
      "\n",
      "Example 6: Size of each product group\n",
      "product\n",
      "Laptop        43\n",
      "Tablet        37\n",
      "Camera        34\n",
      "Headphones    34\n",
      "Phone         28\n",
      "Watch         24\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=== GROUPBY BASICS ===\\n\")\n",
    "\n",
    "# Example 1: Simple groupby with sum\n",
    "print(\"Example 1: Total sales by product\")\n",
    "product_sales = sales_df.groupby('product')['total_amount'].sum()\n",
    "print(product_sales.sort_values(ascending=False))\n",
    "print(f\"\\nType: {type(product_sales)}\")\n",
    "print()\n",
    "\n",
    "# Example 2: Count orders by product\n",
    "print(\"Example 2: Number of orders by product\")\n",
    "product_count = sales_df.groupby('product')['order_id'].count()\n",
    "print(product_count.sort_values(ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 3: Average order value by region\n",
    "print(\"Example 3: Average order value by region\")\n",
    "region_avg = sales_df.groupby('region')['total_amount'].mean()\n",
    "print(region_avg.sort_values(ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 4: Understanding GroupBy object\n",
    "print(\"Example 4: Understanding the GroupBy object\")\n",
    "grouped = sales_df.groupby('product')\n",
    "print(f\"GroupBy object: {grouped}\")\n",
    "print(f\"Number of groups: {grouped.ngroups}\")\n",
    "print(f\"Group names: {list(grouped.groups.keys())}\")\n",
    "print()\n",
    "\n",
    "# Example 5: Get first and last rows of each group\n",
    "print(\"Example 5: First order for each product\")\n",
    "first_orders = sales_df.groupby('product').first()\n",
    "print(first_orders[['date', 'quantity', 'total_amount']].head())\n",
    "print()\n",
    "\n",
    "# Example 6: Group size (number of items in each group)\n",
    "print(\"Example 6: Size of each product group\")\n",
    "group_sizes = sales_df.groupby('product').size()\n",
    "print(group_sizes.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368db13",
   "metadata": {},
   "source": [
    "## 2. Common Aggregation Functions\n",
    "\n",
    "### Built-in Aggregation Functions\n",
    "\n",
    "| Function | Description | Example Use Case |\n",
    "|----------|-------------|------------------|\n",
    "| `sum()` | Sum of values | Total revenue |\n",
    "| `mean()` | Average | Average order value |\n",
    "| `median()` | Middle value | Median price |\n",
    "| `min()` | Minimum value | Lowest price |\n",
    "| `max()` | Maximum value | Highest revenue |\n",
    "| `count()` | Number of items | Order count |\n",
    "| `std()` | Standard deviation | Price volatility |\n",
    "| `var()` | Variance | Revenue variance |\n",
    "| `first()` | First value | First order date |\n",
    "| `last()` | Last value | Last order date |\n",
    "| `size()` | Group size | Items per group |\n",
    "| `nunique()` | Unique count | Unique customers |\n",
    "\n",
    "### Statistical Functions\n",
    "\n",
    "| Function | Description |\n",
    "|----------|-------------|\n",
    "| `quantile(q)` | Quantile (e.g., q=0.25 for 25th percentile) |\n",
    "| `sem()` | Standard error of mean |\n",
    "| `skew()` | Skewness |\n",
    "| `kurt()` | Kurtosis |\n",
    "\n",
    "### String Functions\n",
    "\n",
    "```python\n",
    "# For string columns\n",
    "df.groupby('category')['name'].agg(lambda x: ', '.join(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e83f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AGGREGATION FUNCTIONS ===\n",
      "\n",
      "Example 1: Product statistics\n",
      "            Total_Revenue  Avg_Order  Num_Orders  Min_Order  Max_Order\n",
      "product                                                               \n",
      "Laptop          181627.65    4223.90          43     254.15   14995.00\n",
      "Phone           149261.70    5330.78          28     508.30   14995.00\n",
      "Tablet          146091.55    3948.42          37     284.05   14245.25\n",
      "Camera          108263.20    3184.21          34     479.20   14995.00\n",
      "Headphones      103322.00    3038.88          34     284.05   11996.00\n",
      "Watch            96575.45    4023.98          24     538.20   12745.75\n",
      "\n",
      "Example 2: Revenue statistics by region\n",
      "           Mean   Median  Std_Dev     Min       Max\n",
      "region                                             \n",
      "East    4039.02  2468.10  4142.94  254.15  14995.00\n",
      "North   4025.54  2924.03  3632.26  269.10  14995.00\n",
      "South   3393.49  2396.00  3177.71  508.30  12745.75\n",
      "West    4109.91  2638.18  3840.08  284.05  14995.00\n",
      "\n",
      "Example 3: Unique products per region\n",
      "region\n",
      "East     6\n",
      "North    6\n",
      "South    6\n",
      "West     6\n",
      "Name: product, dtype: int64\n",
      "\n",
      "Example 4: First and last order date by product\n",
      "           First_Order Last_Order\n",
      "product                          \n",
      "Camera      2024-01-03 2024-02-08\n",
      "Headphones  2024-01-24 2024-02-27\n",
      "Laptop      2024-03-12 2024-02-21\n",
      "Phone       2024-02-21 2024-02-01\n",
      "Tablet      2024-01-15 2024-02-20\n",
      "Watch       2024-03-01 2024-03-02\n",
      "\n",
      "Example 5: 25th, 50th, 75th percentile of order amounts\n",
      "customer_type      \n",
      "New            0.25    1136.20\n",
      "               0.50    2876.80\n",
      "               0.75    5697.15\n",
      "Returning      0.25    1207.01\n",
      "               0.50    2344.22\n",
      "               0.75    5397.98\n",
      "VIP            0.25    1138.10\n",
      "               0.50    2598.00\n",
      "               0.75    4798.40\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Example 6: Difference between size() and count()\n",
      "\n",
      "size() - includes NaN:\n",
      "product\n",
      "Camera        34\n",
      "Headphones    34\n",
      "Laptop        43\n",
      "Phone         28\n",
      "Tablet        37\n",
      "Watch         24\n",
      "dtype: int64\n",
      "\n",
      "count() - excludes NaN:\n",
      "product\n",
      "Camera        34\n",
      "Headphones    34\n",
      "Laptop        43\n",
      "Phone         28\n",
      "Tablet        37\n",
      "Watch         24\n",
      "Name: total_amount, dtype: int64\n",
      "\n",
      "Note: They're the same if no NaN values exist\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AGGREGATION FUNCTIONS ===\\n\")\n",
    "\n",
    "# Example 1: Multiple aggregations on single column\n",
    "print(\"Example 1: Product statistics\")\n",
    "product_stats = sales_df.groupby('product')['total_amount'].agg(['sum', 'mean', 'count', 'min', 'max'])\n",
    "product_stats.columns = ['Total_Revenue', 'Avg_Order', 'Num_Orders', 'Min_Order', 'Max_Order']\n",
    "print(product_stats.sort_values('Total_Revenue', ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 2: Statistical measures\n",
    "print(\"Example 2: Revenue statistics by region\")\n",
    "region_stats = sales_df.groupby('region')['total_amount'].agg([\n",
    "    'mean', 'median', 'std', 'min', 'max'\n",
    "])\n",
    "region_stats.columns = ['Mean', 'Median', 'Std_Dev', 'Min', 'Max']\n",
    "print(region_stats)\n",
    "print()\n",
    "\n",
    "# Example 3: Count unique values\n",
    "print(\"Example 3: Unique products per region\")\n",
    "unique_products = sales_df.groupby('region')['product'].nunique()\n",
    "print(unique_products)\n",
    "print()\n",
    "\n",
    "# Example 4: First and last dates\n",
    "print(\"Example 4: First and last order date by product\")\n",
    "date_range = sales_df.groupby('product')['date'].agg(['first', 'last'])\n",
    "date_range.columns = ['First_Order', 'Last_Order']\n",
    "print(date_range)\n",
    "print()\n",
    "\n",
    "# Example 5: Quantiles\n",
    "print(\"Example 5: 25th, 50th, 75th percentile of order amounts\")\n",
    "quantiles = sales_df.groupby('customer_type')['total_amount'].quantile([0.25, 0.5, 0.75])\n",
    "print(quantiles)\n",
    "print()\n",
    "\n",
    "# Example 6: Size vs count\n",
    "print(\"Example 6: Difference between size() and count()\")\n",
    "print(\"\\nsize() - includes NaN:\")\n",
    "print(sales_df.groupby('product').size())\n",
    "print(\"\\ncount() - excludes NaN:\")\n",
    "print(sales_df.groupby('product')['total_amount'].count())\n",
    "print(\"\\nNote: They're the same if no NaN values exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182fa473",
   "metadata": {},
   "source": [
    "## 3. Aggregating Multiple Columns\n",
    "\n",
    "### Different Aggregations for Different Columns\n",
    "\n",
    "```python\n",
    "df.groupby('category').agg({\n",
    "    'sales': 'sum',\n",
    "    'profit': 'mean',\n",
    "    'customer': 'nunique'\n",
    "})\n",
    "```\n",
    "\n",
    "### Multiple Aggregations per Column\n",
    "\n",
    "```python\n",
    "df.groupby('category').agg({\n",
    "    'sales': ['sum', 'mean', 'count'],\n",
    "    'profit': ['sum', 'mean']\n",
    "})\n",
    "```\n",
    "\n",
    "### Named Aggregations (Pandas 0.25+)\n",
    "\n",
    "```python\n",
    "df.groupby('category').agg(\n",
    "    total_sales=('sales', 'sum'),\n",
    "    avg_profit=('profit', 'mean'),\n",
    "    unique_customers=('customer', 'nunique')\n",
    ")\n",
    "```\n",
    "\n",
    "### Benefits of Named Aggregations\n",
    "- ✅ Clear column names\n",
    "- ✅ No MultiIndex columns\n",
    "- ✅ More readable code\n",
    "- ✅ Easier to work with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0aa0b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULTIPLE COLUMN AGGREGATION ===\n",
      "\n",
      "Example 1: Product performance metrics\n",
      "            Total_Revenue  Units_Sold  Num_Orders  Avg_Discount\n",
      "product                                                        \n",
      "Laptop          181627.65         136          43          6.51\n",
      "Phone           149261.70         100          28          6.79\n",
      "Tablet          146091.55         105          37          5.68\n",
      "Camera          108263.20          85          34          4.41\n",
      "Headphones      103322.00         100          34          6.76\n",
      "Watch            96575.45          71          24          7.50\n",
      "\n",
      "Example 2: Comprehensive product analysis\n",
      "           total_amount                    quantity       order_id\n",
      "                    sum     mean       max      sum  mean    count\n",
      "product                                                           \n",
      "Camera        108263.20  3184.21  14995.00       85  2.50       34\n",
      "Headphones    103322.00  3038.88  11996.00      100  2.94       34\n",
      "Laptop        181627.65  4223.90  14995.00      136  3.16       43\n",
      "Phone         149261.70  5330.78  14995.00      100  3.57       28\n",
      "Tablet        146091.55  3948.42  14245.25      105  2.84       37\n",
      "Watch          96575.45  4023.98  12745.75       71  2.96       24\n",
      "\n",
      "Example 3: Named aggregations (recommended)\n",
      "            total_revenue  avg_order_value  max_order  units_sold  num_orders  \\\n",
      "product                                                                         \n",
      "Laptop          181627.65          4223.90   14995.00         136          43   \n",
      "Phone           149261.70          5330.78   14995.00         100          28   \n",
      "Tablet          146091.55          3948.42   14245.25         105          37   \n",
      "Camera          108263.20          3184.21   14995.00          85          34   \n",
      "Headphones      103322.00          3038.88   11996.00         100          34   \n",
      "Watch            96575.45          4023.98   12745.75          71          24   \n",
      "\n",
      "            avg_discount  \n",
      "product                   \n",
      "Laptop              6.51  \n",
      "Phone               6.79  \n",
      "Tablet              5.68  \n",
      "Camera              4.41  \n",
      "Headphones          6.76  \n",
      "Watch               7.50  \n",
      "\n",
      "Example 4: Formatted results\n",
      "        total_revenue  avg_order_value  num_orders\n",
      "region                                            \n",
      "North       265685.80          4025.54          66\n",
      "West        197275.65          4109.91          48\n",
      "East        189834.10          4039.02          47\n",
      "South       132346.00          3393.49          39\n",
      "\n",
      "Example 5: Customer type analysis\n",
      "               total_revenue  avg_order  median_order  total_orders  \\\n",
      "customer_type                                                         \n",
      "New                355387.60    4181.03       2876.80            85   \n",
      "Returning          275700.65    3725.68       2344.22            74   \n",
      "VIP                154053.30    3757.40       2598.00            41   \n",
      "\n",
      "               unique_products  avg_quantity  avg_discount  \n",
      "customer_type                                               \n",
      "New                          6          3.18          6.35  \n",
      "Returning                    6          2.86          5.81  \n",
      "VIP                          6          2.80          6.59  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== MULTIPLE COLUMN AGGREGATION ===\\n\")\n",
    "\n",
    "# Example 1: Different aggregations for different columns\n",
    "print(\"Example 1: Product performance metrics\")\n",
    "product_metrics = sales_df.groupby('product').agg({\n",
    "    'total_amount': 'sum',\n",
    "    'quantity': 'sum',\n",
    "    'order_id': 'count',\n",
    "    'discount_%': 'mean'\n",
    "})\n",
    "product_metrics.columns = ['Total_Revenue', 'Units_Sold', 'Num_Orders', 'Avg_Discount']\n",
    "print(product_metrics.sort_values('Total_Revenue', ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 2: Multiple aggregations per column\n",
    "print(\"Example 2: Comprehensive product analysis\")\n",
    "comprehensive = sales_df.groupby('product').agg({\n",
    "    'total_amount': ['sum', 'mean', 'max'],\n",
    "    'quantity': ['sum', 'mean'],\n",
    "    'order_id': 'count'\n",
    "})\n",
    "print(comprehensive)\n",
    "print()\n",
    "\n",
    "# Example 3: Named aggregations (cleaner)\n",
    "print(\"Example 3: Named aggregations (recommended)\")\n",
    "named_agg = sales_df.groupby('product').agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    avg_order_value=('total_amount', 'mean'),\n",
    "    max_order=('total_amount', 'max'),\n",
    "    units_sold=('quantity', 'sum'),\n",
    "    num_orders=('order_id', 'count'),\n",
    "    avg_discount=('discount_%', 'mean')\n",
    ")\n",
    "print(named_agg.sort_values('total_revenue', ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 4: Custom aggregation names with round\n",
    "print(\"Example 4: Formatted results\")\n",
    "formatted = sales_df.groupby('region').agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    avg_order_value=('total_amount', 'mean'),\n",
    "    num_orders=('order_id', 'count')\n",
    ").round(2)\n",
    "print(formatted.sort_values('total_revenue', ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 5: Complex aggregations\n",
    "print(\"Example 5: Customer type analysis\")\n",
    "customer_analysis = sales_df.groupby('customer_type').agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    avg_order=('total_amount', 'mean'),\n",
    "    median_order=('total_amount', 'median'),\n",
    "    total_orders=('order_id', 'count'),\n",
    "    unique_products=('product', 'nunique'),\n",
    "    avg_quantity=('quantity', 'mean'),\n",
    "    avg_discount=('discount_%', 'mean')\n",
    ").round(2)\n",
    "print(customer_analysis.sort_values('total_revenue', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95257b78",
   "metadata": {},
   "source": [
    "## 4. Grouping by Multiple Columns\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "# Group by multiple columns\n",
    "df.groupby(['col1', 'col2'])['value'].sum()\n",
    "```\n",
    "\n",
    "### How It Works\n",
    "\n",
    "Creates groups for each **unique combination** of values:\n",
    "\n",
    "```\n",
    "Original Data:\n",
    "Product   Region   Sales\n",
    "Laptop    North    1000\n",
    "Laptop    South     800\n",
    "Phone     North     600\n",
    "Phone     South     500\n",
    "\n",
    "After groupby(['Product', 'Region']):\n",
    "\n",
    "Group 1: (Laptop, North)  → 1000\n",
    "Group 2: (Laptop, South)  → 800\n",
    "Group 3: (Phone, North)   → 600\n",
    "Group 4: (Phone, South)   → 500\n",
    "```\n",
    "\n",
    "### MultiIndex Result\n",
    "\n",
    "Result has a **MultiIndex** (hierarchical index):\n",
    "\n",
    "```python\n",
    "result = df.groupby(['Product', 'Region'])['Sales'].sum()\n",
    "# Index: (Laptop, North), (Laptop, South), ...\n",
    "```\n",
    "\n",
    "### Reset Index\n",
    "\n",
    "```python\n",
    "# Convert MultiIndex back to columns\n",
    "result.reset_index()\n",
    "```\n",
    "\n",
    "### Use Cases\n",
    "- Sales by product × region\n",
    "- Revenue by year × month\n",
    "- Performance by team × employee\n",
    "- Cross-dimensional analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293940d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GROUPING BY MULTIPLE COLUMNS ===\n",
      "\n",
      "Example 1: Sales by product and region\n",
      "product     region\n",
      "Laptop      West      71423.70\n",
      "            North     70954.30\n",
      "Tablet      North     56759.35\n",
      "Phone       North     52722.45\n",
      "Camera      East      46293.70\n",
      "Phone       East      39094.20\n",
      "Headphones  West      34402.25\n",
      "Camera      North     32933.60\n",
      "Tablet      East      31622.05\n",
      "Watch       South     30745.40\n",
      "Tablet      West      30248.45\n",
      "Phone       West      29749.75\n",
      "Watch       North     28463.35\n",
      "Phone       South     27695.30\n",
      "Tablet      South     27461.70\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Index type: <class 'pandas.core.indexes.multi.MultiIndex'>\n",
      "\n",
      "Example 2: Same data with reset index\n",
      "       Product Region  Total_Sales\n",
      "11      Laptop   West     71423.70\n",
      "9       Laptop  North     70954.30\n",
      "17      Tablet  North     56759.35\n",
      "13       Phone  North     52722.45\n",
      "0       Camera   East     46293.70\n",
      "12       Phone   East     39094.20\n",
      "7   Headphones   West     34402.25\n",
      "1       Camera  North     32933.60\n",
      "16      Tablet   East     31622.05\n",
      "22       Watch  South     30745.40\n",
      "\n",
      "Example 3: Product × Region × Customer Type\n",
      "                                 total_sales  num_orders  avg_order\n",
      "product    region customer_type                                    \n",
      "Laptop     North  New               51798.80          10    5179.88\n",
      "Tablet     North  New               41827.70           9    4647.52\n",
      "Laptop     West   New               31922.10           6    5320.35\n",
      "Headphones West   New               28793.30           4    7198.32\n",
      "Laptop     West   Returning         27505.60           5    5501.12\n",
      "Tablet     East   Returning         26046.65           4    6511.66\n",
      "Watch      South  New               24517.20           3    8172.40\n",
      "Phone      East   Returning         23913.70           3    7971.23\n",
      "Camera     East   VIP               22324.05           4    5581.01\n",
      "Phone      North  Returning         20939.05           3    6979.68\n",
      "Laptop     East   New               19744.15           3    6581.38\n",
      "Camera     North  New               17447.95           5    3489.59\n",
      "           East   Returning         17393.30           2    8696.65\n",
      "Phone      North  VIP               17391.00           2    8695.50\n",
      "           South  New               17192.00           2    8596.00\n",
      "\n",
      "Example 4: Monthly product sales\n",
      "       month     product  total_revenue  num_orders\n",
      "3   February       Phone       80948.70          14\n",
      "2   February      Laptop       77787.80          13\n",
      "16     March      Tablet       67693.90          19\n",
      "14     March      Laptop       60305.50          17\n",
      "1   February  Headphones       51295.35          14\n",
      "4   February      Tablet       49429.05           7\n",
      "17     March       Watch       47773.00           9\n",
      "15     March       Phone       47505.20           9\n",
      "8    January      Laptop       43534.35          13\n",
      "0   February      Camera       42294.35           9\n",
      "6    January      Camera       39743.75          16\n",
      "7    January  Headphones       30601.45          12\n",
      "10   January      Tablet       28968.60          11\n",
      "11   January       Watch       28232.40           8\n",
      "12     March      Camera       26225.10           9\n",
      "\n",
      "Example 5: Region × Customer Type performance\n",
      "   region customer_type  total_revenue  avg_order  num_orders  units_sold  \\\n",
      "3   North           New      142666.65    4323.23          33          94   \n",
      "1    East     Returning       87746.10    5484.13          16          52   \n",
      "6   South           New       78885.05    4382.50          18          63   \n",
      "10   West     Returning       77239.55    3510.89          22          70   \n",
      "9    West           New       76383.85    4493.17          17          62   \n",
      "4   North     Returning       65942.05    3663.45          18          41   \n",
      "0    East           New       57452.05    3379.53          17          51   \n",
      "5   North           VIP       57077.10    3805.14          15          41   \n",
      "7   South     Returning       44772.95    2487.39          18          49   \n",
      "2    East           VIP       44635.95    3188.28          14          36   \n",
      "11   West           VIP       43652.25    4850.25           9          26   \n",
      "8   South           VIP        8688.00    2896.00           3          12   \n",
      "\n",
      "    unique_products  \n",
      "3                 6  \n",
      "1                 6  \n",
      "6                 6  \n",
      "10                6  \n",
      "9                 6  \n",
      "4                 6  \n",
      "0                 6  \n",
      "5                 5  \n",
      "7                 5  \n",
      "2                 5  \n",
      "11                5  \n",
      "8                 3  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== GROUPING BY MULTIPLE COLUMNS ===\\n\")\n",
    "\n",
    "# Example 1: Product × Region analysis\n",
    "print(\"Example 1: Sales by product and region\")\n",
    "product_region = sales_df.groupby(['product', 'region'])['total_amount'].sum()\n",
    "print(product_region.sort_values(ascending=False).head(15))\n",
    "print(f\"\\nIndex type: {type(product_region.index)}\")\n",
    "print()\n",
    "\n",
    "# Example 2: Reset index for cleaner output\n",
    "print(\"Example 2: Same data with reset index\")\n",
    "product_region_df = sales_df.groupby(['product', 'region'])['total_amount'].sum().reset_index()\n",
    "product_region_df.columns = ['Product', 'Region', 'Total_Sales']\n",
    "print(product_region_df.sort_values('Total_Sales', ascending=False).head(10))\n",
    "print()\n",
    "\n",
    "# Example 3: Three-way grouping\n",
    "print(\"Example 3: Product × Region × Customer Type\")\n",
    "three_way = sales_df.groupby(['product', 'region', 'customer_type']).agg(\n",
    "    total_sales=('total_amount', 'sum'),\n",
    "    num_orders=('order_id', 'count'),\n",
    "    avg_order=('total_amount', 'mean')\n",
    ").round(2)\n",
    "print(three_way.sort_values('total_sales', ascending=False).head(15))\n",
    "print()\n",
    "\n",
    "# Example 4: Month × Product analysis\n",
    "print(\"Example 4: Monthly product sales\")\n",
    "monthly_product = sales_df.groupby(['month', 'product']).agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    num_orders=('order_id', 'count')\n",
    ").reset_index()\n",
    "print(monthly_product.sort_values('total_revenue', ascending=False).head(15))\n",
    "print()\n",
    "\n",
    "# Example 5: Comprehensive multi-dimensional analysis\n",
    "print(\"Example 5: Region × Customer Type performance\")\n",
    "region_customer = sales_df.groupby(['region', 'customer_type']).agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    avg_order=('total_amount', 'mean'),\n",
    "    num_orders=('order_id', 'count'),\n",
    "    units_sold=('quantity', 'sum'),\n",
    "    unique_products=('product', 'nunique')\n",
    ").round(2).reset_index()\n",
    "print(region_customer.sort_values('total_revenue', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e77553",
   "metadata": {},
   "source": [
    "## 5. Transform vs Aggregation\n",
    "\n",
    "### Key Difference\n",
    "\n",
    "| Operation | Returns | Shape | Use Case |\n",
    "|-----------|---------|-------|----------|\n",
    "| **Aggregation** | Summary per group | Reduced (fewer rows) | Get group totals |\n",
    "| **Transform** | Value per row | Same as original | Add group stats to each row |\n",
    "\n",
    "### Visual Comparison\n",
    "\n",
    "```\n",
    "Original (5 rows):\n",
    "Product   Sales\n",
    "Laptop    1000\n",
    "Laptop     800\n",
    "Phone      500\n",
    "Phone      600\n",
    "Tablet     700\n",
    "\n",
    "AGGREGATION (3 rows - one per group):\n",
    "Product   Total_Sales\n",
    "Laptop    1800\n",
    "Phone     1100\n",
    "Tablet     700\n",
    "\n",
    "TRANSFORM (5 rows - same as original):\n",
    "Product   Sales   Group_Total\n",
    "Laptop    1000    1800\n",
    "Laptop     800    1800\n",
    "Phone      500    1100\n",
    "Phone      600    1100\n",
    "Tablet     700     700\n",
    "```\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "# Aggregation - reduces rows\n",
    "df.groupby('category')['sales'].sum()\n",
    "\n",
    "# Transform - keeps all rows\n",
    "df['group_total'] = df.groupby('category')['sales'].transform('sum')\n",
    "```\n",
    "\n",
    "### Common Use Cases for Transform\n",
    "- Add group mean/median to each row\n",
    "- Calculate percentage of group total\n",
    "- Normalize within groups\n",
    "- Fill missing values with group average\n",
    "- Compare individual to group performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8539ec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRANSFORM VS AGGREGATION ===\n",
      "\n",
      "Example 1: Aggregation vs Transform\n",
      "\n",
      "Aggregation (reduces rows):\n",
      "Shape: (6,)\n",
      "product\n",
      "Camera        108263.20\n",
      "Headphones    103322.00\n",
      "Laptop        181627.65\n",
      "Phone         149261.70\n",
      "Tablet        146091.55\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Transform (same number of rows):\n",
      "Shape: (200, 15)\n",
      "  product  total_amount  product_total\n",
      "0   Phone        569.05      149261.70\n",
      "1  Tablet       5997.00      146091.55\n",
      "2  Laptop        269.10      181627.65\n",
      "3   Watch        538.20       96575.45\n",
      "4  Laptop       3117.60      181627.65\n",
      "5  Laptop        598.00      181627.65\n",
      "6  Tablet        852.15      146091.55\n",
      "7  Laptop       6170.25      181627.65\n",
      "8   Phone      11996.00      149261.70\n",
      "9   Phone      14995.00      149261.70\n",
      "\n",
      "Example 2: Add multiple group statistics\n",
      "  product  total_amount  product_mean  product_max  product_min\n",
      "0   Phone        569.05       5330.78     14995.00       508.30\n",
      "1  Tablet       5997.00       3948.42     14245.25       284.05\n",
      "2  Laptop        269.10       4223.90     14995.00       254.15\n",
      "3   Watch        538.20       4023.98     12745.75       538.20\n",
      "4  Laptop       3117.60       4223.90     14995.00       254.15\n",
      "5  Laptop        598.00       4223.90     14995.00       254.15\n",
      "6  Tablet        852.15       3948.42     14245.25       284.05\n",
      "7  Laptop       6170.25       4223.90     14995.00       254.15\n",
      "8   Phone      11996.00       5330.78     14995.00       508.30\n",
      "9   Phone      14995.00       5330.78     14995.00       508.30\n",
      "\n",
      "Example 3: Percentage of product total\n",
      "       product  total_amount  product_total  pct_of_product_total\n",
      "0        Phone        569.05      149261.70                  0.38\n",
      "1       Tablet       5997.00      146091.55                  4.10\n",
      "2       Laptop        269.10      181627.65                  0.15\n",
      "3        Watch        538.20       96575.45                  0.56\n",
      "4       Laptop       3117.60      181627.65                  1.72\n",
      "5       Laptop        598.00      181627.65                  0.33\n",
      "6       Tablet        852.15      146091.55                  0.58\n",
      "7       Laptop       6170.25      181627.65                  3.40\n",
      "8        Phone      11996.00      149261.70                  8.04\n",
      "9        Phone      14995.00      149261.70                 10.05\n",
      "10  Headphones       2468.10      103322.00                  2.39\n",
      "11      Camera       7196.40      108263.20                  6.65\n",
      "12       Watch        852.15       96575.45                  0.88\n",
      "13      Laptop       1136.20      181627.65                  0.63\n",
      "14      Laptop       1999.00      181627.65                  1.10\n",
      "\n",
      "Example 4: Z-score normalization within products\n",
      "  product  total_amount  product_mean  product_std  z_score\n",
      "0   Phone        569.05       5330.78      4789.77    -0.99\n",
      "1  Tablet       5997.00       3948.42      3558.60     0.58\n",
      "2  Laptop        269.10       4223.90      3915.51    -1.01\n",
      "3   Watch        538.20       4023.98      3447.24    -1.01\n",
      "4  Laptop       3117.60       4223.90      3915.51    -0.28\n",
      "5  Laptop        598.00       4223.90      3915.51    -0.93\n",
      "6  Tablet        852.15       3948.42      3558.60    -0.87\n",
      "7  Laptop       6170.25       4223.90      3915.51     0.50\n",
      "8   Phone      11996.00       5330.78      4789.77     1.39\n",
      "9   Phone      14995.00       5330.78      4789.77     2.02\n",
      "\n",
      "Interpretation: z_score shows how many std devs from product mean\n",
      "\n",
      "Example 5: Rank orders within each product\n",
      "        product  total_amount  product_rank\n",
      "37       Camera      14995.00           1.0\n",
      "144      Camera      11996.00           2.0\n",
      "100      Camera       8997.00           3.0\n",
      "120      Camera       8997.00           3.0\n",
      "158  Headphones      11996.00           1.0\n",
      "196  Headphones       9995.00           2.0\n",
      "19   Headphones       5998.00           3.0\n",
      "76       Laptop      14995.00           1.0\n",
      "154      Laptop      14995.00           1.0\n",
      "113      Laptop      13495.50           2.0\n",
      "33       Laptop      11996.00           3.0\n",
      "9         Phone      14995.00           1.0\n",
      "20        Phone      14995.00           1.0\n",
      "29        Phone      14245.25           2.0\n",
      "8         Phone      11996.00           3.0\n",
      "\n",
      "Example 6: Fill missing with group mean (demo)\n",
      "Before filling:\n",
      "  product  total_amount\n",
      "0   Phone        569.05\n",
      "1  Tablet       5997.00\n",
      "2  Laptop           NaN\n",
      "3   Watch        538.20\n",
      "4  Laptop       3117.60\n",
      "5  Laptop           NaN\n",
      "6  Tablet        852.15\n",
      "7  Laptop       6170.25\n",
      "8   Phone      11996.00\n",
      "9   Phone      14995.00\n",
      "\n",
      "After filling with group mean:\n",
      "  product  total_amount\n",
      "0   Phone        569.05\n",
      "1  Tablet       5997.00\n",
      "2  Laptop       3105.76\n",
      "3   Watch        538.20\n",
      "4  Laptop       3117.60\n",
      "5  Laptop       3105.76\n",
      "6  Tablet        852.15\n",
      "7  Laptop       6170.25\n",
      "8   Phone      11996.00\n",
      "9   Phone      14995.00\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TRANSFORM VS AGGREGATION ===\\n\")\n",
    "\n",
    "# Example 1: Compare aggregation vs transform\n",
    "print(\"Example 1: Aggregation vs Transform\")\n",
    "print(\"\\nAggregation (reduces rows):\")\n",
    "agg_result = sales_df.groupby('product')['total_amount'].sum()\n",
    "print(f\"Shape: {agg_result.shape}\")\n",
    "print(agg_result.head())\n",
    "\n",
    "print(\"\\nTransform (same number of rows):\")\n",
    "sales_df['product_total'] = sales_df.groupby('product')['total_amount'].transform('sum')\n",
    "print(f\"Shape: {sales_df.shape}\")\n",
    "print(sales_df[['product', 'total_amount', 'product_total']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 2: Add group statistics to each row\n",
    "print(\"Example 2: Add multiple group statistics\")\n",
    "sales_df['product_mean'] = sales_df.groupby('product')['total_amount'].transform('mean')\n",
    "sales_df['product_max'] = sales_df.groupby('product')['total_amount'].transform('max')\n",
    "sales_df['product_min'] = sales_df.groupby('product')['total_amount'].transform('min')\n",
    "print(sales_df[['product', 'total_amount', 'product_mean', 'product_max', 'product_min']].head(10))\n",
    "print()\n",
    "\n",
    "# Example 3: Calculate percentage of group total\n",
    "print(\"Example 3: Percentage of product total\")\n",
    "sales_df['pct_of_product_total'] = (\n",
    "    sales_df['total_amount'] / sales_df['product_total'] * 100\n",
    ").round(2)\n",
    "print(sales_df[['product', 'total_amount', 'product_total', 'pct_of_product_total']].head(15))\n",
    "print()\n",
    "\n",
    "# Example 4: Normalize within groups (z-score)\n",
    "print(\"Example 4: Z-score normalization within products\")\n",
    "sales_df['product_std'] = sales_df.groupby('product')['total_amount'].transform('std')\n",
    "sales_df['z_score'] = (\n",
    "    (sales_df['total_amount'] - sales_df['product_mean']) / sales_df['product_std']\n",
    ").round(2)\n",
    "print(sales_df[['product', 'total_amount', 'product_mean', 'product_std', 'z_score']].head(10))\n",
    "print(\"\\nInterpretation: z_score shows how many std devs from product mean\")\n",
    "print()\n",
    "\n",
    "# Example 5: Rank within groups\n",
    "print(\"Example 5: Rank orders within each product\")\n",
    "sales_df['product_rank'] = sales_df.groupby('product')['total_amount'].rank(\n",
    "    ascending=False, method='dense'\n",
    ")\n",
    "top_orders = sales_df[sales_df['product_rank'] <= 3].sort_values(['product', 'product_rank'])\n",
    "print(top_orders[['product', 'total_amount', 'product_rank']].head(15))\n",
    "print()\n",
    "\n",
    "# Example 6: Fill missing values with group mean\n",
    "print(\"Example 6: Fill missing with group mean (demo)\")\n",
    "# Create sample with missing values\n",
    "demo_df = sales_df[['product', 'total_amount']].head(20).copy()\n",
    "demo_df.loc[2, 'total_amount'] = np.nan\n",
    "demo_df.loc[5, 'total_amount'] = np.nan\n",
    "print(\"Before filling:\")\n",
    "print(demo_df.head(10))\n",
    "print()\n",
    "demo_df['total_amount'] = demo_df.groupby('product')['total_amount'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "print(\"After filling with group mean:\")\n",
    "print(demo_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ddeff0",
   "metadata": {},
   "source": [
    "## 6. Filtering Groups\n",
    "\n",
    "### What is Group Filtering?\n",
    "\n",
    "**Filter** keeps or removes **entire groups** based on group properties.\n",
    "\n",
    "### Difference from Row Filtering\n",
    "\n",
    "```python\n",
    "# Row filtering: Keep rows where sales > 1000\n",
    "df[df['sales'] > 1000]\n",
    "\n",
    "# Group filtering: Keep groups where total sales > 10000\n",
    "df.groupby('product').filter(lambda x: x['sales'].sum() > 10000)\n",
    "```\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "df.groupby('column').filter(function)\n",
    "```\n",
    "\n",
    "### Visual Example\n",
    "\n",
    "```\n",
    "Original Data:\n",
    "Product   Sales\n",
    "Laptop    1000    ┐\n",
    "Laptop     800    ├─ Total: 1800 ✅ Keep\n",
    "Phone      200    ┘\n",
    "Phone      150    ├─ Total: 350 ❌ Remove\n",
    "Tablet    1200    ┘\n",
    "Tablet     900    ├─ Total: 2100 ✅ Keep\n",
    "\n",
    "Filter: Keep groups with total > 500\n",
    "\n",
    "Result:\n",
    "Product   Sales\n",
    "Laptop    1000\n",
    "Laptop     800\n",
    "Tablet    1200\n",
    "Tablet     900\n",
    "```\n",
    "\n",
    "### Common Use Cases\n",
    "- Keep products with > 100 orders\n",
    "- Remove customers with < $1000 spend\n",
    "- Keep categories with > 5 unique items\n",
    "- Filter groups by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d944d138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FILTERING GROUPS ===\n",
      "\n",
      "Example 1: Products with total sales > $20,000\n",
      "Original rows: 200\n",
      "After filtering: 200\n",
      "\n",
      "Products kept:\n",
      "product\n",
      "Laptop        181627.65\n",
      "Phone         149261.70\n",
      "Tablet        146091.55\n",
      "Camera        108263.20\n",
      "Headphones    103322.00\n",
      "Watch          96575.45\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Example 2: Regions with more than 40 orders\n",
      "Region order counts:\n",
      "region\n",
      "North    66\n",
      "West     48\n",
      "East     47\n",
      "dtype: int64\n",
      "\n",
      "Example 3: Products with high average order value\n",
      "               mean  count\n",
      "product                   \n",
      "Phone       5330.78     28\n",
      "Laptop      4223.90     43\n",
      "Watch       4023.98     24\n",
      "Tablet      3948.42     37\n",
      "Camera      3184.21     34\n",
      "Headphones  3038.88     34\n",
      "\n",
      "Example 4: Products with consistent pricing (low std dev)\n",
      "Empty DataFrame\n",
      "Columns: [mean, std]\n",
      "Index: []\n",
      "\n",
      "Example 5: Products with >30 orders AND avg order >$1500\n",
      "            num_orders  avg_order  total_revenue\n",
      "product                                         \n",
      "Laptop              43    4223.90      181627.65\n",
      "Tablet              37    3948.42      146091.55\n",
      "Camera              34    3184.21      108263.20\n",
      "Headphones          34    3038.88      103322.00\n",
      "\n",
      "Example 6: Filter (entire groups) vs Boolean indexing (individual rows)\n",
      "\n",
      "Boolean indexing (rows with sales > 3000):\n",
      "Rows kept: 82\n",
      "\n",
      "Group filter (products with total > 20000):\n",
      "Rows kept: 200\n",
      "\n",
      "Note: Filter keeps ALL rows of matching groups!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== FILTERING GROUPS ===\\n\")\n",
    "\n",
    "# Example 1: Keep products with total sales > $20,000\n",
    "print(\"Example 1: Products with total sales > $20,000\")\n",
    "high_revenue_products = sales_df.groupby('product').filter(\n",
    "    lambda x: x['total_amount'].sum() > 20000\n",
    ")\n",
    "print(f\"Original rows: {len(sales_df)}\")\n",
    "print(f\"After filtering: {len(high_revenue_products)}\")\n",
    "print(\"\\nProducts kept:\")\n",
    "print(high_revenue_products.groupby('product')['total_amount'].sum().sort_values(ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 2: Keep regions with > 40 orders\n",
    "print(\"Example 2: Regions with more than 40 orders\")\n",
    "busy_regions = sales_df.groupby('region').filter(\n",
    "    lambda x: len(x) > 40\n",
    ")\n",
    "print(\"Region order counts:\")\n",
    "print(busy_regions.groupby('region').size().sort_values(ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 3: Keep products with average order > $2000\n",
    "print(\"Example 3: Products with high average order value\")\n",
    "high_aov_products = sales_df.groupby('product').filter(\n",
    "    lambda x: x['total_amount'].mean() > 2000\n",
    ")\n",
    "print(high_aov_products.groupby('product')['total_amount'].agg(['mean', 'count']).sort_values('mean', ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 4: Keep groups with low variability (std < 500)\n",
    "print(\"Example 4: Products with consistent pricing (low std dev)\")\n",
    "consistent_products = sales_df.groupby('product').filter(\n",
    "    lambda x: x['total_amount'].std() < 500\n",
    ")\n",
    "print(consistent_products.groupby('product')['total_amount'].agg(['mean', 'std']).sort_values('std'))\n",
    "print()\n",
    "\n",
    "# Example 5: Complex filter - multiple conditions\n",
    "print(\"Example 5: Products with >30 orders AND avg order >$1500\")\n",
    "premium_products = sales_df.groupby('product').filter(\n",
    "    lambda x: (len(x) > 30) and (x['total_amount'].mean() > 1500)\n",
    ")\n",
    "print(premium_products.groupby('product').agg(\n",
    "    num_orders=('order_id', 'count'),\n",
    "    avg_order=('total_amount', 'mean'),\n",
    "    total_revenue=('total_amount', 'sum')\n",
    ").round(2).sort_values('total_revenue', ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 6: Filter vs normal boolean indexing comparison\n",
    "print(\"Example 6: Filter (entire groups) vs Boolean indexing (individual rows)\")\n",
    "print(\"\\nBoolean indexing (rows with sales > 3000):\")\n",
    "high_sales_rows = sales_df[sales_df['total_amount'] > 3000]\n",
    "print(f\"Rows kept: {len(high_sales_rows)}\")\n",
    "print()\n",
    "print(\"Group filter (products with total > 20000):\")\n",
    "print(f\"Rows kept: {len(high_revenue_products)}\")\n",
    "print(\"\\nNote: Filter keeps ALL rows of matching groups!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496eb80b",
   "metadata": {},
   "source": [
    "## 7. Apply and Custom Functions\n",
    "\n",
    "### Using apply() with GroupBy\n",
    "\n",
    "**`apply()`** allows you to apply **any function** to each group.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "df.groupby('category').apply(function)\n",
    "```\n",
    "\n",
    "### When to Use apply()\n",
    "\n",
    "| Scenario | Use |\n",
    "|----------|-----|\n",
    "| **Built-in aggregation** (sum, mean) | `groupby().sum()` ✅ Faster |\n",
    "| **Custom logic** | `groupby().apply()` |\n",
    "| **Multiple operations** | `groupby().apply()` |\n",
    "| **Return DataFrame per group** | `groupby().apply()` |\n",
    "\n",
    "### Function Types\n",
    "\n",
    "**1. Lambda functions**\n",
    "```python\n",
    "df.groupby('cat').apply(lambda x: x['sales'].max() - x['sales'].min())\n",
    "```\n",
    "\n",
    "**2. Named functions**\n",
    "```python\n",
    "def custom_stats(group):\n",
    "    return pd.Series({\n",
    "        'total': group['sales'].sum(),\n",
    "        'avg': group['sales'].mean()\n",
    "    })\n",
    "\n",
    "df.groupby('cat').apply(custom_stats)\n",
    "```\n",
    "\n",
    "**3. Return DataFrame**\n",
    "```python\n",
    "def top_n(group, n=3):\n",
    "    return group.nlargest(n, 'sales')\n",
    "\n",
    "df.groupby('cat').apply(top_n, n=5)\n",
    "```\n",
    "\n",
    "### Common Custom Operations\n",
    "- Calculate range (max - min)\n",
    "- Get top N rows per group\n",
    "- Complex statistical calculations\n",
    "- Custom business logic\n",
    "- Weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093826a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APPLY AND CUSTOM FUNCTIONS ===\n",
      "\n",
      "Example 1: Revenue range per product (max - min)\n",
      "product\n",
      "Laptop        14740.85\n",
      "Camera        14515.80\n",
      "Phone         14486.70\n",
      "Tablet        13961.20\n",
      "Watch         12207.55\n",
      "Headphones    11711.95\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Example 2: Custom statistics function\n",
      "            total_revenue  avg_order  revenue_range  num_orders  total_units\n",
      "product                                                                     \n",
      "Laptop          181627.65    4223.90       14740.85        43.0        136.0\n",
      "Phone           149261.70    5330.78       14486.70        28.0        100.0\n",
      "Tablet          146091.55    3948.42       13961.20        37.0        105.0\n",
      "Camera          108263.20    3184.21       14515.80        34.0         85.0\n",
      "Headphones      103322.00    3038.88       11711.95        34.0        100.0\n",
      "Watch            96575.45    4023.98       12207.55        24.0         71.0\n",
      "\n",
      "Example 3: Top 3 orders for each product\n",
      "                order_id  total_amount       date\n",
      "product                                          \n",
      "Camera     37       1038      14995.00 2024-02-20\n",
      "           144      1145      11996.00 2024-02-11\n",
      "           100      1101       8997.00 2024-03-29\n",
      "Headphones 158      1159      11996.00 2024-02-28\n",
      "           196      1197       9995.00 2024-02-27\n",
      "           19       1020       5998.00 2024-03-04\n",
      "Laptop     76       1077      14995.00 2024-02-03\n",
      "           154      1155      14995.00 2024-02-05\n",
      "           113      1114      13495.50 2024-02-02\n",
      "Phone      9        1010      14995.00 2024-03-28\n",
      "           20       1021      14995.00 2024-02-29\n",
      "           29       1030      14245.25 2024-02-11\n",
      "Tablet     115      1116      14245.25 2024-02-10\n",
      "           15       1016      11996.00 2024-03-28\n",
      "           90       1091       9495.25 2024-02-22\n",
      "\n",
      "Example 4: Weighted average price by quantity\n",
      "product\n",
      "Phone         1572.00\n",
      "Watch         1515.90\n",
      "Tablet        1469.48\n",
      "Laptop        1429.15\n",
      "Camera        1316.65\n",
      "Headphones    1116.00\n",
      "dtype: float64\n",
      "\n",
      "Example 5: Performance score (custom business logic)\n",
      "product\n",
      "Laptop        1994.12\n",
      "Tablet        1518.54\n",
      "Headphones    1338.16\n",
      "Camera        1039.90\n",
      "Phone          872.37\n",
      "Watch          672.17\n",
      "dtype: float64\n",
      "\n",
      "Example 6: Region × Customer Type performance\n",
      "                      total_revenue  num_orders  avg_order  avg_discount  \\\n",
      "region customer_type                                                       \n",
      "North  New                142666.65        33.0    4323.23          5.61   \n",
      "East   Returning           87746.10        16.0    5484.13          5.00   \n",
      "South  New                 78885.05        18.0    4382.50          4.44   \n",
      "West   Returning           77239.55        22.0    3510.89          6.59   \n",
      "       New                 76383.85        17.0    4493.17          9.12   \n",
      "North  Returning           65942.05        18.0    3663.45          6.39   \n",
      "East   New                 57452.05        17.0    3379.53          7.06   \n",
      "North  VIP                 57077.10        15.0    3805.14          7.00   \n",
      "South  Returning           44772.95        18.0    2487.39          5.00   \n",
      "East   VIP                 44635.95        14.0    3188.28          4.64   \n",
      "\n",
      "                      units_sold  \n",
      "region customer_type              \n",
      "North  New                  94.0  \n",
      "East   Returning            52.0  \n",
      "South  New                  63.0  \n",
      "West   Returning            70.0  \n",
      "       New                  62.0  \n",
      "North  Returning            41.0  \n",
      "East   New                  51.0  \n",
      "North  VIP                  41.0  \n",
      "South  Returning            49.0  \n",
      "East   VIP                  36.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/sfvddbbx4tg14yxq7trqmhyw0000gn/T/ipykernel_1622/3673280966.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  product_stats = sales_df.groupby('product').apply(custom_stats).round(2)\n",
      "/var/folders/d1/sfvddbbx4tg14yxq7trqmhyw0000gn/T/ipykernel_1622/3673280966.py:31: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top_3_per_product = sales_df.groupby('product').apply(top_orders)\n",
      "/var/folders/d1/sfvddbbx4tg14yxq7trqmhyw0000gn/T/ipykernel_1622/3673280966.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  weighted_prices = sales_df.groupby('product').apply(weighted_avg).round(2)\n",
      "/var/folders/d1/sfvddbbx4tg14yxq7trqmhyw0000gn/T/ipykernel_1622/3673280966.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  performance = sales_df.groupby('product').apply(performance_score).round(2)\n",
      "/var/folders/d1/sfvddbbx4tg14yxq7trqmhyw0000gn/T/ipykernel_1622/3673280966.py:69: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  region_customer_perf = sales_df.groupby(['region', 'customer_type']).apply(\n"
     ]
    }
   ],
   "source": [
    "print(\"=== APPLY AND CUSTOM FUNCTIONS ===\\n\")\n",
    "\n",
    "# Example 1: Simple lambda with apply\n",
    "print(\"Example 1: Revenue range per product (max - min)\")\n",
    "revenue_range = sales_df.groupby('product')['total_amount'].apply(\n",
    "    lambda x: x.max() - x.min()\n",
    ")\n",
    "print(revenue_range.sort_values(ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 2: Custom function returning Series\n",
    "print(\"Example 2: Custom statistics function\")\n",
    "def custom_stats(group):\n",
    "    return pd.Series({\n",
    "        'total_revenue': group['total_amount'].sum(),\n",
    "        'avg_order': group['total_amount'].mean(),\n",
    "        'revenue_range': group['total_amount'].max() - group['total_amount'].min(),\n",
    "        'num_orders': len(group),\n",
    "        'total_units': group['quantity'].sum()\n",
    "    })\n",
    "\n",
    "product_stats = sales_df.groupby('product').apply(custom_stats).round(2)\n",
    "print(product_stats.sort_values('total_revenue', ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 3: Get top 3 orders per product\n",
    "print(\"Example 3: Top 3 orders for each product\")\n",
    "def top_orders(group, n=3):\n",
    "    return group.nlargest(n, 'total_amount')[['order_id', 'total_amount', 'date']]\n",
    "\n",
    "top_3_per_product = sales_df.groupby('product').apply(top_orders)\n",
    "print(top_3_per_product.head(15))\n",
    "print()\n",
    "\n",
    "# Example 4: Calculate weighted average\n",
    "print(\"Example 4: Weighted average price by quantity\")\n",
    "def weighted_avg(group):\n",
    "    return (group['unit_price'] * group['quantity']).sum() / group['quantity'].sum()\n",
    "\n",
    "weighted_prices = sales_df.groupby('product').apply(weighted_avg).round(2)\n",
    "print(weighted_prices.sort_values(ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 5: Complex business logic\n",
    "print(\"Example 5: Performance score (custom business logic)\")\n",
    "def performance_score(group):\n",
    "    \"\"\"Calculate performance score: revenue * order_count * avg_rating_proxy\"\"\"\n",
    "    revenue = group['total_amount'].sum()\n",
    "    order_count = len(group)\n",
    "    consistency = 1 / (1 + group['total_amount'].std())  # Lower std = more consistent\n",
    "    score = revenue * order_count * consistency\n",
    "    return score\n",
    "\n",
    "performance = sales_df.groupby('product').apply(performance_score).round(2)\n",
    "print(performance.sort_values(ascending=False))\n",
    "print()\n",
    "\n",
    "# Example 6: Multiple group analysis\n",
    "print(\"Example 6: Region × Customer Type performance\")\n",
    "def region_customer_analysis(group):\n",
    "    return pd.Series({\n",
    "        'total_revenue': group['total_amount'].sum(),\n",
    "        'num_orders': len(group),\n",
    "        'avg_order': group['total_amount'].mean(),\n",
    "        'avg_discount': group['discount_%'].mean(),\n",
    "        'units_sold': group['quantity'].sum()\n",
    "    })\n",
    "\n",
    "region_customer_perf = sales_df.groupby(['region', 'customer_type']).apply(\n",
    "    region_customer_analysis\n",
    ").round(2)\n",
    "print(region_customer_perf.sort_values('total_revenue', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e25d20",
   "metadata": {},
   "source": [
    "## 8. Iterating Over Groups\n",
    "\n",
    "### When to Iterate\n",
    "\n",
    "Use iteration when you need to:\n",
    "- Process each group separately\n",
    "- Generate reports per group\n",
    "- Debug groupby operations\n",
    "- Apply operations that can't be vectorized\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "for name, group in df.groupby('column'):\n",
    "    # name: group identifier\n",
    "    # group: DataFrame for that group\n",
    "    print(f\"Processing {name}\")\n",
    "    print(group)\n",
    "```\n",
    "\n",
    "### Multiple Groupby Columns\n",
    "\n",
    "```python\n",
    "for (col1_val, col2_val), group in df.groupby(['col1', 'col2']):\n",
    "    print(f\"Group: {col1_val}, {col2_val}\")\n",
    "```\n",
    "\n",
    "### Access Specific Group\n",
    "\n",
    "```python\n",
    "# Get specific group\n",
    "grouped = df.groupby('product')\n",
    "laptop_group = grouped.get_group('Laptop')\n",
    "```\n",
    "\n",
    "### Performance Note\n",
    "⚠️ **Iteration is slower** than vectorized operations. Use only when necessary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0416d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ITERATING OVER GROUPS ===\n",
      "\n",
      "Example 1: Iterate and print summary for each product\n",
      "Camera: 34 orders, $108,263.20 revenue\n",
      "Headphones: 34 orders, $103,322.00 revenue\n",
      "Laptop: 43 orders, $181,627.65 revenue\n",
      "Phone: 28 orders, $149,261.70 revenue\n",
      "Tablet: 37 orders, $146,091.55 revenue\n",
      "Watch: 24 orders, $96,575.45 revenue\n",
      "\n",
      "Example 2: Access specific group (Laptop)\n",
      "Laptop orders: 43\n",
      "    order_id  quantity  total_amount\n",
      "2       1003         1        269.10\n",
      "4       1005         3       3117.60\n",
      "5       1006         2        598.00\n",
      "7       1008         5       6170.25\n",
      "13      1014         4       1136.20\n",
      "\n",
      "Example 3: Iterate over region × customer type\n",
      "East - New: $57,452.05\n",
      "East - Returning: $87,746.10\n",
      "East - VIP: $44,635.95\n",
      "North - New: $142,666.65\n",
      "North - Returning: $65,942.05\n",
      "North - VIP: $57,077.10\n",
      "South - New: $78,885.05\n",
      "South - Returning: $44,772.95\n",
      "West - New: $76,383.85\n",
      "West - Returning: $77,239.55\n",
      "West - VIP: $43,652.25\n",
      "\n",
      "Example 4: Generate mini-reports for each region\n",
      "\n",
      "==================================================\n",
      "REGION: East\n",
      "==================================================\n",
      "Total Orders: 47\n",
      "Total Revenue: $189,834.10\n",
      "Avg Order: $4,039.02\n",
      "Top Product: Camera\n",
      "Unique Customers: 3\n",
      "\n",
      "==================================================\n",
      "REGION: North\n",
      "==================================================\n",
      "Total Orders: 66\n",
      "Total Revenue: $265,685.80\n",
      "Avg Order: $4,025.54\n",
      "Top Product: Laptop\n",
      "Unique Customers: 3\n",
      "\n",
      "==================================================\n",
      "REGION: South\n",
      "==================================================\n",
      "Total Orders: 39\n",
      "Total Revenue: $132,346.00\n",
      "Avg Order: $3,393.49\n",
      "Top Product: Camera\n",
      "Unique Customers: 3\n",
      "\n",
      "==================================================\n",
      "REGION: West\n",
      "==================================================\n",
      "Total Orders: 48\n",
      "Total Revenue: $197,275.65\n",
      "Avg Order: $4,109.91\n",
      "Top Product: Laptop\n",
      "Unique Customers: 3\n",
      "\n",
      "Example 5: Process only high-revenue products\n",
      "Camera: $108,263.20 (Avg discount: 4.4%)\n",
      "Headphones: $103,322.00 (Avg discount: 6.8%)\n",
      "Laptop: $181,627.65 (Avg discount: 6.5%)\n",
      "Phone: $149,261.70 (Avg discount: 6.8%)\n",
      "Tablet: $146,091.55 (Avg discount: 5.7%)\n",
      "Watch: $96,575.45 (Avg discount: 7.5%)\n",
      "\n",
      "Example 6: Store each group in a dictionary\n",
      "Available products: ['Camera', 'Headphones', 'Laptop', 'Phone', 'Tablet', 'Watch']\n",
      "\n",
      "Laptop group shape: (43, 22)\n",
      "Phone group shape: (28, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ITERATING OVER GROUPS ===\\n\")\n",
    "\n",
    "# Example 1: Basic iteration\n",
    "print(\"Example 1: Iterate and print summary for each product\")\n",
    "for product_name, product_group in sales_df.groupby('product'):\n",
    "    total = product_group['total_amount'].sum()\n",
    "    count = len(product_group)\n",
    "    print(f\"{product_name}: {count} orders, ${total:,.2f} revenue\")\n",
    "print()\n",
    "\n",
    "# Example 2: Get specific group\n",
    "print(\"Example 2: Access specific group (Laptop)\")\n",
    "grouped = sales_df.groupby('product')\n",
    "laptop_data = grouped.get_group('Laptop')\n",
    "print(f\"Laptop orders: {len(laptop_data)}\")\n",
    "print(laptop_data[['order_id', 'quantity', 'total_amount']].head())\n",
    "print()\n",
    "\n",
    "# Example 3: Multiple groupby columns\n",
    "print(\"Example 3: Iterate over region × customer type\")\n",
    "for (region, cust_type), group in sales_df.groupby(['region', 'customer_type']):\n",
    "    revenue = group['total_amount'].sum()\n",
    "    if revenue > 10000:  # Only show significant segments\n",
    "        print(f\"{region} - {cust_type}: ${revenue:,.2f}\")\n",
    "print()\n",
    "\n",
    "# Example 4: Generate report per group\n",
    "print(\"Example 4: Generate mini-reports for each region\")\n",
    "for region, region_data in sales_df.groupby('region'):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"REGION: {region}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total Orders: {len(region_data)}\")\n",
    "    print(f\"Total Revenue: ${region_data['total_amount'].sum():,.2f}\")\n",
    "    print(f\"Avg Order: ${region_data['total_amount'].mean():,.2f}\")\n",
    "    print(f\"Top Product: {region_data['product'].mode()[0]}\")\n",
    "    print(f\"Unique Customers: {region_data['customer_type'].nunique()}\")\n",
    "print()\n",
    "\n",
    "# Example 5: Filter and process\n",
    "print(\"Example 5: Process only high-revenue products\")\n",
    "for product, product_data in sales_df.groupby('product'):\n",
    "    total_revenue = product_data['total_amount'].sum()\n",
    "    if total_revenue > 30000:\n",
    "        avg_discount = product_data['discount_%'].mean()\n",
    "        print(f\"{product}: ${total_revenue:,.2f} (Avg discount: {avg_discount:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Example 6: Store groups in dictionary\n",
    "print(\"Example 6: Store each group in a dictionary\")\n",
    "product_dict = {}\n",
    "for product, product_data in sales_df.groupby('product'):\n",
    "    product_dict[product] = product_data\n",
    "\n",
    "print(\"Available products:\", list(product_dict.keys()))\n",
    "print(f\"\\nLaptop group shape: {product_dict['Laptop'].shape}\")\n",
    "print(f\"Phone group shape: {product_dict['Phone'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f040d",
   "metadata": {},
   "source": [
    "## 9. Comprehensive Business Analysis Example\n",
    "\n",
    "### Scenario: E-commerce Performance Report\n",
    "\n",
    "**Business Questions:**\n",
    "1. Which products are top performers?\n",
    "2. How do different regions compare?\n",
    "3. What's the performance by customer type?\n",
    "4. What are the monthly trends?\n",
    "5. Which product-region combinations are best?\n",
    "6. What's the discount impact analysis?\n",
    "\n",
    "We'll use multiple groupby techniques to answer these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b53255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE E-COMMERCE PERFORMANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "1. PRODUCT PERFORMANCE ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "            total_revenue  num_orders  avg_order_value  total_units  \\\n",
      "product                                                               \n",
      "Laptop          181627.65          43          4223.90          136   \n",
      "Phone           149261.70          28          5330.78          100   \n",
      "Tablet          146091.55          37          3948.42          105   \n",
      "Camera          108263.20          34          3184.21           85   \n",
      "Headphones      103322.00          34          3038.88          100   \n",
      "Watch            96575.45          24          4023.98           71   \n",
      "\n",
      "            avg_discount  max_order  min_order  market_share_%  \n",
      "product                                                         \n",
      "Laptop              6.51   14995.00     254.15           23.13  \n",
      "Phone               6.79   14995.00     508.30           19.01  \n",
      "Tablet              5.68   14245.25     284.05           18.61  \n",
      "Camera              4.41   14995.00     479.20           13.79  \n",
      "Headphones          6.76   11996.00     284.05           13.16  \n",
      "Watch               7.50   12745.75     538.20           12.30  \n",
      "\n",
      "2. REGIONAL PERFORMANCE\n",
      "--------------------------------------------------------------------------------\n",
      "        total_revenue  num_orders  avg_order  unique_products  total_units\n",
      "region                                                                    \n",
      "North       265685.80          66    4025.54                6          176\n",
      "West        197275.65          48    4109.91                6          158\n",
      "East        189834.10          47    4039.02                6          139\n",
      "South       132346.00          39    3393.49                6          124\n",
      "\n",
      "3. CUSTOMER TYPE ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "               total_revenue  num_orders  avg_order  median_order  avg_units  \\\n",
      "customer_type                                                                  \n",
      "New                355387.60          85    4181.03       2876.80       3.18   \n",
      "Returning          275700.65          74    3725.68       2344.22       2.86   \n",
      "VIP                154053.30          41    3757.40       2598.00       2.80   \n",
      "\n",
      "               avg_discount  revenue_per_order  \n",
      "customer_type                                   \n",
      "New                    6.35            4181.03  \n",
      "Returning              5.81            3725.68  \n",
      "VIP                    6.59            3757.40  \n",
      "\n",
      "4. MONTHLY TRENDS\n",
      "--------------------------------------------------------------------------------\n",
      "          total_revenue  num_orders  avg_order  total_units\n",
      "month                                                      \n",
      "January       191888.35          65    2952.13          158\n",
      "February      322325.30          64    5036.33          225\n",
      "March         270927.90          71    3815.89          214\n",
      "\n",
      "5. TOP PRODUCT-REGION COMBINATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "                   total_revenue  num_orders  avg_order\n",
      "product    region                                      \n",
      "Laptop     West         71423.70          12    5951.98\n",
      "           North        70954.30          17    4173.78\n",
      "Tablet     North        56759.35          14    4054.24\n",
      "Phone      North        52722.45           8    6590.31\n",
      "Camera     East         46293.70          10    4629.37\n",
      "Phone      East         39094.20           8    4886.77\n",
      "Headphones West         34402.25           8    4300.28\n",
      "Camera     North        32933.60          10    3293.36\n",
      "Tablet     East         31622.05           6    5270.34\n",
      "Watch      South        30745.40           7    4392.20\n",
      "Tablet     West         30248.45          11    2749.86\n",
      "Phone      West         29749.75           8    3718.72\n",
      "Watch      North        28463.35           7    4066.19\n",
      "Phone      South        27695.30           4    6923.82\n",
      "Tablet     South        27461.70           6    4576.95\n",
      "\n",
      "6. DISCOUNT IMPACT ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "                   num_orders  total_revenue  avg_order  avg_units  \\\n",
      "discount_category                                                    \n",
      "No Discount                75      323779.00    4317.05       2.95   \n",
      "Low (1-10%)                88      329700.50    3746.60       2.86   \n",
      "Medium (11-20%)            37      131662.05    3558.43       3.35   \n",
      "High (>20%)                 0           0.00        NaN        NaN   \n",
      "\n",
      "                   avg_discount  \n",
      "discount_category                \n",
      "No Discount                0.00  \n",
      "Low (1-10%)                6.93  \n",
      "Medium (11-20%)           17.03  \n",
      "High (>20%)                 NaN  \n",
      "\n",
      "================================================================================\n",
      "EXECUTIVE SUMMARY\n",
      "================================================================================\n",
      "Total Revenue: $785,141.55\n",
      "Total Orders: 200\n",
      "Average Order Value: $3,925.71\n",
      "Total Units Sold: 597\n",
      "\n",
      "Top Product: Laptop ($181,627.65)\n",
      "Top Region: North ($265,685.80)\n",
      "Best Customer Type: New ($355,387.60)\n",
      "\n",
      "Average Discount: 6.20%\n",
      "Orders with Discount: 125 (62.5%)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/sfvddbbx4tg14yxq7trqmhyw0000gn/T/ipykernel_1622/3506594376.py:98: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  discount_impact = sales_df.groupby('discount_category').agg(\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE E-COMMERCE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Question 1: Top performing products\n",
    "print(\"1. PRODUCT PERFORMANCE ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "product_performance = sales_df.groupby('product').agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    num_orders=('order_id', 'count'),\n",
    "    avg_order_value=('total_amount', 'mean'),\n",
    "    total_units=('quantity', 'sum'),\n",
    "    avg_discount=('discount_%', 'mean'),\n",
    "    max_order=('total_amount', 'max'),\n",
    "    min_order=('total_amount', 'min')\n",
    ").round(2).sort_values('total_revenue', ascending=False)\n",
    "\n",
    "# Add market share\n",
    "total_revenue = sales_df['total_amount'].sum()\n",
    "product_performance['market_share_%'] = (\n",
    "    product_performance['total_revenue'] / total_revenue * 100\n",
    ").round(2)\n",
    "\n",
    "print(product_performance)\n",
    "print()\n",
    "\n",
    "# Question 2: Regional comparison\n",
    "print(\"2. REGIONAL PERFORMANCE\")\n",
    "print(\"-\" * 80)\n",
    "regional_performance = sales_df.groupby('region').agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    num_orders=('order_id', 'count'),\n",
    "    avg_order=('total_amount', 'mean'),\n",
    "    unique_products=('product', 'nunique'),\n",
    "    total_units=('quantity', 'sum')\n",
    ").round(2).sort_values('total_revenue', ascending=False)\n",
    "print(regional_performance)\n",
    "print()\n",
    "\n",
    "# Question 3: Customer type analysis\n",
    "print(\"3. CUSTOMER TYPE ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "customer_analysis = sales_df.groupby('customer_type').agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    num_orders=('order_id', 'count'),\n",
    "    avg_order=('total_amount', 'mean'),\n",
    "    median_order=('total_amount', 'median'),\n",
    "    avg_units=('quantity', 'mean'),\n",
    "    avg_discount=('discount_%', 'mean')\n",
    ").round(2).sort_values('total_revenue', ascending=False)\n",
    "\n",
    "# Add revenue per order\n",
    "customer_analysis['revenue_per_order'] = (\n",
    "    customer_analysis['total_revenue'] / customer_analysis['num_orders']\n",
    ").round(2)\n",
    "\n",
    "print(customer_analysis)\n",
    "print()\n",
    "\n",
    "# Question 4: Monthly trends\n",
    "print(\"4. MONTHLY TRENDS\")\n",
    "print(\"-\" * 80)\n",
    "monthly_trends = sales_df.groupby('month').agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    num_orders=('order_id', 'count'),\n",
    "    avg_order=('total_amount', 'mean'),\n",
    "    total_units=('quantity', 'sum')\n",
    ").round(2)\n",
    "\n",
    "# Sort by month order\n",
    "month_order = ['January', 'February', 'March']\n",
    "monthly_trends = monthly_trends.reindex([m for m in month_order if m in monthly_trends.index])\n",
    "print(monthly_trends)\n",
    "print()\n",
    "\n",
    "# Question 5: Product × Region combinations\n",
    "print(\"5. TOP PRODUCT-REGION COMBINATIONS\")\n",
    "print(\"-\" * 80)\n",
    "product_region = sales_df.groupby(['product', 'region']).agg(\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    num_orders=('order_id', 'count'),\n",
    "    avg_order=('total_amount', 'mean')\n",
    ").round(2).sort_values('total_revenue', ascending=False).head(15)\n",
    "print(product_region)\n",
    "print()\n",
    "\n",
    "# Question 6: Discount impact\n",
    "print(\"6. DISCOUNT IMPACT ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "# Create discount bins\n",
    "sales_df['discount_category'] = pd.cut(\n",
    "    sales_df['discount_%'],\n",
    "    bins=[-1, 0, 10, 20, 100],\n",
    "    labels=['No Discount', 'Low (1-10%)', 'Medium (11-20%)', 'High (>20%)']\n",
    ")\n",
    "\n",
    "discount_impact = sales_df.groupby('discount_category').agg(\n",
    "    num_orders=('order_id', 'count'),\n",
    "    total_revenue=('total_amount', 'sum'),\n",
    "    avg_order=('total_amount', 'mean'),\n",
    "    avg_units=('quantity', 'mean'),\n",
    "    avg_discount=('discount_%', 'mean')\n",
    ").round(2)\n",
    "print(discount_impact)\n",
    "print()\n",
    "\n",
    "# Summary metrics\n",
    "print(\"=\"*80)\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total Revenue: ${sales_df['total_amount'].sum():,.2f}\")\n",
    "print(f\"Total Orders: {len(sales_df):,}\")\n",
    "print(f\"Average Order Value: ${sales_df['total_amount'].mean():,.2f}\")\n",
    "print(f\"Total Units Sold: {sales_df['quantity'].sum():,}\")\n",
    "print(f\"\\nTop Product: {product_performance.index[0]} (${product_performance.iloc[0]['total_revenue']:,.2f})\")\n",
    "print(f\"Top Region: {regional_performance.index[0]} (${regional_performance.iloc[0]['total_revenue']:,.2f})\")\n",
    "print(f\"Best Customer Type: {customer_analysis.index[0]} (${customer_analysis.iloc[0]['total_revenue']:,.2f})\")\n",
    "print(f\"\\nAverage Discount: {sales_df['discount_%'].mean():.2f}%\")\n",
    "print(f\"Orders with Discount: {(sales_df['discount_%'] > 0).sum()} ({(sales_df['discount_%'] > 0).sum()/len(sales_df)*100:.1f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d486e8f7",
   "metadata": {},
   "source": [
    "## 10. Advanced GroupBy Techniques\n",
    "\n",
    "### Multiple Column Selection\n",
    "\n",
    "```python\n",
    "# Select multiple columns for aggregation\n",
    "df.groupby('category')[['sales', 'profit']].sum()\n",
    "```\n",
    "\n",
    "### Grouping by Calculated Columns\n",
    "\n",
    "```python\n",
    "# Group by binned values\n",
    "df.groupby(pd.cut(df['age'], bins=[0, 18, 35, 60, 100])).mean()\n",
    "\n",
    "# Group by date components\n",
    "df.groupby(df['date'].dt.year).sum()\n",
    "df.groupby(df['date'].dt.to_period('M')).sum()\n",
    "```\n",
    "\n",
    "### Grouping with Custom Index\n",
    "\n",
    "```python\n",
    "# Group by index level\n",
    "df.groupby(level=0).sum()  # For MultiIndex\n",
    "```\n",
    "\n",
    "### Handling MultiIndex Results\n",
    "\n",
    "```python\n",
    "# Flatten MultiIndex columns\n",
    "result = df.groupby('cat').agg({'sales': ['sum', 'mean']})\n",
    "result.columns = ['_'.join(col) for col in result.columns]\n",
    "```\n",
    "\n",
    "### Combining GroupBy with Other Operations\n",
    "\n",
    "```python\n",
    "# GroupBy + Sort + Head\n",
    "df.groupby('category').apply(lambda x: x.nlargest(3, 'sales'))\n",
    "\n",
    "# GroupBy + Pivot\n",
    "df.groupby(['product', 'region'])['sales'].sum().unstack()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b6a9f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ADVANCED GROUPBY TECHNIQUES ===\n",
      "\n",
      "Example 1: Group by month and year\n",
      "           revenue  orders\n",
      "date                      \n",
      "2024-01  191888.35      65\n",
      "2024-02  322325.30      64\n",
      "2024-03  270927.90      71\n",
      "\n",
      "Example 2: Group by order value bins\n",
      "                num_orders  avg_amount  total_revenue\n",
      "total_amount                                         \n",
      "Small (<$1k)            40      666.36       26654.30\n",
      "Medium ($1-3k)          78     1997.11      155774.75\n",
      "Large ($3-5k)           26     4006.56      104170.50\n",
      "XLarge (>$5k)           38     6928.17      263270.45\n",
      "\n",
      "Example 3: Aggregate multiple columns simultaneously\n",
      "           total_amount            quantity      discount_%     \n",
      "                   mean        sum     mean  sum       mean  sum\n",
      "product                                                         \n",
      "Camera          3184.21  108263.20     2.50   85       4.41  150\n",
      "Headphones      3038.88  103322.00     2.94  100       6.76  230\n",
      "Laptop          4223.90  181627.65     3.16  136       6.51  280\n",
      "Phone           5330.78  149261.70     3.57  100       6.79  190\n",
      "Tablet          3948.42  146091.55     2.84  105       5.68  210\n",
      "\n",
      "Example 4: Group by custom function (even/odd order IDs)\n",
      "          num_orders  total_revenue\n",
      "order_id                           \n",
      "Even             100      404817.90\n",
      "Odd              100      380323.65\n",
      "\n",
      "Example 5: Product × Region matrix using unstack\n",
      "region          East     North     South      West\n",
      "product                                           \n",
      "Camera      46293.70  32933.60  14134.45  14901.45\n",
      "Headphones  25464.05  23852.75  19602.95  34402.25\n",
      "Laptop      26543.45  70954.30  12706.20  71423.70\n",
      "Phone       39094.20  52722.45  27695.30  29749.75\n",
      "Tablet      31622.05  56759.35  27461.70  30248.45\n",
      "Watch       20816.65  28463.35  30745.40  16550.05\n",
      "\n",
      "Example 6: Cumulative revenue by product (sorted by date)\n",
      "        product       date  total_amount  cumulative_revenue\n",
      "176       Phone 2024-01-01      11996.00            11996.00\n",
      "104  Headphones 2024-01-01       3198.40             3198.40\n",
      "135  Headphones 2024-01-01       1018.30             4216.70\n",
      "18        Watch 2024-01-02        899.00              899.00\n",
      "54       Tablet 2024-01-02        852.15              852.15\n",
      "14       Laptop 2024-01-02       1999.00             1999.00\n",
      "67       Laptop 2024-01-02       2427.30             4426.30\n",
      "40   Headphones 2024-01-03       1234.05             5450.75\n",
      "180      Laptop 2024-01-03       3598.20             8024.50\n",
      "11       Camera 2024-01-03       7196.40             7196.40\n",
      "134       Watch 2024-01-03       6396.80             7295.80\n",
      "70       Camera 2024-01-04        854.05             8050.45\n",
      "66   Headphones 2024-01-04       1707.15             7157.90\n",
      "47       Tablet 2024-01-04       5998.00             6850.15\n",
      "149      Tablet 2024-01-04       2999.00             9849.15\n",
      "\n",
      "Example 7: 3-order moving average per product\n",
      "        product  total_amount  rolling_avg\n",
      "176       Phone      11996.00     11996.00\n",
      "104  Headphones       3198.40      3198.40\n",
      "135  Headphones       1018.30      2108.35\n",
      "18        Watch        899.00       899.00\n",
      "54       Tablet        852.15       852.15\n",
      "14       Laptop       1999.00      1999.00\n",
      "67       Laptop       2427.30      2213.15\n",
      "40   Headphones       1234.05      1816.92\n",
      "180      Laptop       3598.20      2674.83\n",
      "11       Camera       7196.40      7196.40\n",
      "134       Watch       6396.80      3647.90\n",
      "70       Camera        854.05      4025.22\n",
      "66   Headphones       1707.15      1319.83\n",
      "47       Tablet       5998.00      3425.08\n",
      "149      Tablet       2999.00      3283.05\n",
      "136       Watch       9495.25      5597.02\n",
      "114  Headphones       4495.00      2478.73\n",
      "166      Laptop       1899.05      2641.52\n",
      "68        Phone       5398.20      8697.10\n",
      "42       Tablet       5697.15      4898.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/sfvddbbx4tg14yxq7trqmhyw0000gn/T/ipykernel_1622/1219253020.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  bin_analysis = sales_df.groupby(value_bins).agg(\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ADVANCED GROUPBY TECHNIQUES ===\\n\")\n",
    "\n",
    "# Example 1: Group by date components\n",
    "print(\"Example 1: Group by month and year\")\n",
    "monthly_sales = sales_df.groupby(\n",
    "    sales_df['date'].dt.to_period('M')\n",
    ").agg(\n",
    "    revenue=('total_amount', 'sum'),\n",
    "    orders=('order_id', 'count')\n",
    ").round(2)\n",
    "print(monthly_sales)\n",
    "print()\n",
    "\n",
    "# Example 2: Group by binned values\n",
    "print(\"Example 2: Group by order value bins\")\n",
    "value_bins = pd.cut(\n",
    "    sales_df['total_amount'],\n",
    "    bins=[0, 1000, 3000, 5000, 10000],\n",
    "    labels=['Small (<$1k)', 'Medium ($1-3k)', 'Large ($3-5k)', 'XLarge (>$5k)']\n",
    ")\n",
    "bin_analysis = sales_df.groupby(value_bins).agg(\n",
    "    num_orders=('order_id', 'count'),\n",
    "    avg_amount=('total_amount', 'mean'),\n",
    "    total_revenue=('total_amount', 'sum')\n",
    ").round(2)\n",
    "print(bin_analysis)\n",
    "print()\n",
    "\n",
    "# Example 3: Multiple column selection\n",
    "print(\"Example 3: Aggregate multiple columns simultaneously\")\n",
    "multi_col = sales_df.groupby('product')[['total_amount', 'quantity', 'discount_%']].agg(['mean', 'sum']).round(2)\n",
    "print(multi_col.head())\n",
    "print()\n",
    "\n",
    "# Example 4: Custom grouping function\n",
    "print(\"Example 4: Group by custom function (even/odd order IDs)\")\n",
    "def even_odd(order_id):\n",
    "    return 'Even' if order_id % 2 == 0 else 'Odd'\n",
    "\n",
    "even_odd_analysis = sales_df.groupby(sales_df['order_id'].apply(even_odd)).agg(\n",
    "    num_orders=('order_id', 'count'),\n",
    "    total_revenue=('total_amount', 'sum')\n",
    ").round(2)\n",
    "print(even_odd_analysis)\n",
    "print()\n",
    "\n",
    "# Example 5: GroupBy with unstack (pivot-like)\n",
    "print(\"Example 5: Product × Region matrix using unstack\")\n",
    "product_region_matrix = sales_df.groupby(['product', 'region'])['total_amount'].sum().unstack(fill_value=0)\n",
    "print(product_region_matrix)\n",
    "print()\n",
    "\n",
    "# Example 6: Cumulative sum within groups\n",
    "print(\"Example 6: Cumulative revenue by product (sorted by date)\")\n",
    "sales_sorted = sales_df.sort_values('date')\n",
    "sales_sorted['cumulative_revenue'] = sales_sorted.groupby('product')['total_amount'].cumsum()\n",
    "print(sales_sorted[['product', 'date', 'total_amount', 'cumulative_revenue']].head(15))\n",
    "print()\n",
    "\n",
    "# Example 7: Rolling mean within groups\n",
    "print(\"Example 7: 3-order moving average per product\")\n",
    "sales_sorted['rolling_avg'] = sales_sorted.groupby('product')['total_amount'].transform(\n",
    "    lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    ").round(2)\n",
    "print(sales_sorted[['product', 'total_amount', 'rolling_avg']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61ebd0",
   "metadata": {},
   "source": [
    "## 11. Best Practices & Performance Tips\n",
    "\n",
    "### Best Practices ✅\n",
    "\n",
    "**1. Use Named Aggregations**\n",
    "```python\n",
    "# ✅ Clear and readable\n",
    "df.groupby('cat').agg(\n",
    "    total_sales=('sales', 'sum'),\n",
    "    avg_price=('price', 'mean')\n",
    ")\n",
    "\n",
    "# ❌ MultiIndex columns, harder to work with\n",
    "df.groupby('cat').agg({'sales': 'sum', 'price': 'mean'})\n",
    "```\n",
    "\n",
    "**2. Use Built-in Functions When Possible**\n",
    "```python\n",
    "# ✅ Fast - built-in aggregation\n",
    "df.groupby('cat')['sales'].sum()\n",
    "\n",
    "# ❌ Slower - apply with lambda\n",
    "df.groupby('cat')['sales'].apply(lambda x: x.sum())\n",
    "```\n",
    "\n",
    "**3. Reset Index for Cleaner Results**\n",
    "```python\n",
    "# ✅ Clean DataFrame\n",
    "result = df.groupby('cat')['sales'].sum().reset_index()\n",
    "\n",
    "# ❌ Grouped column becomes index\n",
    "result = df.groupby('cat')['sales'].sum()\n",
    "```\n",
    "\n",
    "**4. Use Transform for Same-Shape Operations**\n",
    "```python\n",
    "# ✅ Add group mean to each row\n",
    "df['group_mean'] = df.groupby('cat')['sales'].transform('mean')\n",
    "\n",
    "# ❌ Aggregation reduces rows\n",
    "df.groupby('cat')['sales'].mean()\n",
    "```\n",
    "\n",
    "**5. Filter Groups, Not Rows**\n",
    "```python\n",
    "# ✅ Keep entire groups\n",
    "df.groupby('product').filter(lambda x: x['sales'].sum() > 1000)\n",
    "\n",
    "# ❌ Filters individual rows\n",
    "df[df['sales'] > 1000]\n",
    "```\n",
    "\n",
    "### Performance Tips 🚀\n",
    "\n",
    "**1. Avoid Unnecessary apply()**\n",
    "```python\n",
    "# Fast\n",
    "df.groupby('cat')['sales'].sum()  # ~10ms\n",
    "\n",
    "# Slow\n",
    "df.groupby('cat')['sales'].apply(sum)  # ~100ms\n",
    "```\n",
    "\n",
    "**2. Use Categorical Data Types**\n",
    "```python\n",
    "# Faster groupby on categorical columns\n",
    "df['category'] = df['category'].astype('category')\n",
    "df.groupby('category')['sales'].sum()  # Faster!\n",
    "```\n",
    "\n",
    "**3. Sort Before GroupBy (Sometimes)**\n",
    "```python\n",
    "# Can be faster for large datasets\n",
    "df.sort_values('category').groupby('category', sort=False).sum()\n",
    "```\n",
    "\n",
    "**4. Use as_index=False to Avoid Reset**\n",
    "```python\n",
    "# ✅ One step\n",
    "df.groupby('cat', as_index=False)['sales'].sum()\n",
    "\n",
    "# ❌ Two steps\n",
    "df.groupby('cat')['sales'].sum().reset_index()\n",
    "```\n",
    "\n",
    "### Common Pitfalls ❌\n",
    "\n",
    "**1. Forgetting to Aggregate**\n",
    "```python\n",
    "# ❌ Returns GroupBy object, not results\n",
    "grouped = df.groupby('category')\n",
    "\n",
    "# ✅ Apply aggregation\n",
    "result = df.groupby('category')['sales'].sum()\n",
    "```\n",
    "\n",
    "**2. Confusing Transform and Aggregate**\n",
    "```python\n",
    "# Aggregate: Reduces rows\n",
    "df.groupby('cat')['sales'].sum()  # Returns 1 value per group\n",
    "\n",
    "# Transform: Same number of rows\n",
    "df.groupby('cat')['sales'].transform('sum')  # Returns value for each row\n",
    "```\n",
    "\n",
    "**3. Not Handling MultiIndex**\n",
    "```python\n",
    "# ❌ MultiIndex can be confusing\n",
    "result = df.groupby(['col1', 'col2'])['val'].sum()\n",
    "\n",
    "# ✅ Flatten with reset_index()\n",
    "result = df.groupby(['col1', 'col2'])['val'].sum().reset_index()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b84679",
   "metadata": {},
   "source": [
    "## 12. Practice Exercises\n",
    "\n",
    "### Beginner Level (1-5)\n",
    "\n",
    "1. **Calculate total revenue by product**\n",
    "   - Use `groupby('product')['total_amount'].sum()`\n",
    "\n",
    "2. **Count number of orders per region**\n",
    "   - Use `groupby('region').size()`\n",
    "\n",
    "3. **Find average order value by customer type**\n",
    "   - Use `groupby('customer_type')['total_amount'].mean()`\n",
    "\n",
    "4. **Get total units sold per product**\n",
    "   - Use `groupby('product')['quantity'].sum()`\n",
    "\n",
    "5. **Find maximum order amount in each region**\n",
    "   - Use `groupby('region')['total_amount'].max()`\n",
    "\n",
    "### Intermediate Level (6-10)\n",
    "\n",
    "6. **Product statistics: total, average, count**\n",
    "   - Use `groupby('product')['total_amount'].agg(['sum', 'mean', 'count'])`\n",
    "\n",
    "7. **Revenue by product and region**\n",
    "   - Use `groupby(['product', 'region'])['total_amount'].sum()`\n",
    "\n",
    "8. **Add group mean to each row**\n",
    "   - Use `groupby('product')['total_amount'].transform('mean')`\n",
    "\n",
    "9. **Keep only products with > 30 orders**\n",
    "   - Use `groupby('product').filter(lambda x: len(x) > 30)`\n",
    "\n",
    "10. **Calculate market share % for each product**\n",
    "    - Sum by product, divide by total, multiply by 100\n",
    "\n",
    "### Advanced Level (11-15)\n",
    "\n",
    "11. **Top 3 orders for each product**\n",
    "    - Use `groupby('product').apply(lambda x: x.nlargest(3, 'total_amount'))`\n",
    "\n",
    "12. **Calculate weighted average price by quantity**\n",
    "    - Use custom function with apply\n",
    "\n",
    "13. **Monthly revenue with month-over-month growth**\n",
    "    - Group by month, calculate percentage change\n",
    "\n",
    "14. **Rank orders within each product**\n",
    "    - Use `groupby('product')['total_amount'].rank()`\n",
    "\n",
    "15. **Find products with high revenue variability (std > 1000)**\n",
    "    - Use `groupby('product').filter(lambda x: x['total_amount'].std() > 1000)`\n",
    "\n",
    "### Challenge Problems (16-20)\n",
    "\n",
    "16. **Create RFM analysis (Recency, Frequency, Monetary)**\n",
    "    - Group by customer, calculate days since last order, count, total spend\n",
    "\n",
    "17. **Identify \"star\" products: high revenue + high order count + low discount**\n",
    "    - Multiple aggregations with conditions\n",
    "\n",
    "18. **Calculate cohort analysis by first purchase month**\n",
    "    - Complex grouping with date transformations\n",
    "\n",
    "19. **Find cross-sell opportunities (products often bought together)**\n",
    "    - Would require order-level grouping (beyond current dataset)\n",
    "\n",
    "20. **Create a custom performance score combining multiple metrics**\n",
    "    - Custom function with weighted combination of revenue, orders, consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "585c1391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRACTICE EXERCISE SOLUTIONS ===\n",
      "\n",
      "Try solving the exercises first, then check solutions!\n",
      "\n",
      "Solution 1: Total revenue by product\n",
      "product\n",
      "Laptop        181627.65\n",
      "Phone         149261.70\n",
      "Tablet        146091.55\n",
      "Camera        108263.20\n",
      "Headphones    103322.00\n",
      "Watch          96575.45\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Solution 6: Product statistics\n",
      "                Total  Average  Count\n",
      "product                              \n",
      "Laptop      181627.65  4223.90     43\n",
      "Phone       149261.70  5330.78     28\n",
      "Tablet      146091.55  3948.42     37\n",
      "Camera      108263.20  3184.21     34\n",
      "Headphones  103322.00  3038.88     34\n",
      "Watch        96575.45  4023.98     24\n",
      "\n",
      "Solution 10: Market share % for each product\n",
      "product\n",
      "Laptop        23.13\n",
      "Phone         19.01\n",
      "Tablet        18.61\n",
      "Camera        13.79\n",
      "Headphones    13.16\n",
      "Watch         12.30\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Solution 11: Top 3 orders for each product\n",
      "     order_id  total_amount\n",
      "37       1038      14995.00\n",
      "144      1145      11996.00\n",
      "100      1101       8997.00\n",
      "158      1159      11996.00\n",
      "196      1197       9995.00\n",
      "19       1020       5998.00\n",
      "76       1077      14995.00\n",
      "154      1155      14995.00\n",
      "113      1114      13495.50\n",
      "9        1010      14995.00\n",
      "20       1021      14995.00\n",
      "29       1030      14245.25\n",
      "115      1116      14245.25\n",
      "15       1016      11996.00\n",
      "90       1091       9495.25\n",
      "\n",
      "Solution 14: Rank orders within each product\n",
      "    product  total_amount  product_rank\n",
      "37   Camera      14995.00           1.0\n",
      "144  Camera      11996.00           2.0\n",
      "100  Camera       8997.00           3.0\n",
      "120  Camera       8997.00           3.0\n",
      "11   Camera       7196.40           4.0\n",
      "173  Camera       5998.00           5.0\n",
      "21   Camera       5397.30           6.0\n",
      "199  Camera       5196.00           7.0\n",
      "118  Camera       4045.50           8.0\n",
      "130  Camera       3702.15           9.0\n",
      "59   Camera       2849.05          10.0\n",
      "171  Camera       2849.05          10.0\n",
      "117  Camera       2396.00          11.0\n",
      "31   Camera       2156.40          12.0\n",
      "155  Camera       1799.10          13.0\n",
      "87   Camera       1797.00          14.0\n",
      "122  Camera       1797.00          14.0\n",
      "30   Camera       1618.20          15.0\n",
      "146  Camera       1495.00          16.0\n",
      "97   Camera       1234.05          17.0\n",
      "\n",
      "Solution 20: Custom performance score\n",
      "product\n",
      "Laptop        92071.29\n",
      "Phone         75436.94\n",
      "Tablet        74127.42\n",
      "Camera        55129.57\n",
      "Headphones    52647.21\n",
      "Watch         48970.25\n",
      "dtype: float64\n",
      "\n",
      "Interpretation: Higher score = better overall performance\n",
      "\n",
      "================================================================================\n",
      "Try solving the remaining exercises on your own!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/sfvddbbx4tg14yxq7trqmhyw0000gn/T/ipykernel_1622/1865269321.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top3_per_product = sales_df.groupby('product', group_keys=False).apply(top3)\n",
      "/var/folders/d1/sfvddbbx4tg14yxq7trqmhyw0000gn/T/ipykernel_1622/1865269321.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  performance_scores = sales_df.groupby('product').apply(performance_score).sort_values(ascending=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PRACTICE EXERCISE SOLUTIONS ===\\n\")\n",
    "print(\"Try solving the exercises first, then check solutions!\\n\")\n",
    "\n",
    "# Solution 1\n",
    "print(\"Solution 1: Total revenue by product\")\n",
    "revenue_by_product = sales_df.groupby('product')['total_amount'].sum().sort_values(ascending=False)\n",
    "print(revenue_by_product)\n",
    "print()\n",
    "\n",
    "# Solution 6\n",
    "print(\"Solution 6: Product statistics\")\n",
    "product_stats = sales_df.groupby('product')['total_amount'].agg(['sum', 'mean', 'count'])\n",
    "product_stats.columns = ['Total', 'Average', 'Count']\n",
    "print(product_stats.sort_values('Total', ascending=False))\n",
    "print()\n",
    "\n",
    "# Solution 10\n",
    "print(\"Solution 10: Market share % for each product\")\n",
    "total_revenue = sales_df['total_amount'].sum()\n",
    "market_share = sales_df.groupby('product')['total_amount'].sum()\n",
    "market_share_pct = (market_share / total_revenue * 100).sort_values(ascending=False).round(2)\n",
    "print(market_share_pct)\n",
    "print()\n",
    "\n",
    "# Solution 11\n",
    "print(\"Solution 11: Top 3 orders for each product\")\n",
    "def top3(group):\n",
    "    return group.nlargest(3, 'total_amount')[['order_id', 'total_amount']]\n",
    "\n",
    "top3_per_product = sales_df.groupby('product', group_keys=False).apply(top3)\n",
    "print(top3_per_product.head(15))\n",
    "print()\n",
    "\n",
    "# Solution 14\n",
    "print(\"Solution 14: Rank orders within each product\")\n",
    "sales_df['product_rank'] = sales_df.groupby('product')['total_amount'].rank(\n",
    "    ascending=False, method='dense'\n",
    ")\n",
    "print(sales_df[['product', 'total_amount', 'product_rank']].sort_values(['product', 'product_rank']).head(20))\n",
    "print()\n",
    "\n",
    "# Solution 20\n",
    "print(\"Solution 20: Custom performance score\")\n",
    "def performance_score(group):\n",
    "    revenue = group['total_amount'].sum()\n",
    "    order_count = len(group)\n",
    "    consistency = 1 / (1 + group['total_amount'].std())  # Reward consistency\n",
    "    avg_discount = group['discount_%'].mean()\n",
    "    \n",
    "    # Weighted score\n",
    "    score = (revenue * 0.5 + \n",
    "             order_count * 100 * 0.3 + \n",
    "             consistency * 1000 * 0.1 - \n",
    "             avg_discount * 50 * 0.1)\n",
    "    return score\n",
    "\n",
    "performance_scores = sales_df.groupby('product').apply(performance_score).sort_values(ascending=False)\n",
    "print(performance_scores.round(2))\n",
    "print(\"\\nInterpretation: Higher score = better overall performance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Try solving the remaining exercises on your own!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257dab5d",
   "metadata": {},
   "source": [
    "## Quick Reference Card\n",
    "\n",
    "### Basic GroupBy Syntax\n",
    "\n",
    "```python\n",
    "# Simple groupby + aggregation\n",
    "df.groupby('column')['value'].sum()\n",
    "\n",
    "# Multiple columns\n",
    "df.groupby(['col1', 'col2'])['value'].sum()\n",
    "\n",
    "# Multiple aggregations\n",
    "df.groupby('col')['value'].agg(['sum', 'mean', 'count'])\n",
    "```\n",
    "\n",
    "### Named Aggregations (Recommended)\n",
    "\n",
    "```python\n",
    "df.groupby('category').agg(\n",
    "    total_sales=('sales', 'sum'),\n",
    "    avg_price=('price', 'mean'),\n",
    "    num_orders=('order_id', 'count')\n",
    ")\n",
    "```\n",
    "\n",
    "### Common Aggregation Functions\n",
    "\n",
    "```python\n",
    "sum()      # Total\n",
    "mean()     # Average\n",
    "median()   # Middle value\n",
    "min()      # Minimum\n",
    "max()      # Maximum\n",
    "count()    # Count non-null\n",
    "size()     # Count all (including null)\n",
    "std()      # Standard deviation\n",
    "var()      # Variance\n",
    "nunique()  # Count unique\n",
    "first()    # First value\n",
    "last()     # Last value\n",
    "```\n",
    "\n",
    "### Transform vs Aggregate\n",
    "\n",
    "```python\n",
    "# Aggregate: Reduces rows\n",
    "df.groupby('cat')['sales'].sum()  # One row per group\n",
    "\n",
    "# Transform: Same number of rows\n",
    "df['group_sum'] = df.groupby('cat')['sales'].transform('sum')\n",
    "```\n",
    "\n",
    "### Filter Groups\n",
    "\n",
    "```python\n",
    "# Keep groups where sum > 1000\n",
    "df.groupby('product').filter(lambda x: x['sales'].sum() > 1000)\n",
    "```\n",
    "\n",
    "### Apply Custom Functions\n",
    "\n",
    "```python\n",
    "# Custom aggregation\n",
    "def custom_func(group):\n",
    "    return group['value'].max() - group['value'].min()\n",
    "\n",
    "df.groupby('category').apply(custom_func)\n",
    "```\n",
    "\n",
    "### Iterate Over Groups\n",
    "\n",
    "```python\n",
    "for name, group in df.groupby('category'):\n",
    "    print(f\"Processing {name}\")\n",
    "    print(group.head())\n",
    "```\n",
    "\n",
    "### Reset Index\n",
    "\n",
    "```python\n",
    "# Reset index to columns\n",
    "result = df.groupby('cat')['sales'].sum().reset_index()\n",
    "\n",
    "# Or use as_index=False\n",
    "result = df.groupby('cat', as_index=False)['sales'].sum()\n",
    "```\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "```python\n",
    "# Top N per group\n",
    "df.groupby('category').apply(lambda x: x.nlargest(3, 'sales'))\n",
    "\n",
    "# Percentage of group total\n",
    "df['pct'] = df['value'] / df.groupby('cat')['value'].transform('sum') * 100\n",
    "\n",
    "# Rank within groups\n",
    "df['rank'] = df.groupby('cat')['value'].rank(ascending=False)\n",
    "\n",
    "# Cumulative sum within groups\n",
    "df['cumsum'] = df.groupby('cat')['value'].cumsum()\n",
    "\n",
    "# Fill missing with group mean\n",
    "df['value'] = df.groupby('cat')['value'].transform(lambda x: x.fillna(x.mean()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7908d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts Mastered ✅\n",
    "\n",
    "**1. Split-Apply-Combine Pattern**\n",
    "- Split data into groups\n",
    "- Apply function to each group\n",
    "- Combine results\n",
    "\n",
    "**2. Aggregation Operations**\n",
    "- Single aggregations: `sum()`, `mean()`, `count()`\n",
    "- Multiple aggregations: `agg(['sum', 'mean'])`\n",
    "- Named aggregations: Clean, readable results\n",
    "- Different aggregations per column\n",
    "\n",
    "**3. Transform Operations**\n",
    "- Add group statistics to each row\n",
    "- Maintain original DataFrame shape\n",
    "- Calculate percentages, z-scores\n",
    "- Fill missing values with group stats\n",
    "\n",
    "**4. Filter Operations**\n",
    "- Keep/remove entire groups\n",
    "- Based on group properties\n",
    "- Different from row filtering\n",
    "\n",
    "**5. Apply Custom Functions**\n",
    "- Lambda functions for simple operations\n",
    "- Named functions for complex logic\n",
    "- Return Series or DataFrame\n",
    "\n",
    "**6. Multiple GroupBy Columns**\n",
    "- Create groups for unique combinations\n",
    "- Results in MultiIndex\n",
    "- Use `reset_index()` for flat structure\n",
    "\n",
    "---\n",
    "\n",
    "### Method Selection Guide\n",
    "\n",
    "| Task | Method | Example |\n",
    "|------|--------|----------|\n",
    "| Get group totals | `agg('sum')` | Revenue per product |\n",
    "| Add group mean to rows | `transform('mean')` | Compare to group avg |\n",
    "| Keep high-performing groups | `filter()` | Products with >1000 orders |\n",
    "| Custom calculations | `apply()` | Weighted averages |\n",
    "| Multiple metrics | `agg({...})` | Total + average + count |\n",
    "| Top N per group | `apply(nlargest)` | Top 3 orders per product |\n",
    "\n",
    "---\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "**Pattern 1: Basic Analysis**\n",
    "```python\n",
    "df.groupby('category')['sales'].sum().sort_values(ascending=False)\n",
    "```\n",
    "\n",
    "**Pattern 2: Multi-Metric Dashboard**\n",
    "```python\n",
    "df.groupby('product').agg(\n",
    "    total=('sales', 'sum'),\n",
    "    average=('sales', 'mean'),\n",
    "    count=('order_id', 'count')\n",
    ")\n",
    "```\n",
    "\n",
    "**Pattern 3: Percentage Contribution**\n",
    "```python\n",
    "total = df['sales'].sum()\n",
    "df.groupby('product')['sales'].sum() / total * 100\n",
    "```\n",
    "\n",
    "**Pattern 4: Rank Within Groups**\n",
    "```python\n",
    "df['rank'] = df.groupby('category')['sales'].rank(ascending=False)\n",
    "df[df['rank'] <= 3]  # Top 3 per category\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "After mastering GroupBy:\n",
    "1. **Pivot Tables** - Reshape grouped data\n",
    "2. **Time Series** - Date-based grouping and resampling\n",
    "3. **Window Functions** - Rolling calculations within groups\n",
    "4. **Multi-Index** - Advanced hierarchical indexing\n",
    "5. **Performance Optimization** - Speed up large GroupBy operations\n",
    "\n",
    "---\n",
    "\n",
    "### Remember\n",
    "\n",
    "- 🎯 **Use named aggregations** for clarity\n",
    "- ⚡ **Built-in functions** are faster than `apply()`\n",
    "- 📊 **Transform** preserves shape, **aggregate** reduces\n",
    "- 🔍 **Filter** operates on groups, not rows\n",
    "- 🔄 **Reset index** for flat, easy-to-use results\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Grouping! 🐼📊**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
