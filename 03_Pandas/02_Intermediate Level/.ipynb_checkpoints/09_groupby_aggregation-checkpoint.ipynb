{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GroupBy and Aggregation in Pandas\n",
        "\n",
        "## Overview\n",
        "\n",
        "**GroupBy** = Split-Apply-Combine strategy for data analysis\n",
        "\n",
        "### The Split-Apply-Combine Pattern\n",
        "\n",
        "```\n",
        "1. SPLIT    \u2192 Divide data into groups\n",
        "2. APPLY    \u2192 Apply function to each group\n",
        "3. COMBINE  \u2192 Combine results back together\n",
        "```\n",
        "\n",
        "### Visual Example\n",
        "\n",
        "```\n",
        "Original Data:\n",
        "Product   Region   Sales\n",
        "Laptop    North    1000\n",
        "Phone     South     500\n",
        "Laptop    South     800\n",
        "Phone     North     600\n",
        "\n",
        "           \u2193 SPLIT by Product\n",
        "\n",
        "Group 1: Laptop    [1000, 800]\n",
        "Group 2: Phone     [500, 600]\n",
        "\n",
        "           \u2193 APPLY sum()\n",
        "\n",
        "Laptop: 1800\n",
        "Phone:  1100\n",
        "\n",
        "           \u2193 COMBINE\n",
        "\n",
        "Product   Total_Sales\n",
        "Laptop    1800\n",
        "Phone     1100\n",
        "```\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "| Concept | Description | Example |\n",
        "|---------|-------------|----------|\n",
        "| **GroupBy** | Split data into groups | `df.groupby('category')` |\n",
        "| **Aggregation** | Summarize each group | `sum()`, `mean()`, `count()` |\n",
        "| **Transform** | Return same shape | Add group mean to each row |\n",
        "| **Filter** | Keep/remove groups | Keep groups with sum > 1000 |\n",
        "| **Apply** | Custom operations | Any function |\n",
        "\n",
        "### What We'll Learn\n",
        "1. \u2705 Basic groupby operations\n",
        "2. \u2705 Single and multiple aggregations\n",
        "3. \u2705 Multiple groupby columns\n",
        "4. \u2705 Transform vs aggregation\n",
        "5. \u2705 Filtering groups\n",
        "6. \u2705 Custom aggregation functions\n",
        "7. \u2705 Named aggregations\n",
        "8. \u2705 Real-world business analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.precision', 2)\n",
        "\n",
        "print(\"\u2705 Libraries imported\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Dataset: E-commerce Sales\n",
        "\n",
        "We'll use a comprehensive sales dataset to demonstrate groupby operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create realistic e-commerce sales data\n",
        "np.random.seed(42)\n",
        "\n",
        "n_orders = 200\n",
        "\n",
        "# Generate dates over 3 months\n",
        "start_date = datetime(2024, 1, 1)\n",
        "dates = [start_date + timedelta(days=np.random.randint(0, 90)) for _ in range(n_orders)]\n",
        "\n",
        "sales_df = pd.DataFrame({\n",
        "    'order_id': range(1001, 1001 + n_orders),\n",
        "    'date': dates,\n",
        "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Headphones', 'Watch', 'Camera'], n_orders),\n",
        "    'category': np.random.choice(['Electronics', 'Accessories'], n_orders),\n",
        "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_orders),\n",
        "    'customer_type': np.random.choice(['New', 'Returning', 'VIP'], n_orders, p=[0.4, 0.4, 0.2]),\n",
        "    'quantity': np.random.randint(1, 6, n_orders),\n",
        "    'unit_price': np.random.choice([299, 599, 899, 1299, 1999, 2999], n_orders),\n",
        "    'discount_%': np.random.choice([0, 5, 10, 15, 20], n_orders, p=[0.4, 0.25, 0.2, 0.1, 0.05])\n",
        "})\n",
        "\n",
        "# Calculate derived columns\n",
        "sales_df['subtotal'] = sales_df['quantity'] * sales_df['unit_price']\n",
        "sales_df['discount_amount'] = sales_df['subtotal'] * sales_df['discount_%'] / 100\n",
        "sales_df['total_amount'] = sales_df['subtotal'] - sales_df['discount_amount']\n",
        "sales_df['month'] = pd.to_datetime(sales_df['date']).dt.month_name()\n",
        "sales_df['year'] = pd.to_datetime(sales_df['date']).dt.year\n",
        "\n",
        "print(\"Sales Dataset:\")\n",
        "print(sales_df.head(15))\n",
        "print(f\"\\nShape: {sales_df.shape}\")\n",
        "print(f\"\\nColumns: {sales_df.columns.tolist()}\")\n",
        "print(f\"\\nData types:\\n{sales_df.dtypes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. GroupBy Basics\n",
        "\n",
        "### What is GroupBy?\n",
        "\n",
        "**GroupBy** creates a grouped object that splits data by unique values in a column.\n",
        "\n",
        "### Syntax\n",
        "\n",
        "```python\n",
        "# Basic groupby\n",
        "grouped = df.groupby('column')\n",
        "\n",
        "# Apply aggregation\n",
        "result = df.groupby('column')['value_column'].sum()\n",
        "```\n",
        "\n",
        "### Understanding the GroupBy Object\n",
        "\n",
        "```python\n",
        "grouped = df.groupby('product')\n",
        "# This creates a GroupBy object (not a DataFrame yet)\n",
        "\n",
        "# To see results, apply an aggregation:\n",
        "grouped.sum()      # Sum for each group\n",
        "grouped.mean()     # Mean for each group\n",
        "grouped.count()    # Count for each group\n",
        "```\n",
        "\n",
        "### Basic Workflow\n",
        "\n",
        "```python\n",
        "# Step 1: Group by category\n",
        "df.groupby('category')\n",
        "\n",
        "# Step 2: Select column to aggregate\n",
        "df.groupby('category')['sales']\n",
        "\n",
        "# Step 3: Apply aggregation\n",
        "df.groupby('category')['sales'].sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== GROUPBY BASICS ===\\n\")\n",
        "\n",
        "# Example 1: Simple groupby with sum\n",
        "print(\"Example 1: Total sales by product\")\n",
        "product_sales = sales_df.groupby('product')['total_amount'].sum()\n",
        "print(product_sales.sort_values(ascending=False))\n",
        "print(f\"\\nType: {type(product_sales)}\")\n",
        "print()\n",
        "\n",
        "# Example 2: Count orders by product\n",
        "print(\"Example 2: Number of orders by product\")\n",
        "product_count = sales_df.groupby('product')['order_id'].count()\n",
        "print(product_count.sort_values(ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 3: Average order value by region\n",
        "print(\"Example 3: Average order value by region\")\n",
        "region_avg = sales_df.groupby('region')['total_amount'].mean()\n",
        "print(region_avg.sort_values(ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 4: Understanding GroupBy object\n",
        "print(\"Example 4: Understanding the GroupBy object\")\n",
        "grouped = sales_df.groupby('product')\n",
        "print(f\"GroupBy object: {grouped}\")\n",
        "print(f\"Number of groups: {grouped.ngroups}\")\n",
        "print(f\"Group names: {list(grouped.groups.keys())}\")\n",
        "print()\n",
        "\n",
        "# Example 5: Get first and last rows of each group\n",
        "print(\"Example 5: First order for each product\")\n",
        "first_orders = sales_df.groupby('product').first()\n",
        "print(first_orders[['date', 'quantity', 'total_amount']].head())\n",
        "print()\n",
        "\n",
        "# Example 6: Group size (number of items in each group)\n",
        "print(\"Example 6: Size of each product group\")\n",
        "group_sizes = sales_df.groupby('product').size()\n",
        "print(group_sizes.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Common Aggregation Functions\n",
        "\n",
        "### Built-in Aggregation Functions\n",
        "\n",
        "| Function | Description | Example Use Case |\n",
        "|----------|-------------|------------------|\n",
        "| `sum()` | Sum of values | Total revenue |\n",
        "| `mean()` | Average | Average order value |\n",
        "| `median()` | Middle value | Median price |\n",
        "| `min()` | Minimum value | Lowest price |\n",
        "| `max()` | Maximum value | Highest revenue |\n",
        "| `count()` | Number of items | Order count |\n",
        "| `std()` | Standard deviation | Price volatility |\n",
        "| `var()` | Variance | Revenue variance |\n",
        "| `first()` | First value | First order date |\n",
        "| `last()` | Last value | Last order date |\n",
        "| `size()` | Group size | Items per group |\n",
        "| `nunique()` | Unique count | Unique customers |\n",
        "\n",
        "### Statistical Functions\n",
        "\n",
        "| Function | Description |\n",
        "|----------|-------------|\n",
        "| `quantile(q)` | Quantile (e.g., q=0.25 for 25th percentile) |\n",
        "| `sem()` | Standard error of mean |\n",
        "| `skew()` | Skewness |\n",
        "| `kurt()` | Kurtosis |\n",
        "\n",
        "### String Functions\n",
        "\n",
        "```python\n",
        "# For string columns\n",
        "df.groupby('category')['name'].agg(lambda x: ', '.join(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== AGGREGATION FUNCTIONS ===\\n\")\n",
        "\n",
        "# Example 1: Multiple aggregations on single column\n",
        "print(\"Example 1: Product statistics\")\n",
        "product_stats = sales_df.groupby('product')['total_amount'].agg(['sum', 'mean', 'count', 'min', 'max'])\n",
        "product_stats.columns = ['Total_Revenue', 'Avg_Order', 'Num_Orders', 'Min_Order', 'Max_Order']\n",
        "print(product_stats.sort_values('Total_Revenue', ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 2: Statistical measures\n",
        "print(\"Example 2: Revenue statistics by region\")\n",
        "region_stats = sales_df.groupby('region')['total_amount'].agg([\n",
        "    'mean', 'median', 'std', 'min', 'max'\n",
        "])\n",
        "region_stats.columns = ['Mean', 'Median', 'Std_Dev', 'Min', 'Max']\n",
        "print(region_stats)\n",
        "print()\n",
        "\n",
        "# Example 3: Count unique values\n",
        "print(\"Example 3: Unique products per region\")\n",
        "unique_products = sales_df.groupby('region')['product'].nunique()\n",
        "print(unique_products)\n",
        "print()\n",
        "\n",
        "# Example 4: First and last dates\n",
        "print(\"Example 4: First and last order date by product\")\n",
        "date_range = sales_df.groupby('product')['date'].agg(['first', 'last'])\n",
        "date_range.columns = ['First_Order', 'Last_Order']\n",
        "print(date_range)\n",
        "print()\n",
        "\n",
        "# Example 5: Quantiles\n",
        "print(\"Example 5: 25th, 50th, 75th percentile of order amounts\")\n",
        "quantiles = sales_df.groupby('customer_type')['total_amount'].quantile([0.25, 0.5, 0.75])\n",
        "print(quantiles)\n",
        "print()\n",
        "\n",
        "# Example 6: Size vs count\n",
        "print(\"Example 6: Difference between size() and count()\")\n",
        "print(\"\\nsize() - includes NaN:\")\n",
        "print(sales_df.groupby('product').size())\n",
        "print(\"\\ncount() - excludes NaN:\")\n",
        "print(sales_df.groupby('product')['total_amount'].count())\n",
        "print(\"\\nNote: They're the same if no NaN values exist\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Aggregating Multiple Columns\n",
        "\n",
        "### Different Aggregations for Different Columns\n",
        "\n",
        "```python\n",
        "df.groupby('category').agg({\n",
        "    'sales': 'sum',\n",
        "    'profit': 'mean',\n",
        "    'customer': 'nunique'\n",
        "})\n",
        "```\n",
        "\n",
        "### Multiple Aggregations per Column\n",
        "\n",
        "```python\n",
        "df.groupby('category').agg({\n",
        "    'sales': ['sum', 'mean', 'count'],\n",
        "    'profit': ['sum', 'mean']\n",
        "})\n",
        "```\n",
        "\n",
        "### Named Aggregations (Pandas 0.25+)\n",
        "\n",
        "```python\n",
        "df.groupby('category').agg(\n",
        "    total_sales=('sales', 'sum'),\n",
        "    avg_profit=('profit', 'mean'),\n",
        "    unique_customers=('customer', 'nunique')\n",
        ")\n",
        "```\n",
        "\n",
        "### Benefits of Named Aggregations\n",
        "- \u2705 Clear column names\n",
        "- \u2705 No MultiIndex columns\n",
        "- \u2705 More readable code\n",
        "- \u2705 Easier to work with results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== MULTIPLE COLUMN AGGREGATION ===\\n\")\n",
        "\n",
        "# Example 1: Different aggregations for different columns\n",
        "print(\"Example 1: Product performance metrics\")\n",
        "product_metrics = sales_df.groupby('product').agg({\n",
        "    'total_amount': 'sum',\n",
        "    'quantity': 'sum',\n",
        "    'order_id': 'count',\n",
        "    'discount_%': 'mean'\n",
        "})\n",
        "product_metrics.columns = ['Total_Revenue', 'Units_Sold', 'Num_Orders', 'Avg_Discount']\n",
        "print(product_metrics.sort_values('Total_Revenue', ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 2: Multiple aggregations per column\n",
        "print(\"Example 2: Comprehensive product analysis\")\n",
        "comprehensive = sales_df.groupby('product').agg({\n",
        "    'total_amount': ['sum', 'mean', 'max'],\n",
        "    'quantity': ['sum', 'mean'],\n",
        "    'order_id': 'count'\n",
        "})\n",
        "print(comprehensive)\n",
        "print()\n",
        "\n",
        "# Example 3: Named aggregations (cleaner)\n",
        "print(\"Example 3: Named aggregations (recommended)\")\n",
        "named_agg = sales_df.groupby('product').agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    avg_order_value=('total_amount', 'mean'),\n",
        "    max_order=('total_amount', 'max'),\n",
        "    units_sold=('quantity', 'sum'),\n",
        "    num_orders=('order_id', 'count'),\n",
        "    avg_discount=('discount_%', 'mean')\n",
        ")\n",
        "print(named_agg.sort_values('total_revenue', ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 4: Custom aggregation names with round\n",
        "print(\"Example 4: Formatted results\")\n",
        "formatted = sales_df.groupby('region').agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    avg_order_value=('total_amount', 'mean'),\n",
        "    num_orders=('order_id', 'count')\n",
        ").round(2)\n",
        "print(formatted.sort_values('total_revenue', ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 5: Complex aggregations\n",
        "print(\"Example 5: Customer type analysis\")\n",
        "customer_analysis = sales_df.groupby('customer_type').agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    avg_order=('total_amount', 'mean'),\n",
        "    median_order=('total_amount', 'median'),\n",
        "    total_orders=('order_id', 'count'),\n",
        "    unique_products=('product', 'nunique'),\n",
        "    avg_quantity=('quantity', 'mean'),\n",
        "    avg_discount=('discount_%', 'mean')\n",
        ").round(2)\n",
        "print(customer_analysis.sort_values('total_revenue', ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Grouping by Multiple Columns\n",
        "\n",
        "### Syntax\n",
        "\n",
        "```python\n",
        "# Group by multiple columns\n",
        "df.groupby(['col1', 'col2'])['value'].sum()\n",
        "```\n",
        "\n",
        "### How It Works\n",
        "\n",
        "Creates groups for each **unique combination** of values:\n",
        "\n",
        "```\n",
        "Original Data:\n",
        "Product   Region   Sales\n",
        "Laptop    North    1000\n",
        "Laptop    South     800\n",
        "Phone     North     600\n",
        "Phone     South     500\n",
        "\n",
        "After groupby(['Product', 'Region']):\n",
        "\n",
        "Group 1: (Laptop, North)  \u2192 1000\n",
        "Group 2: (Laptop, South)  \u2192 800\n",
        "Group 3: (Phone, North)   \u2192 600\n",
        "Group 4: (Phone, South)   \u2192 500\n",
        "```\n",
        "\n",
        "### MultiIndex Result\n",
        "\n",
        "Result has a **MultiIndex** (hierarchical index):\n",
        "\n",
        "```python\n",
        "result = df.groupby(['Product', 'Region'])['Sales'].sum()\n",
        "# Index: (Laptop, North), (Laptop, South), ...\n",
        "```\n",
        "\n",
        "### Reset Index\n",
        "\n",
        "```python\n",
        "# Convert MultiIndex back to columns\n",
        "result.reset_index()\n",
        "```\n",
        "\n",
        "### Use Cases\n",
        "- Sales by product \u00d7 region\n",
        "- Revenue by year \u00d7 month\n",
        "- Performance by team \u00d7 employee\n",
        "- Cross-dimensional analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== GROUPING BY MULTIPLE COLUMNS ===\\n\")\n",
        "\n",
        "# Example 1: Product \u00d7 Region analysis\n",
        "print(\"Example 1: Sales by product and region\")\n",
        "product_region = sales_df.groupby(['product', 'region'])['total_amount'].sum()\n",
        "print(product_region.sort_values(ascending=False).head(15))\n",
        "print(f\"\\nIndex type: {type(product_region.index)}\")\n",
        "print()\n",
        "\n",
        "# Example 2: Reset index for cleaner output\n",
        "print(\"Example 2: Same data with reset index\")\n",
        "product_region_df = sales_df.groupby(['product', 'region'])['total_amount'].sum().reset_index()\n",
        "product_region_df.columns = ['Product', 'Region', 'Total_Sales']\n",
        "print(product_region_df.sort_values('Total_Sales', ascending=False).head(10))\n",
        "print()\n",
        "\n",
        "# Example 3: Three-way grouping\n",
        "print(\"Example 3: Product \u00d7 Region \u00d7 Customer Type\")\n",
        "three_way = sales_df.groupby(['product', 'region', 'customer_type']).agg(\n",
        "    total_sales=('total_amount', 'sum'),\n",
        "    num_orders=('order_id', 'count'),\n",
        "    avg_order=('total_amount', 'mean')\n",
        ").round(2)\n",
        "print(three_way.sort_values('total_sales', ascending=False).head(15))\n",
        "print()\n",
        "\n",
        "# Example 4: Month \u00d7 Product analysis\n",
        "print(\"Example 4: Monthly product sales\")\n",
        "monthly_product = sales_df.groupby(['month', 'product']).agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    num_orders=('order_id', 'count')\n",
        ").reset_index()\n",
        "print(monthly_product.sort_values('total_revenue', ascending=False).head(15))\n",
        "print()\n",
        "\n",
        "# Example 5: Comprehensive multi-dimensional analysis\n",
        "print(\"Example 5: Region \u00d7 Customer Type performance\")\n",
        "region_customer = sales_df.groupby(['region', 'customer_type']).agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    avg_order=('total_amount', 'mean'),\n",
        "    num_orders=('order_id', 'count'),\n",
        "    units_sold=('quantity', 'sum'),\n",
        "    unique_products=('product', 'nunique')\n",
        ").round(2).reset_index()\n",
        "print(region_customer.sort_values('total_revenue', ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Transform vs Aggregation\n",
        "\n",
        "### Key Difference\n",
        "\n",
        "| Operation | Returns | Shape | Use Case |\n",
        "|-----------|---------|-------|----------|\n",
        "| **Aggregation** | Summary per group | Reduced (fewer rows) | Get group totals |\n",
        "| **Transform** | Value per row | Same as original | Add group stats to each row |\n",
        "\n",
        "### Visual Comparison\n",
        "\n",
        "```\n",
        "Original (5 rows):\n",
        "Product   Sales\n",
        "Laptop    1000\n",
        "Laptop     800\n",
        "Phone      500\n",
        "Phone      600\n",
        "Tablet     700\n",
        "\n",
        "AGGREGATION (3 rows - one per group):\n",
        "Product   Total_Sales\n",
        "Laptop    1800\n",
        "Phone     1100\n",
        "Tablet     700\n",
        "\n",
        "TRANSFORM (5 rows - same as original):\n",
        "Product   Sales   Group_Total\n",
        "Laptop    1000    1800\n",
        "Laptop     800    1800\n",
        "Phone      500    1100\n",
        "Phone      600    1100\n",
        "Tablet     700     700\n",
        "```\n",
        "\n",
        "### Syntax\n",
        "\n",
        "```python\n",
        "# Aggregation - reduces rows\n",
        "df.groupby('category')['sales'].sum()\n",
        "\n",
        "# Transform - keeps all rows\n",
        "df['group_total'] = df.groupby('category')['sales'].transform('sum')\n",
        "```\n",
        "\n",
        "### Common Use Cases for Transform\n",
        "- Add group mean/median to each row\n",
        "- Calculate percentage of group total\n",
        "- Normalize within groups\n",
        "- Fill missing values with group average\n",
        "- Compare individual to group performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== TRANSFORM VS AGGREGATION ===\\n\")\n",
        "\n",
        "# Example 1: Compare aggregation vs transform\n",
        "print(\"Example 1: Aggregation vs Transform\")\n",
        "print(\"\\nAggregation (reduces rows):\")\n",
        "agg_result = sales_df.groupby('product')['total_amount'].sum()\n",
        "print(f\"Shape: {agg_result.shape}\")\n",
        "print(agg_result.head())\n",
        "\n",
        "print(\"\\nTransform (same number of rows):\")\n",
        "sales_df['product_total'] = sales_df.groupby('product')['total_amount'].transform('sum')\n",
        "print(f\"Shape: {sales_df.shape}\")\n",
        "print(sales_df[['product', 'total_amount', 'product_total']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 2: Add group statistics to each row\n",
        "print(\"Example 2: Add multiple group statistics\")\n",
        "sales_df['product_mean'] = sales_df.groupby('product')['total_amount'].transform('mean')\n",
        "sales_df['product_max'] = sales_df.groupby('product')['total_amount'].transform('max')\n",
        "sales_df['product_min'] = sales_df.groupby('product')['total_amount'].transform('min')\n",
        "print(sales_df[['product', 'total_amount', 'product_mean', 'product_max', 'product_min']].head(10))\n",
        "print()\n",
        "\n",
        "# Example 3: Calculate percentage of group total\n",
        "print(\"Example 3: Percentage of product total\")\n",
        "sales_df['pct_of_product_total'] = (\n",
        "    sales_df['total_amount'] / sales_df['product_total'] * 100\n",
        ").round(2)\n",
        "print(sales_df[['product', 'total_amount', 'product_total', 'pct_of_product_total']].head(15))\n",
        "print()\n",
        "\n",
        "# Example 4: Normalize within groups (z-score)\n",
        "print(\"Example 4: Z-score normalization within products\")\n",
        "sales_df['product_std'] = sales_df.groupby('product')['total_amount'].transform('std')\n",
        "sales_df['z_score'] = (\n",
        "    (sales_df['total_amount'] - sales_df['product_mean']) / sales_df['product_std']\n",
        ").round(2)\n",
        "print(sales_df[['product', 'total_amount', 'product_mean', 'product_std', 'z_score']].head(10))\n",
        "print(\"\\nInterpretation: z_score shows how many std devs from product mean\")\n",
        "print()\n",
        "\n",
        "# Example 5: Rank within groups\n",
        "print(\"Example 5: Rank orders within each product\")\n",
        "sales_df['product_rank'] = sales_df.groupby('product')['total_amount'].rank(\n",
        "    ascending=False, method='dense'\n",
        ")\n",
        "top_orders = sales_df[sales_df['product_rank'] <= 3].sort_values(['product', 'product_rank'])\n",
        "print(top_orders[['product', 'total_amount', 'product_rank']].head(15))\n",
        "print()\n",
        "\n",
        "# Example 6: Fill missing values with group mean\n",
        "print(\"Example 6: Fill missing with group mean (demo)\")\n",
        "# Create sample with missing values\n",
        "demo_df = sales_df[['product', 'total_amount']].head(20).copy()\n",
        "demo_df.loc[2, 'total_amount'] = np.nan\n",
        "demo_df.loc[5, 'total_amount'] = np.nan\n",
        "print(\"Before filling:\")\n",
        "print(demo_df.head(10))\n",
        "print()\n",
        "demo_df['total_amount'] = demo_df.groupby('product')['total_amount'].transform(\n",
        "    lambda x: x.fillna(x.mean())\n",
        ")\n",
        "print(\"After filling with group mean:\")\n",
        "print(demo_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Filtering Groups\n",
        "\n",
        "### What is Group Filtering?\n",
        "\n",
        "**Filter** keeps or removes **entire groups** based on group properties.\n",
        "\n",
        "### Difference from Row Filtering\n",
        "\n",
        "```python\n",
        "# Row filtering: Keep rows where sales > 1000\n",
        "df[df['sales'] > 1000]\n",
        "\n",
        "# Group filtering: Keep groups where total sales > 10000\n",
        "df.groupby('product').filter(lambda x: x['sales'].sum() > 10000)\n",
        "```\n",
        "\n",
        "### Syntax\n",
        "\n",
        "```python\n",
        "df.groupby('column').filter(function)\n",
        "```\n",
        "\n",
        "### Visual Example\n",
        "\n",
        "```\n",
        "Original Data:\n",
        "Product   Sales\n",
        "Laptop    1000    \u2510\n",
        "Laptop     800    \u251c\u2500 Total: 1800 \u2705 Keep\n",
        "Phone      200    \u2518\n",
        "Phone      150    \u251c\u2500 Total: 350 \u274c Remove\n",
        "Tablet    1200    \u2518\n",
        "Tablet     900    \u251c\u2500 Total: 2100 \u2705 Keep\n",
        "\n",
        "Filter: Keep groups with total > 500\n",
        "\n",
        "Result:\n",
        "Product   Sales\n",
        "Laptop    1000\n",
        "Laptop     800\n",
        "Tablet    1200\n",
        "Tablet     900\n",
        "```\n",
        "\n",
        "### Common Use Cases\n",
        "- Keep products with > 100 orders\n",
        "- Remove customers with < $1000 spend\n",
        "- Keep categories with > 5 unique items\n",
        "- Filter groups by size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== FILTERING GROUPS ===\\n\")\n",
        "\n",
        "# Example 1: Keep products with total sales > $20,000\n",
        "print(\"Example 1: Products with total sales > $20,000\")\n",
        "high_revenue_products = sales_df.groupby('product').filter(\n",
        "    lambda x: x['total_amount'].sum() > 20000\n",
        ")\n",
        "print(f\"Original rows: {len(sales_df)}\")\n",
        "print(f\"After filtering: {len(high_revenue_products)}\")\n",
        "print(\"\\nProducts kept:\")\n",
        "print(high_revenue_products.groupby('product')['total_amount'].sum().sort_values(ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 2: Keep regions with > 40 orders\n",
        "print(\"Example 2: Regions with more than 40 orders\")\n",
        "busy_regions = sales_df.groupby('region').filter(\n",
        "    lambda x: len(x) > 40\n",
        ")\n",
        "print(\"Region order counts:\")\n",
        "print(busy_regions.groupby('region').size().sort_values(ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 3: Keep products with average order > $2000\n",
        "print(\"Example 3: Products with high average order value\")\n",
        "high_aov_products = sales_df.groupby('product').filter(\n",
        "    lambda x: x['total_amount'].mean() > 2000\n",
        ")\n",
        "print(high_aov_products.groupby('product')['total_amount'].agg(['mean', 'count']).sort_values('mean', ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 4: Keep groups with low variability (std < 500)\n",
        "print(\"Example 4: Products with consistent pricing (low std dev)\")\n",
        "consistent_products = sales_df.groupby('product').filter(\n",
        "    lambda x: x['total_amount'].std() < 500\n",
        ")\n",
        "print(consistent_products.groupby('product')['total_amount'].agg(['mean', 'std']).sort_values('std'))\n",
        "print()\n",
        "\n",
        "# Example 5: Complex filter - multiple conditions\n",
        "print(\"Example 5: Products with >30 orders AND avg order >$1500\")\n",
        "premium_products = sales_df.groupby('product').filter(\n",
        "    lambda x: (len(x) > 30) and (x['total_amount'].mean() > 1500)\n",
        ")\n",
        "print(premium_products.groupby('product').agg(\n",
        "    num_orders=('order_id', 'count'),\n",
        "    avg_order=('total_amount', 'mean'),\n",
        "    total_revenue=('total_amount', 'sum')\n",
        ").round(2).sort_values('total_revenue', ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 6: Filter vs normal boolean indexing comparison\n",
        "print(\"Example 6: Filter (entire groups) vs Boolean indexing (individual rows)\")\n",
        "print(\"\\nBoolean indexing (rows with sales > 3000):\")\n",
        "high_sales_rows = sales_df[sales_df['total_amount'] > 3000]\n",
        "print(f\"Rows kept: {len(high_sales_rows)}\")\n",
        "print()\n",
        "print(\"Group filter (products with total > 20000):\")\n",
        "print(f\"Rows kept: {len(high_revenue_products)}\")\n",
        "print(\"\\nNote: Filter keeps ALL rows of matching groups!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Apply and Custom Functions\n",
        "\n",
        "### Using apply() with GroupBy\n",
        "\n",
        "**`apply()`** allows you to apply **any function** to each group.\n",
        "\n",
        "### Syntax\n",
        "\n",
        "```python\n",
        "df.groupby('category').apply(function)\n",
        "```\n",
        "\n",
        "### When to Use apply()\n",
        "\n",
        "| Scenario | Use |\n",
        "|----------|-----|\n",
        "| **Built-in aggregation** (sum, mean) | `groupby().sum()` \u2705 Faster |\n",
        "| **Custom logic** | `groupby().apply()` |\n",
        "| **Multiple operations** | `groupby().apply()` |\n",
        "| **Return DataFrame per group** | `groupby().apply()` |\n",
        "\n",
        "### Function Types\n",
        "\n",
        "**1. Lambda functions**\n",
        "```python\n",
        "df.groupby('cat').apply(lambda x: x['sales'].max() - x['sales'].min())\n",
        "```\n",
        "\n",
        "**2. Named functions**\n",
        "```python\n",
        "def custom_stats(group):\n",
        "    return pd.Series({\n",
        "        'total': group['sales'].sum(),\n",
        "        'avg': group['sales'].mean()\n",
        "    })\n",
        "\n",
        "df.groupby('cat').apply(custom_stats)\n",
        "```\n",
        "\n",
        "**3. Return DataFrame**\n",
        "```python\n",
        "def top_n(group, n=3):\n",
        "    return group.nlargest(n, 'sales')\n",
        "\n",
        "df.groupby('cat').apply(top_n, n=5)\n",
        "```\n",
        "\n",
        "### Common Custom Operations\n",
        "- Calculate range (max - min)\n",
        "- Get top N rows per group\n",
        "- Complex statistical calculations\n",
        "- Custom business logic\n",
        "- Weighted averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== APPLY AND CUSTOM FUNCTIONS ===\\n\")\n",
        "\n",
        "# Example 1: Simple lambda with apply\n",
        "print(\"Example 1: Revenue range per product (max - min)\")\n",
        "revenue_range = sales_df.groupby('product')['total_amount'].apply(\n",
        "    lambda x: x.max() - x.min()\n",
        ")\n",
        "print(revenue_range.sort_values(ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 2: Custom function returning Series\n",
        "print(\"Example 2: Custom statistics function\")\n",
        "def custom_stats(group):\n",
        "    return pd.Series({\n",
        "        'total_revenue': group['total_amount'].sum(),\n",
        "        'avg_order': group['total_amount'].mean(),\n",
        "        'revenue_range': group['total_amount'].max() - group['total_amount'].min(),\n",
        "        'num_orders': len(group),\n",
        "        'total_units': group['quantity'].sum()\n",
        "    })\n",
        "\n",
        "product_stats = sales_df.groupby('product').apply(custom_stats).round(2)\n",
        "print(product_stats.sort_values('total_revenue', ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 3: Get top 3 orders per product\n",
        "print(\"Example 3: Top 3 orders for each product\")\n",
        "def top_orders(group, n=3):\n",
        "    return group.nlargest(n, 'total_amount')[['order_id', 'total_amount', 'date']]\n",
        "\n",
        "top_3_per_product = sales_df.groupby('product').apply(top_orders)\n",
        "print(top_3_per_product.head(15))\n",
        "print()\n",
        "\n",
        "# Example 4: Calculate weighted average\n",
        "print(\"Example 4: Weighted average price by quantity\")\n",
        "def weighted_avg(group):\n",
        "    return (group['unit_price'] * group['quantity']).sum() / group['quantity'].sum()\n",
        "\n",
        "weighted_prices = sales_df.groupby('product').apply(weighted_avg).round(2)\n",
        "print(weighted_prices.sort_values(ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 5: Complex business logic\n",
        "print(\"Example 5: Performance score (custom business logic)\")\n",
        "def performance_score(group):\n",
        "    \"\"\"Calculate performance score: revenue * order_count * avg_rating_proxy\"\"\"\n",
        "    revenue = group['total_amount'].sum()\n",
        "    order_count = len(group)\n",
        "    consistency = 1 / (1 + group['total_amount'].std())  # Lower std = more consistent\n",
        "    score = revenue * order_count * consistency\n",
        "    return score\n",
        "\n",
        "performance = sales_df.groupby('product').apply(performance_score).round(2)\n",
        "print(performance.sort_values(ascending=False))\n",
        "print()\n",
        "\n",
        "# Example 6: Multiple group analysis\n",
        "print(\"Example 6: Region \u00d7 Customer Type performance\")\n",
        "def region_customer_analysis(group):\n",
        "    return pd.Series({\n",
        "        'total_revenue': group['total_amount'].sum(),\n",
        "        'num_orders': len(group),\n",
        "        'avg_order': group['total_amount'].mean(),\n",
        "        'avg_discount': group['discount_%'].mean(),\n",
        "        'units_sold': group['quantity'].sum()\n",
        "    })\n",
        "\n",
        "region_customer_perf = sales_df.groupby(['region', 'customer_type']).apply(\n",
        "    region_customer_analysis\n",
        ").round(2)\n",
        "print(region_customer_perf.sort_values('total_revenue', ascending=False).head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Iterating Over Groups\n",
        "\n",
        "### When to Iterate\n",
        "\n",
        "Use iteration when you need to:\n",
        "- Process each group separately\n",
        "- Generate reports per group\n",
        "- Debug groupby operations\n",
        "- Apply operations that can't be vectorized\n",
        "\n",
        "### Syntax\n",
        "\n",
        "```python\n",
        "for name, group in df.groupby('column'):\n",
        "    # name: group identifier\n",
        "    # group: DataFrame for that group\n",
        "    print(f\"Processing {name}\")\n",
        "    print(group)\n",
        "```\n",
        "\n",
        "### Multiple Groupby Columns\n",
        "\n",
        "```python\n",
        "for (col1_val, col2_val), group in df.groupby(['col1', 'col2']):\n",
        "    print(f\"Group: {col1_val}, {col2_val}\")\n",
        "```\n",
        "\n",
        "### Access Specific Group\n",
        "\n",
        "```python\n",
        "# Get specific group\n",
        "grouped = df.groupby('product')\n",
        "laptop_group = grouped.get_group('Laptop')\n",
        "```\n",
        "\n",
        "### Performance Note\n",
        "\u26a0\ufe0f **Iteration is slower** than vectorized operations. Use only when necessary!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== ITERATING OVER GROUPS ===\\n\")\n",
        "\n",
        "# Example 1: Basic iteration\n",
        "print(\"Example 1: Iterate and print summary for each product\")\n",
        "for product_name, product_group in sales_df.groupby('product'):\n",
        "    total = product_group['total_amount'].sum()\n",
        "    count = len(product_group)\n",
        "    print(f\"{product_name}: {count} orders, ${total:,.2f} revenue\")\n",
        "print()\n",
        "\n",
        "# Example 2: Get specific group\n",
        "print(\"Example 2: Access specific group (Laptop)\")\n",
        "grouped = sales_df.groupby('product')\n",
        "laptop_data = grouped.get_group('Laptop')\n",
        "print(f\"Laptop orders: {len(laptop_data)}\")\n",
        "print(laptop_data[['order_id', 'quantity', 'total_amount']].head())\n",
        "print()\n",
        "\n",
        "# Example 3: Multiple groupby columns\n",
        "print(\"Example 3: Iterate over region \u00d7 customer type\")\n",
        "for (region, cust_type), group in sales_df.groupby(['region', 'customer_type']):\n",
        "    revenue = group['total_amount'].sum()\n",
        "    if revenue > 10000:  # Only show significant segments\n",
        "        print(f\"{region} - {cust_type}: ${revenue:,.2f}\")\n",
        "print()\n",
        "\n",
        "# Example 4: Generate report per group\n",
        "print(\"Example 4: Generate mini-reports for each region\")\n",
        "for region, region_data in sales_df.groupby('region'):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"REGION: {region}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Total Orders: {len(region_data)}\")\n",
        "    print(f\"Total Revenue: ${region_data['total_amount'].sum():,.2f}\")\n",
        "    print(f\"Avg Order: ${region_data['total_amount'].mean():,.2f}\")\n",
        "    print(f\"Top Product: {region_data['product'].mode()[0]}\")\n",
        "    print(f\"Unique Customers: {region_data['customer_type'].nunique()}\")\n",
        "print()\n",
        "\n",
        "# Example 5: Filter and process\n",
        "print(\"Example 5: Process only high-revenue products\")\n",
        "for product, product_data in sales_df.groupby('product'):\n",
        "    total_revenue = product_data['total_amount'].sum()\n",
        "    if total_revenue > 30000:\n",
        "        avg_discount = product_data['discount_%'].mean()\n",
        "        print(f\"{product}: ${total_revenue:,.2f} (Avg discount: {avg_discount:.1f}%)\")\n",
        "print()\n",
        "\n",
        "# Example 6: Store groups in dictionary\n",
        "print(\"Example 6: Store each group in a dictionary\")\n",
        "product_dict = {}\n",
        "for product, product_data in sales_df.groupby('product'):\n",
        "    product_dict[product] = product_data\n",
        "\n",
        "print(\"Available products:\", list(product_dict.keys()))\n",
        "print(f\"\\nLaptop group shape: {product_dict['Laptop'].shape}\")\n",
        "print(f\"Phone group shape: {product_dict['Phone'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Comprehensive Business Analysis Example\n",
        "\n",
        "### Scenario: E-commerce Performance Report\n",
        "\n",
        "**Business Questions:**\n",
        "1. Which products are top performers?\n",
        "2. How do different regions compare?\n",
        "3. What's the performance by customer type?\n",
        "4. What are the monthly trends?\n",
        "5. Which product-region combinations are best?\n",
        "6. What's the discount impact analysis?\n",
        "\n",
        "We'll use multiple groupby techniques to answer these questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE E-COMMERCE PERFORMANCE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "\n",
        "# Question 1: Top performing products\n",
        "print(\"1. PRODUCT PERFORMANCE ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "product_performance = sales_df.groupby('product').agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    num_orders=('order_id', 'count'),\n",
        "    avg_order_value=('total_amount', 'mean'),\n",
        "    total_units=('quantity', 'sum'),\n",
        "    avg_discount=('discount_%', 'mean'),\n",
        "    max_order=('total_amount', 'max'),\n",
        "    min_order=('total_amount', 'min')\n",
        ").round(2).sort_values('total_revenue', ascending=False)\n",
        "\n",
        "# Add market share\n",
        "total_revenue = sales_df['total_amount'].sum()\n",
        "product_performance['market_share_%'] = (\n",
        "    product_performance['total_revenue'] / total_revenue * 100\n",
        ").round(2)\n",
        "\n",
        "print(product_performance)\n",
        "print()\n",
        "\n",
        "# Question 2: Regional comparison\n",
        "print(\"2. REGIONAL PERFORMANCE\")\n",
        "print(\"-\" * 80)\n",
        "regional_performance = sales_df.groupby('region').agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    num_orders=('order_id', 'count'),\n",
        "    avg_order=('total_amount', 'mean'),\n",
        "    unique_products=('product', 'nunique'),\n",
        "    total_units=('quantity', 'sum')\n",
        ").round(2).sort_values('total_revenue', ascending=False)\n",
        "print(regional_performance)\n",
        "print()\n",
        "\n",
        "# Question 3: Customer type analysis\n",
        "print(\"3. CUSTOMER TYPE ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "customer_analysis = sales_df.groupby('customer_type').agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    num_orders=('order_id', 'count'),\n",
        "    avg_order=('total_amount', 'mean'),\n",
        "    median_order=('total_amount', 'median'),\n",
        "    avg_units=('quantity', 'mean'),\n",
        "    avg_discount=('discount_%', 'mean')\n",
        ").round(2).sort_values('total_revenue', ascending=False)\n",
        "\n",
        "# Add revenue per order\n",
        "customer_analysis['revenue_per_order'] = (\n",
        "    customer_analysis['total_revenue'] / customer_analysis['num_orders']\n",
        ").round(2)\n",
        "\n",
        "print(customer_analysis)\n",
        "print()\n",
        "\n",
        "# Question 4: Monthly trends\n",
        "print(\"4. MONTHLY TRENDS\")\n",
        "print(\"-\" * 80)\n",
        "monthly_trends = sales_df.groupby('month').agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    num_orders=('order_id', 'count'),\n",
        "    avg_order=('total_amount', 'mean'),\n",
        "    total_units=('quantity', 'sum')\n",
        ").round(2)\n",
        "\n",
        "# Sort by month order\n",
        "month_order = ['January', 'February', 'March']\n",
        "monthly_trends = monthly_trends.reindex([m for m in month_order if m in monthly_trends.index])\n",
        "print(monthly_trends)\n",
        "print()\n",
        "\n",
        "# Question 5: Product \u00d7 Region combinations\n",
        "print(\"5. TOP PRODUCT-REGION COMBINATIONS\")\n",
        "print(\"-\" * 80)\n",
        "product_region = sales_df.groupby(['product', 'region']).agg(\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    num_orders=('order_id', 'count'),\n",
        "    avg_order=('total_amount', 'mean')\n",
        ").round(2).sort_values('total_revenue', ascending=False).head(15)\n",
        "print(product_region)\n",
        "print()\n",
        "\n",
        "# Question 6: Discount impact\n",
        "print(\"6. DISCOUNT IMPACT ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "# Create discount bins\n",
        "sales_df['discount_category'] = pd.cut(\n",
        "    sales_df['discount_%'],\n",
        "    bins=[-1, 0, 10, 20, 100],\n",
        "    labels=['No Discount', 'Low (1-10%)', 'Medium (11-20%)', 'High (>20%)']\n",
        ")\n",
        "\n",
        "discount_impact = sales_df.groupby('discount_category').agg(\n",
        "    num_orders=('order_id', 'count'),\n",
        "    total_revenue=('total_amount', 'sum'),\n",
        "    avg_order=('total_amount', 'mean'),\n",
        "    avg_units=('quantity', 'mean'),\n",
        "    avg_discount=('discount_%', 'mean')\n",
        ").round(2)\n",
        "print(discount_impact)\n",
        "print()\n",
        "\n",
        "# Summary metrics\n",
        "print(\"=\"*80)\n",
        "print(\"EXECUTIVE SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Total Revenue: ${sales_df['total_amount'].sum():,.2f}\")\n",
        "print(f\"Total Orders: {len(sales_df):,}\")\n",
        "print(f\"Average Order Value: ${sales_df['total_amount'].mean():,.2f}\")\n",
        "print(f\"Total Units Sold: {sales_df['quantity'].sum():,}\")\n",
        "print(f\"\\nTop Product: {product_performance.index[0]} (${product_performance.iloc[0]['total_revenue']:,.2f})\")\n",
        "print(f\"Top Region: {regional_performance.index[0]} (${regional_performance.iloc[0]['total_revenue']:,.2f})\")\n",
        "print(f\"Best Customer Type: {customer_analysis.index[0]} (${customer_analysis.iloc[0]['total_revenue']:,.2f})\")\n",
        "print(f\"\\nAverage Discount: {sales_df['discount_%'].mean():.2f}%\")\n",
        "print(f\"Orders with Discount: {(sales_df['discount_%'] > 0).sum()} ({(sales_df['discount_%'] > 0).sum()/len(sales_df)*100:.1f}%)\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Advanced GroupBy Techniques\n",
        "\n",
        "### Multiple Column Selection\n",
        "\n",
        "```python\n",
        "# Select multiple columns for aggregation\n",
        "df.groupby('category')[['sales', 'profit']].sum()\n",
        "```\n",
        "\n",
        "### Grouping by Calculated Columns\n",
        "\n",
        "```python\n",
        "# Group by binned values\n",
        "df.groupby(pd.cut(df['age'], bins=[0, 18, 35, 60, 100])).mean()\n",
        "\n",
        "# Group by date components\n",
        "df.groupby(df['date'].dt.year).sum()\n",
        "df.groupby(df['date'].dt.to_period('M')).sum()\n",
        "```\n",
        "\n",
        "### Grouping with Custom Index\n",
        "\n",
        "```python\n",
        "# Group by index level\n",
        "df.groupby(level=0).sum()  # For MultiIndex\n",
        "```\n",
        "\n",
        "### Handling MultiIndex Results\n",
        "\n",
        "```python\n",
        "# Flatten MultiIndex columns\n",
        "result = df.groupby('cat').agg({'sales': ['sum', 'mean']})\n",
        "result.columns = ['_'.join(col) for col in result.columns]\n",
        "```\n",
        "\n",
        "### Combining GroupBy with Other Operations\n",
        "\n",
        "```python\n",
        "# GroupBy + Sort + Head\n",
        "df.groupby('category').apply(lambda x: x.nlargest(3, 'sales'))\n",
        "\n",
        "# GroupBy + Pivot\n",
        "df.groupby(['product', 'region'])['sales'].sum().unstack()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== ADVANCED GROUPBY TECHNIQUES ===\\n\")\n",
        "\n",
        "# Example 1: Group by date components\n",
        "print(\"Example 1: Group by month and year\")\n",
        "monthly_sales = sales_df.groupby(\n",
        "    sales_df['date'].dt.to_period('M')\n",
        ").agg(\n",
        "    revenue=('total_amount', 'sum'),\n",
        "    orders=('order_id', 'count')\n",
        ").round(2)\n",
        "print(monthly_sales)\n",
        "print()\n",
        "\n",
        "# Example 2: Group by binned values\n",
        "print(\"Example 2: Group by order value bins\")\n",
        "value_bins = pd.cut(\n",
        "    sales_df['total_amount'],\n",
        "    bins=[0, 1000, 3000, 5000, 10000],\n",
        "    labels=['Small (<$1k)', 'Medium ($1-3k)', 'Large ($3-5k)', 'XLarge (>$5k)']\n",
        ")\n",
        "bin_analysis = sales_df.groupby(value_bins).agg(\n",
        "    num_orders=('order_id', 'count'),\n",
        "    avg_amount=('total_amount', 'mean'),\n",
        "    total_revenue=('total_amount', 'sum')\n",
        ").round(2)\n",
        "print(bin_analysis)\n",
        "print()\n",
        "\n",
        "# Example 3: Multiple column selection\n",
        "print(\"Example 3: Aggregate multiple columns simultaneously\")\n",
        "multi_col = sales_df.groupby('product')[['total_amount', 'quantity', 'discount_%']].agg(['mean', 'sum']).round(2)\n",
        "print(multi_col.head())\n",
        "print()\n",
        "\n",
        "# Example 4: Custom grouping function\n",
        "print(\"Example 4: Group by custom function (even/odd order IDs)\")\n",
        "def even_odd(order_id):\n",
        "    return 'Even' if order_id % 2 == 0 else 'Odd'\n",
        "\n",
        "even_odd_analysis = sales_df.groupby(sales_df['order_id'].apply(even_odd)).agg(\n",
        "    num_orders=('order_id', 'count'),\n",
        "    total_revenue=('total_amount', 'sum')\n",
        ").round(2)\n",
        "print(even_odd_analysis)\n",
        "print()\n",
        "\n",
        "# Example 5: GroupBy with unstack (pivot-like)\n",
        "print(\"Example 5: Product \u00d7 Region matrix using unstack\")\n",
        "product_region_matrix = sales_df.groupby(['product', 'region'])['total_amount'].sum().unstack(fill_value=0)\n",
        "print(product_region_matrix)\n",
        "print()\n",
        "\n",
        "# Example 6: Cumulative sum within groups\n",
        "print(\"Example 6: Cumulative revenue by product (sorted by date)\")\n",
        "sales_sorted = sales_df.sort_values('date')\n",
        "sales_sorted['cumulative_revenue'] = sales_sorted.groupby('product')['total_amount'].cumsum()\n",
        "print(sales_sorted[['product', 'date', 'total_amount', 'cumulative_revenue']].head(15))\n",
        "print()\n",
        "\n",
        "# Example 7: Rolling mean within groups\n",
        "print(\"Example 7: 3-order moving average per product\")\n",
        "sales_sorted['rolling_avg'] = sales_sorted.groupby('product')['total_amount'].transform(\n",
        "    lambda x: x.rolling(window=3, min_periods=1).mean()\n",
        ").round(2)\n",
        "print(sales_sorted[['product', 'total_amount', 'rolling_avg']].head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Best Practices & Performance Tips\n",
        "\n",
        "### Best Practices \u2705\n",
        "\n",
        "**1. Use Named Aggregations**\n",
        "```python\n",
        "# \u2705 Clear and readable\n",
        "df.groupby('cat').agg(\n",
        "    total_sales=('sales', 'sum'),\n",
        "    avg_price=('price', 'mean')\n",
        ")\n",
        "\n",
        "# \u274c MultiIndex columns, harder to work with\n",
        "df.groupby('cat').agg({'sales': 'sum', 'price': 'mean'})\n",
        "```\n",
        "\n",
        "**2. Use Built-in Functions When Possible**\n",
        "```python\n",
        "# \u2705 Fast - built-in aggregation\n",
        "df.groupby('cat')['sales'].sum()\n",
        "\n",
        "# \u274c Slower - apply with lambda\n",
        "df.groupby('cat')['sales'].apply(lambda x: x.sum())\n",
        "```\n",
        "\n",
        "**3. Reset Index for Cleaner Results**\n",
        "```python\n",
        "# \u2705 Clean DataFrame\n",
        "result = df.groupby('cat')['sales'].sum().reset_index()\n",
        "\n",
        "# \u274c Grouped column becomes index\n",
        "result = df.groupby('cat')['sales'].sum()\n",
        "```\n",
        "\n",
        "**4. Use Transform for Same-Shape Operations**\n",
        "```python\n",
        "# \u2705 Add group mean to each row\n",
        "df['group_mean'] = df.groupby('cat')['sales'].transform('mean')\n",
        "\n",
        "# \u274c Aggregation reduces rows\n",
        "df.groupby('cat')['sales'].mean()\n",
        "```\n",
        "\n",
        "**5. Filter Groups, Not Rows**\n",
        "```python\n",
        "# \u2705 Keep entire groups\n",
        "df.groupby('product').filter(lambda x: x['sales'].sum() > 1000)\n",
        "\n",
        "# \u274c Filters individual rows\n",
        "df[df['sales'] > 1000]\n",
        "```\n",
        "\n",
        "### Performance Tips \ud83d\ude80\n",
        "\n",
        "**1. Avoid Unnecessary apply()**\n",
        "```python\n",
        "# Fast\n",
        "df.groupby('cat')['sales'].sum()  # ~10ms\n",
        "\n",
        "# Slow\n",
        "df.groupby('cat')['sales'].apply(sum)  # ~100ms\n",
        "```\n",
        "\n",
        "**2. Use Categorical Data Types**\n",
        "```python\n",
        "# Faster groupby on categorical columns\n",
        "df['category'] = df['category'].astype('category')\n",
        "df.groupby('category')['sales'].sum()  # Faster!\n",
        "```\n",
        "\n",
        "**3. Sort Before GroupBy (Sometimes)**\n",
        "```python\n",
        "# Can be faster for large datasets\n",
        "df.sort_values('category').groupby('category', sort=False).sum()\n",
        "```\n",
        "\n",
        "**4. Use as_index=False to Avoid Reset**\n",
        "```python\n",
        "# \u2705 One step\n",
        "df.groupby('cat', as_index=False)['sales'].sum()\n",
        "\n",
        "# \u274c Two steps\n",
        "df.groupby('cat')['sales'].sum().reset_index()\n",
        "```\n",
        "\n",
        "### Common Pitfalls \u274c\n",
        "\n",
        "**1. Forgetting to Aggregate**\n",
        "```python\n",
        "# \u274c Returns GroupBy object, not results\n",
        "grouped = df.groupby('category')\n",
        "\n",
        "# \u2705 Apply aggregation\n",
        "result = df.groupby('category')['sales'].sum()\n",
        "```\n",
        "\n",
        "**2. Confusing Transform and Aggregate**\n",
        "```python\n",
        "# Aggregate: Reduces rows\n",
        "df.groupby('cat')['sales'].sum()  # Returns 1 value per group\n",
        "\n",
        "# Transform: Same number of rows\n",
        "df.groupby('cat')['sales'].transform('sum')  # Returns value for each row\n",
        "```\n",
        "\n",
        "**3. Not Handling MultiIndex**\n",
        "```python\n",
        "# \u274c MultiIndex can be confusing\n",
        "result = df.groupby(['col1', 'col2'])['val'].sum()\n",
        "\n",
        "# \u2705 Flatten with reset_index()\n",
        "result = df.groupby(['col1', 'col2'])['val'].sum().reset_index()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Practice Exercises\n",
        "\n",
        "### Beginner Level (1-5)\n",
        "\n",
        "1. **Calculate total revenue by product**\n",
        "   - Use `groupby('product')['total_amount'].sum()`\n",
        "\n",
        "2. **Count number of orders per region**\n",
        "   - Use `groupby('region').size()`\n",
        "\n",
        "3. **Find average order value by customer type**\n",
        "   - Use `groupby('customer_type')['total_amount'].mean()`\n",
        "\n",
        "4. **Get total units sold per product**\n",
        "   - Use `groupby('product')['quantity'].sum()`\n",
        "\n",
        "5. **Find maximum order amount in each region**\n",
        "   - Use `groupby('region')['total_amount'].max()`\n",
        "\n",
        "### Intermediate Level (6-10)\n",
        "\n",
        "6. **Product statistics: total, average, count**\n",
        "   - Use `groupby('product')['total_amount'].agg(['sum', 'mean', 'count'])`\n",
        "\n",
        "7. **Revenue by product and region**\n",
        "   - Use `groupby(['product', 'region'])['total_amount'].sum()`\n",
        "\n",
        "8. **Add group mean to each row**\n",
        "   - Use `groupby('product')['total_amount'].transform('mean')`\n",
        "\n",
        "9. **Keep only products with > 30 orders**\n",
        "   - Use `groupby('product').filter(lambda x: len(x) > 30)`\n",
        "\n",
        "10. **Calculate market share % for each product**\n",
        "    - Sum by product, divide by total, multiply by 100\n",
        "\n",
        "### Advanced Level (11-15)\n",
        "\n",
        "11. **Top 3 orders for each product**\n",
        "    - Use `groupby('product').apply(lambda x: x.nlargest(3, 'total_amount'))`\n",
        "\n",
        "12. **Calculate weighted average price by quantity**\n",
        "    - Use custom function with apply\n",
        "\n",
        "13. **Monthly revenue with month-over-month growth**\n",
        "    - Group by month, calculate percentage change\n",
        "\n",
        "14. **Rank orders within each product**\n",
        "    - Use `groupby('product')['total_amount'].rank()`\n",
        "\n",
        "15. **Find products with high revenue variability (std > 1000)**\n",
        "    - Use `groupby('product').filter(lambda x: x['total_amount'].std() > 1000)`\n",
        "\n",
        "### Challenge Problems (16-20)\n",
        "\n",
        "16. **Create RFM analysis (Recency, Frequency, Monetary)**\n",
        "    - Group by customer, calculate days since last order, count, total spend\n",
        "\n",
        "17. **Identify \"star\" products: high revenue + high order count + low discount**\n",
        "    - Multiple aggregations with conditions\n",
        "\n",
        "18. **Calculate cohort analysis by first purchase month**\n",
        "    - Complex grouping with date transformations\n",
        "\n",
        "19. **Find cross-sell opportunities (products often bought together)**\n",
        "    - Would require order-level grouping (beyond current dataset)\n",
        "\n",
        "20. **Create a custom performance score combining multiple metrics**\n",
        "    - Custom function with weighted combination of revenue, orders, consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== PRACTICE EXERCISE SOLUTIONS ===\\n\")\n",
        "print(\"Try solving the exercises first, then check solutions!\\n\")\n",
        "\n",
        "# Solution 1\n",
        "print(\"Solution 1: Total revenue by product\")\n",
        "revenue_by_product = sales_df.groupby('product')['total_amount'].sum().sort_values(ascending=False)\n",
        "print(revenue_by_product)\n",
        "print()\n",
        "\n",
        "# Solution 6\n",
        "print(\"Solution 6: Product statistics\")\n",
        "product_stats = sales_df.groupby('product')['total_amount'].agg(['sum', 'mean', 'count'])\n",
        "product_stats.columns = ['Total', 'Average', 'Count']\n",
        "print(product_stats.sort_values('Total', ascending=False))\n",
        "print()\n",
        "\n",
        "# Solution 10\n",
        "print(\"Solution 10: Market share % for each product\")\n",
        "total_revenue = sales_df['total_amount'].sum()\n",
        "market_share = sales_df.groupby('product')['total_amount'].sum()\n",
        "market_share_pct = (market_share / total_revenue * 100).sort_values(ascending=False).round(2)\n",
        "print(market_share_pct)\n",
        "print()\n",
        "\n",
        "# Solution 11\n",
        "print(\"Solution 11: Top 3 orders for each product\")\n",
        "def top3(group):\n",
        "    return group.nlargest(3, 'total_amount')[['order_id', 'total_amount']]\n",
        "\n",
        "top3_per_product = sales_df.groupby('product', group_keys=False).apply(top3)\n",
        "print(top3_per_product.head(15))\n",
        "print()\n",
        "\n",
        "# Solution 14\n",
        "print(\"Solution 14: Rank orders within each product\")\n",
        "sales_df['product_rank'] = sales_df.groupby('product')['total_amount'].rank(\n",
        "    ascending=False, method='dense'\n",
        ")\n",
        "print(sales_df[['product', 'total_amount', 'product_rank']].sort_values(['product', 'product_rank']).head(20))\n",
        "print()\n",
        "\n",
        "# Solution 20\n",
        "print(\"Solution 20: Custom performance score\")\n",
        "def performance_score(group):\n",
        "    revenue = group['total_amount'].sum()\n",
        "    order_count = len(group)\n",
        "    consistency = 1 / (1 + group['total_amount'].std())  # Reward consistency\n",
        "    avg_discount = group['discount_%'].mean()\n",
        "    \n",
        "    # Weighted score\n",
        "    score = (revenue * 0.5 + \n",
        "             order_count * 100 * 0.3 + \n",
        "             consistency * 1000 * 0.1 - \n",
        "             avg_discount * 50 * 0.1)\n",
        "    return score\n",
        "\n",
        "performance_scores = sales_df.groupby('product').apply(performance_score).sort_values(ascending=False)\n",
        "print(performance_scores.round(2))\n",
        "print(\"\\nInterpretation: Higher score = better overall performance\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Try solving the remaining exercises on your own!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Reference Card\n",
        "\n",
        "### Basic GroupBy Syntax\n",
        "\n",
        "```python\n",
        "# Simple groupby + aggregation\n",
        "df.groupby('column')['value'].sum()\n",
        "\n",
        "# Multiple columns\n",
        "df.groupby(['col1', 'col2'])['value'].sum()\n",
        "\n",
        "# Multiple aggregations\n",
        "df.groupby('col')['value'].agg(['sum', 'mean', 'count'])\n",
        "```\n",
        "\n",
        "### Named Aggregations (Recommended)\n",
        "\n",
        "```python\n",
        "df.groupby('category').agg(\n",
        "    total_sales=('sales', 'sum'),\n",
        "    avg_price=('price', 'mean'),\n",
        "    num_orders=('order_id', 'count')\n",
        ")\n",
        "```\n",
        "\n",
        "### Common Aggregation Functions\n",
        "\n",
        "```python\n",
        "sum()      # Total\n",
        "mean()     # Average\n",
        "median()   # Middle value\n",
        "min()      # Minimum\n",
        "max()      # Maximum\n",
        "count()    # Count non-null\n",
        "size()     # Count all (including null)\n",
        "std()      # Standard deviation\n",
        "var()      # Variance\n",
        "nunique()  # Count unique\n",
        "first()    # First value\n",
        "last()     # Last value\n",
        "```\n",
        "\n",
        "### Transform vs Aggregate\n",
        "\n",
        "```python\n",
        "# Aggregate: Reduces rows\n",
        "df.groupby('cat')['sales'].sum()  # One row per group\n",
        "\n",
        "# Transform: Same number of rows\n",
        "df['group_sum'] = df.groupby('cat')['sales'].transform('sum')\n",
        "```\n",
        "\n",
        "### Filter Groups\n",
        "\n",
        "```python\n",
        "# Keep groups where sum > 1000\n",
        "df.groupby('product').filter(lambda x: x['sales'].sum() > 1000)\n",
        "```\n",
        "\n",
        "### Apply Custom Functions\n",
        "\n",
        "```python\n",
        "# Custom aggregation\n",
        "def custom_func(group):\n",
        "    return group['value'].max() - group['value'].min()\n",
        "\n",
        "df.groupby('category').apply(custom_func)\n",
        "```\n",
        "\n",
        "### Iterate Over Groups\n",
        "\n",
        "```python\n",
        "for name, group in df.groupby('category'):\n",
        "    print(f\"Processing {name}\")\n",
        "    print(group.head())\n",
        "```\n",
        "\n",
        "### Reset Index\n",
        "\n",
        "```python\n",
        "# Reset index to columns\n",
        "result = df.groupby('cat')['sales'].sum().reset_index()\n",
        "\n",
        "# Or use as_index=False\n",
        "result = df.groupby('cat', as_index=False)['sales'].sum()\n",
        "```\n",
        "\n",
        "### Common Patterns\n",
        "\n",
        "```python\n",
        "# Top N per group\n",
        "df.groupby('category').apply(lambda x: x.nlargest(3, 'sales'))\n",
        "\n",
        "# Percentage of group total\n",
        "df['pct'] = df['value'] / df.groupby('cat')['value'].transform('sum') * 100\n",
        "\n",
        "# Rank within groups\n",
        "df['rank'] = df.groupby('cat')['value'].rank(ascending=False)\n",
        "\n",
        "# Cumulative sum within groups\n",
        "df['cumsum'] = df.groupby('cat')['value'].cumsum()\n",
        "\n",
        "# Fill missing with group mean\n",
        "df['value'] = df.groupby('cat')['value'].transform(lambda x: x.fillna(x.mean()))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Key Concepts Mastered \u2705\n",
        "\n",
        "**1. Split-Apply-Combine Pattern**\n",
        "- Split data into groups\n",
        "- Apply function to each group\n",
        "- Combine results\n",
        "\n",
        "**2. Aggregation Operations**\n",
        "- Single aggregations: `sum()`, `mean()`, `count()`\n",
        "- Multiple aggregations: `agg(['sum', 'mean'])`\n",
        "- Named aggregations: Clean, readable results\n",
        "- Different aggregations per column\n",
        "\n",
        "**3. Transform Operations**\n",
        "- Add group statistics to each row\n",
        "- Maintain original DataFrame shape\n",
        "- Calculate percentages, z-scores\n",
        "- Fill missing values with group stats\n",
        "\n",
        "**4. Filter Operations**\n",
        "- Keep/remove entire groups\n",
        "- Based on group properties\n",
        "- Different from row filtering\n",
        "\n",
        "**5. Apply Custom Functions**\n",
        "- Lambda functions for simple operations\n",
        "- Named functions for complex logic\n",
        "- Return Series or DataFrame\n",
        "\n",
        "**6. Multiple GroupBy Columns**\n",
        "- Create groups for unique combinations\n",
        "- Results in MultiIndex\n",
        "- Use `reset_index()` for flat structure\n",
        "\n",
        "---\n",
        "\n",
        "### Method Selection Guide\n",
        "\n",
        "| Task | Method | Example |\n",
        "|------|--------|----------|\n",
        "| Get group totals | `agg('sum')` | Revenue per product |\n",
        "| Add group mean to rows | `transform('mean')` | Compare to group avg |\n",
        "| Keep high-performing groups | `filter()` | Products with >1000 orders |\n",
        "| Custom calculations | `apply()` | Weighted averages |\n",
        "| Multiple metrics | `agg({...})` | Total + average + count |\n",
        "| Top N per group | `apply(nlargest)` | Top 3 orders per product |\n",
        "\n",
        "---\n",
        "\n",
        "### Common Patterns\n",
        "\n",
        "**Pattern 1: Basic Analysis**\n",
        "```python\n",
        "df.groupby('category')['sales'].sum().sort_values(ascending=False)\n",
        "```\n",
        "\n",
        "**Pattern 2: Multi-Metric Dashboard**\n",
        "```python\n",
        "df.groupby('product').agg(\n",
        "    total=('sales', 'sum'),\n",
        "    average=('sales', 'mean'),\n",
        "    count=('order_id', 'count')\n",
        ")\n",
        "```\n",
        "\n",
        "**Pattern 3: Percentage Contribution**\n",
        "```python\n",
        "total = df['sales'].sum()\n",
        "df.groupby('product')['sales'].sum() / total * 100\n",
        "```\n",
        "\n",
        "**Pattern 4: Rank Within Groups**\n",
        "```python\n",
        "df['rank'] = df.groupby('category')['sales'].rank(ascending=False)\n",
        "df[df['rank'] <= 3]  # Top 3 per category\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "After mastering GroupBy:\n",
        "1. **Pivot Tables** - Reshape grouped data\n",
        "2. **Time Series** - Date-based grouping and resampling\n",
        "3. **Window Functions** - Rolling calculations within groups\n",
        "4. **Multi-Index** - Advanced hierarchical indexing\n",
        "5. **Performance Optimization** - Speed up large GroupBy operations\n",
        "\n",
        "---\n",
        "\n",
        "### Remember\n",
        "\n",
        "- \ud83c\udfaf **Use named aggregations** for clarity\n",
        "- \u26a1 **Built-in functions** are faster than `apply()`\n",
        "- \ud83d\udcca **Transform** preserves shape, **aggregate** reduces\n",
        "- \ud83d\udd0d **Filter** operates on groups, not rows\n",
        "- \ud83d\udd04 **Reset index** for flat, easy-to-use results\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Grouping! \ud83d\udc3c\ud83d\udcca**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}