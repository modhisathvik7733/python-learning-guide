{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9b6e53",
   "metadata": {},
   "source": [
    "# Advanced Image Processing\n",
    "- Image segmentation, Distance transforms, Registration\n",
    "- Real examples: Object segmentation, Image alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52fa0ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced image processing module loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "print('Advanced image processing module loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520c7d39",
   "metadata": {},
   "source": [
    "## Thresholding Segmentation\n",
    "**Simple method**: Separate foreground from background\n",
    "\n",
    "**Types**:\n",
    "- Global: Single threshold for entire image\n",
    "- Adaptive: Local thresholds\n",
    "- Otsu: Automatic threshold selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62363c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholding:\n",
      "  Threshold value: 100\n",
      "  Foreground pixels: 5013\n",
      "  Background pixels: 34987\n"
     ]
    }
   ],
   "source": [
    "# Grayscale image\n",
    "img = np.random.rand(200, 200) * 100\n",
    "y, x = np.ogrid[:200, :200]\n",
    "img[(y-100)**2 + (x-100)**2 < 40**2] += 100\n",
    "\n",
    "# Simple threshold\n",
    "threshold = 100\n",
    "binary = img > threshold\n",
    "\n",
    "print(f'Thresholding:')\n",
    "print(f'  Threshold value: {threshold}')\n",
    "print(f'  Foreground pixels: {binary.sum()}')\n",
    "print(f'  Background pixels: {(~binary).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf87633",
   "metadata": {},
   "source": [
    "## Distance Transform\n",
    "For each foreground pixel, compute distance to nearest background\n",
    "\n",
    "**Uses**:\n",
    "- Skeletonization (medial axis)\n",
    "- Watershed seed points\n",
    "- Shape analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f4807dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated f-string literal (detected at line 11) (3358457289.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f'\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated f-string literal (detected at line 11)\n"
     ]
    }
   ],
   "source": [
    "# Binary object\n",
    "y, x = np.ogrid[:200, :200]\n",
    "obj = (y-100)**2 + (x-100)**2 < 50**2\n",
    "\n",
    "# Distance transform\n",
    "dist = ndimage.distance_transform_edt(obj)\n",
    "\n",
    "print(f'Distance transform:')\n",
    "print(f'  Max distance (radius): {dist.max():.1f} pixels')\n",
    "print(f'  Center point distance: {dist[100, 100]:.1f}')\n",
    "print(f'\n",
    "Skeletonization: Points where distance is local maximum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddf92a",
   "metadata": {},
   "source": [
    "## Watershed Segmentation\n",
    "Separate touching objects\n",
    "**Method**: Treat image as topographic map, find watershed lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ffcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two touching circles\n",
    "img_touching = np.zeros((200, 300), dtype=bool)\n",
    "img_touching[(y-100)**2 + (x-100)**2 < 45**2] = True\n",
    "img_touching[(y-100)**2 + (x-180)**2 < 45**2] = True\n",
    "\n",
    "print('Watershed segmentation:')\n",
    "print('  1. Distance transform')\n",
    "print('  2. Find local maxima (seeds)')\n",
    "print('  3. Watershed from seeds')\n",
    "print('  Result: Separate touching objects')\n",
    "\n",
    "# Distance transform\n",
    "dist_touching = ndimage.distance_transform_edt(img_touching)\n",
    "\n",
    "# Local maxima as markers\n",
    "local_max = dist_touching > 30\n",
    "markers, n_markers = ndimage.label(local_max)\n",
    "print(f'  Detected {n_markers} objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f597cc",
   "metadata": {},
   "source": [
    "## Image Registration\n",
    "Align two images\n",
    "\n",
    "**Methods**:\n",
    "- Rigid: Translation + rotation\n",
    "- Affine: + scaling + shearing\n",
    "- Non-rigid: Local deformations\n",
    "\n",
    "**Uses**: Medical imaging, satellite, panoramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73755053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference and shifted image\n",
    "ref_img = np.zeros((200, 200))\n",
    "ref_img[80:120, 80:120] = 1\n",
    "\n",
    "# Shifted version\n",
    "shifted = ndimage.shift(ref_img, shift=[10, 15])\n",
    "\n",
    "print('Image registration:')\n",
    "print('  Reference image created')\n",
    "print('  Shifted version: offset=(10, 15)')\n",
    "\n",
    "# Cross-correlation for registration\n",
    "from scipy import signal\n",
    "corr = signal.correlate2d(ref_img, shifted, mode='same')\n",
    "shift_y, shift_x = np.unravel_index(corr.argmax(), corr.shape)\n",
    "detected_shift = (shift_y - 100, shift_x - 100)\n",
    "\n",
    "print(f'  Detected shift: {detected_shift}')\n",
    "print(f'  Error: {np.abs(detected_shift[0]-10)} pixels (y), {np.abs(detected_shift[1]-15)} pixels (x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935fb046",
   "metadata": {},
   "source": [
    "## Real Example: Satellite Image Change Detection\n",
    "Detect changes between two time points\n",
    "Applications: Urban growth, deforestation, disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a52c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate satellite images (before and after)\n",
    "np.random.seed(42)\n",
    "img_before = np.random.rand(300, 300) * 0.3  # Dark (vegetation)\n",
    "\n",
    "# Add buildings in 'before'\n",
    "img_before[50:100, 50:100] = 0.8\n",
    "img_before[150:180, 200:250] = 0.8\n",
    "\n",
    "# 'After': New buildings added\n",
    "img_after = img_before.copy()\n",
    "img_after[200:240, 80:140] = 0.8  # New building\n",
    "img_after[100:130, 200:230] = 0.8  # Another new\n",
    "\n",
    "# Change detection\n",
    "difference = np.abs(img_after - img_before)\n",
    "changes = difference > 0.2\n",
    "\n",
    "# Remove small noise\n",
    "changes_clean = ndimage.binary_opening(changes, iterations=2)\n",
    "\n",
    "# Label changed regions\n",
    "labeled_changes, n_changes = ndimage.label(changes_clean)\n",
    "\n",
    "print('Satellite change detection:')\n",
    "print(f'  Time period: Before → After')\n",
    "print(f'  Changed regions: {n_changes}')\n",
    "print(f'  Total changed area: {changes_clean.sum()} pixels')\n",
    "\n",
    "# Measure each change\n",
    "for i in range(1, n_changes + 1):\n",
    "    change_mask = labeled_changes == i\n",
    "    area = change_mask.sum()\n",
    "    center = ndimage.center_of_mass(change_mask)\n",
    "    print(f'  Change {i}: Area={area} px, Location={center}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8de116",
   "metadata": {},
   "source": [
    "## Image Restoration\n",
    "Recover degraded images\n",
    "\n",
    "**Problems**:\n",
    "- Blur (defocus, motion)\n",
    "- Noise\n",
    "- Missing data\n",
    "\n",
    "**Methods**:\n",
    "- Deconvolution (Wiener filter)\n",
    "- Inpainting (fill missing)\n",
    "- Super-resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93210d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blurred image\n",
    "original = np.zeros((100, 100))\n",
    "original[40:60, 40:60] = 1\n",
    "\n",
    "# Motion blur kernel\n",
    "kernel = np.zeros((15, 15))\n",
    "kernel[7, :] = 1 / 15  # Horizontal blur\n",
    "\n",
    "# Convolve to create blur\n",
    "from scipy.signal import convolve2d\n",
    "blurred = convolve2d(original, kernel, mode='same')\n",
    "\n",
    "print('Image restoration:')\n",
    "print('  Original sharp image')\n",
    "print('  Applied motion blur')\n",
    "print('  Goal: Deconvolution to recover')\n",
    "print('\n",
    "Wiener deconvolution can partially recover')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eebae7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Advanced Techniques:\n",
    "```python\n",
    "# Thresholding\n",
    "binary = img > threshold\n",
    "\n",
    "# Distance transform\n",
    "dist = ndimage.distance_transform_edt(binary)\n",
    "\n",
    "# Watershed (conceptual)\n",
    "# 1. Distance transform\n",
    "# 2. Find local maxima → markers\n",
    "# 3. Apply watershed\n",
    "\n",
    "# Registration (cross-correlation)\n",
    "from scipy.signal import correlate2d\n",
    "corr = correlate2d(img1, img2, mode='same')\n",
    "shift = np.unravel_index(corr.argmax(), corr.shape)\n",
    "```\n",
    "\n",
    "### Applications:\n",
    "\n",
    "**Medical Imaging**:\n",
    "- Organ segmentation\n",
    "- Tumor detection\n",
    "- Multi-modal registration (CT+MRI)\n",
    "\n",
    "**Satellite/Remote Sensing**:\n",
    "- Land classification\n",
    "- Change detection\n",
    "- Disaster monitoring\n",
    "\n",
    "**Manufacturing**:\n",
    "- Defect detection\n",
    "- Quality control\n",
    "- Part inspection\n",
    "\n",
    "**Security**:\n",
    "- Face detection\n",
    "- Object tracking\n",
    "- Anomaly detection\n",
    "\n",
    "### Best Practices:\n",
    "✓ **Preprocess first**: Denoise, enhance contrast  \n",
    "✓ **Choose right method**: Threshold vs watershed  \n",
    "✓ **Post-process**: Morphology to clean results  \n",
    "✓ **Validate**: Check segmentation accuracy  \n",
    "✓ **Tune parameters**: Test on representative data  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
