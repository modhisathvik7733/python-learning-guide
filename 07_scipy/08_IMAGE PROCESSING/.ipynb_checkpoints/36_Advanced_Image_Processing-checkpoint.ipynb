{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# Advanced Image Processing\n- Image segmentation, Distance transforms, Registration\n- Real examples: Object segmentation, Image alignment"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import numpy as np\nfrom scipy import ndimage\nimport matplotlib.pyplot as plt\nprint('Advanced image processing module loaded')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Thresholding Segmentation\n**Simple method**: Separate foreground from background\n\n**Types**:\n- Global: Single threshold for entire image\n- Adaptive: Local thresholds\n- Otsu: Automatic threshold selection"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Grayscale image\nimg = np.random.rand(200, 200) * 100\ny, x = np.ogrid[:200, :200]\nimg[(y-100)**2 + (x-100)**2 < 40**2] += 100\n\n# Simple threshold\nthreshold = 100\nbinary = img > threshold\n\nprint(f'Thresholding:')\nprint(f'  Threshold value: {threshold}')\nprint(f'  Foreground pixels: {binary.sum()}')\nprint(f'  Background pixels: {(~binary).sum()}')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Distance Transform\nFor each foreground pixel, compute distance to nearest background\n\n**Uses**:\n- Skeletonization (medial axis)\n- Watershed seed points\n- Shape analysis"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Binary object\ny, x = np.ogrid[:200, :200]\nobj = (y-100)**2 + (x-100)**2 < 50**2\n\n# Distance transform\ndist = ndimage.distance_transform_edt(obj)\n\nprint(f'Distance transform:')\nprint(f'  Max distance (radius): {dist.max():.1f} pixels')\nprint(f'  Center point distance: {dist[100, 100]:.1f}')\nprint(f'\nSkeletonization: Points where distance is local maximum')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Watershed Segmentation\nSeparate touching objects\n**Method**: Treat image as topographic map, find watershed lines"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Two touching circles\nimg_touching = np.zeros((200, 300), dtype=bool)\nimg_touching[(y-100)**2 + (x-100)**2 < 45**2] = True\nimg_touching[(y-100)**2 + (x-180)**2 < 45**2] = True\n\nprint('Watershed segmentation:')\nprint('  1. Distance transform')\nprint('  2. Find local maxima (seeds)')\nprint('  3. Watershed from seeds')\nprint('  Result: Separate touching objects')\n\n# Distance transform\ndist_touching = ndimage.distance_transform_edt(img_touching)\n\n# Local maxima as markers\nlocal_max = dist_touching > 30\nmarkers, n_markers = ndimage.label(local_max)\nprint(f'  Detected {n_markers} objects')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Image Registration\nAlign two images\n\n**Methods**:\n- Rigid: Translation + rotation\n- Affine: + scaling + shearing\n- Non-rigid: Local deformations\n\n**Uses**: Medical imaging, satellite, panoramas"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Create reference and shifted image\nref_img = np.zeros((200, 200))\nref_img[80:120, 80:120] = 1\n\n# Shifted version\nshifted = ndimage.shift(ref_img, shift=[10, 15])\n\nprint('Image registration:')\nprint('  Reference image created')\nprint('  Shifted version: offset=(10, 15)')\n\n# Cross-correlation for registration\nfrom scipy import signal\ncorr = signal.correlate2d(ref_img, shifted, mode='same')\nshift_y, shift_x = np.unravel_index(corr.argmax(), corr.shape)\ndetected_shift = (shift_y - 100, shift_x - 100)\n\nprint(f'  Detected shift: {detected_shift}')\nprint(f'  Error: {np.abs(detected_shift[0]-10)} pixels (y), {np.abs(detected_shift[1]-15)} pixels (x)')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Real Example: Satellite Image Change Detection\nDetect changes between two time points\nApplications: Urban growth, deforestation, disaster"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Simulate satellite images (before and after)\nnp.random.seed(42)\nimg_before = np.random.rand(300, 300) * 0.3  # Dark (vegetation)\n\n# Add buildings in 'before'\nimg_before[50:100, 50:100] = 0.8\nimg_before[150:180, 200:250] = 0.8\n\n# 'After': New buildings added\nimg_after = img_before.copy()\nimg_after[200:240, 80:140] = 0.8  # New building\nimg_after[100:130, 200:230] = 0.8  # Another new\n\n# Change detection\ndifference = np.abs(img_after - img_before)\nchanges = difference > 0.2\n\n# Remove small noise\nchanges_clean = ndimage.binary_opening(changes, iterations=2)\n\n# Label changed regions\nlabeled_changes, n_changes = ndimage.label(changes_clean)\n\nprint('Satellite change detection:')\nprint(f'  Time period: Before → After')\nprint(f'  Changed regions: {n_changes}')\nprint(f'  Total changed area: {changes_clean.sum()} pixels')\n\n# Measure each change\nfor i in range(1, n_changes + 1):\n    change_mask = labeled_changes == i\n    area = change_mask.sum()\n    center = ndimage.center_of_mass(change_mask)\n    print(f'  Change {i}: Area={area} px, Location={center}')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Image Restoration\nRecover degraded images\n\n**Problems**:\n- Blur (defocus, motion)\n- Noise\n- Missing data\n\n**Methods**:\n- Deconvolution (Wiener filter)\n- Inpainting (fill missing)\n- Super-resolution"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Blurred image\noriginal = np.zeros((100, 100))\noriginal[40:60, 40:60] = 1\n\n# Motion blur kernel\nkernel = np.zeros((15, 15))\nkernel[7, :] = 1 / 15  # Horizontal blur\n\n# Convolve to create blur\nfrom scipy.signal import convolve2d\nblurred = convolve2d(original, kernel, mode='same')\n\nprint('Image restoration:')\nprint('  Original sharp image')\nprint('  Applied motion blur')\nprint('  Goal: Deconvolution to recover')\nprint('\nWiener deconvolution can partially recover')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Summary\n\n### Advanced Techniques:\n```python\n# Thresholding\nbinary = img > threshold\n\n# Distance transform\ndist = ndimage.distance_transform_edt(binary)\n\n# Watershed (conceptual)\n# 1. Distance transform\n# 2. Find local maxima → markers\n# 3. Apply watershed\n\n# Registration (cross-correlation)\nfrom scipy.signal import correlate2d\ncorr = correlate2d(img1, img2, mode='same')\nshift = np.unravel_index(corr.argmax(), corr.shape)\n```\n\n### Applications:\n\n**Medical Imaging**:\n- Organ segmentation\n- Tumor detection\n- Multi-modal registration (CT+MRI)\n\n**Satellite/Remote Sensing**:\n- Land classification\n- Change detection\n- Disaster monitoring\n\n**Manufacturing**:\n- Defect detection\n- Quality control\n- Part inspection\n\n**Security**:\n- Face detection\n- Object tracking\n- Anomaly detection\n\n### Best Practices:\n✓ **Preprocess first**: Denoise, enhance contrast  \n✓ **Choose right method**: Threshold vs watershed  \n✓ **Post-process**: Morphology to clean results  \n✓ **Validate**: Check segmentation accuracy  \n✓ **Tune parameters**: Test on representative data  "]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "name": "python3"},
    "language_info": {"version": "3.8.0"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}