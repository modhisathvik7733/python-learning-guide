{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Least Squares and Curve Fitting\n",
        "- **Purpose**: Fit models to noisy data by minimizing squared errors\n",
        "- **scipy.optimize**: curve_fit, least_squares, leastsq\n",
        "- **Applications**: Regression, parameter estimation, calibration\n",
        "\n",
        "Key concepts:\n",
        "- **Least squares**: Minimize \u03a3(y\u1d62 - f(x\u1d62))\u00b2\n",
        "- **Linear**: y = ax + b (simple regression)\n",
        "- **Nonlinear**: y = f(x; \u03b8) where f is nonlinear in parameters \u03b8\n",
        "- **Weighted**: Give more importance to certain data points\n",
        "- **Robust**: Reduce influence of outliers\n",
        "\n",
        "Real applications:\n",
        "- **Data analysis**: Trend fitting, prediction models\n",
        "- **Physics**: Experimental data fitting, law discovery\n",
        "- **Finance**: Risk models, yield curves\n",
        "- **Biology**: Growth curves, dose-response\n",
        "- **Engineering**: Calibration, system identification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import optimize\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.set_printoptions(precision=4, suppress=True)\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "print(\"Curve fitting module loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Least Squares\n",
        "\n",
        "**Problem**: Fit y = ax + b to data (x, y)\n",
        "\n",
        "**Objective**: Minimize \u03a3(y\u1d62 - (ax\u1d62 + b))\u00b2\n",
        "\n",
        "**Solution**: Closed-form (normal equations)\n",
        "\n",
        "**scipy.stats.linregress**: Convenient for simple linear regression\n",
        "\n",
        "**Returns**: slope, intercept, r-value, p-value, std_err"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate noisy linear data\n",
        "np.random.seed(42)\n",
        "x_data = np.linspace(0, 10, 50)\n",
        "true_slope = 2.5\n",
        "true_intercept = 1.0\n",
        "noise = np.random.randn(50) * 2\n",
        "y_data = true_slope * x_data + true_intercept + noise\n",
        "\n",
        "print(\"Linear Regression: y = ax + b\")\n",
        "print(f\"\\nTrue parameters:\")\n",
        "print(f\"  Slope (a): {true_slope}\")\n",
        "print(f\"  Intercept (b): {true_intercept}\\n\")\n",
        "\n",
        "# Fit using scipy.stats.linregress\n",
        "result = stats.linregress(x_data, y_data)\n",
        "\n",
        "print(\"Fitted parameters:\")\n",
        "print(f\"  Slope: {result.slope:.4f} \u00b1 {result.stderr:.4f}\")\n",
        "print(f\"  Intercept: {result.intercept:.4f} \u00b1 {result.intercept_stderr:.4f}\")\n",
        "print(f\"  R\u00b2 (correlation): {result.rvalue**2:.4f}\")\n",
        "print(f\"  P-value: {result.pvalue:.2e}\")\n",
        "\n",
        "# Predict\n",
        "y_fit = result.slope * x_data + result.intercept\n",
        "\n",
        "# Residuals\n",
        "residuals = y_data - y_fit\n",
        "rmse = np.sqrt(np.mean(residuals**2))\n",
        "\n",
        "print(f\"\\nFit quality:\")\n",
        "print(f\"  RMSE: {rmse:.4f}\")\n",
        "print(f\"  R\u00b2: {result.rvalue**2:.4f} (closer to 1 = better)\")\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Fit\n",
        "axes[0].scatter(x_data, y_data, alpha=0.6, label='Data')\n",
        "axes[0].plot(x_data, y_fit, 'r-', linewidth=2, \n",
        "            label=f'Fit: y = {result.slope:.2f}x + {result.intercept:.2f}')\n",
        "axes[0].plot(x_data, true_slope*x_data + true_intercept, 'g--', \n",
        "            linewidth=2, alpha=0.7, label='True: y = 2.5x + 1.0')\n",
        "axes[0].set_xlabel('x', fontsize=12)\n",
        "axes[0].set_ylabel('y', fontsize=12)\n",
        "axes[0].set_title('Linear Regression Fit', fontsize=14)\n",
        "axes[0].legend(fontsize=10)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Residuals\n",
        "axes[1].scatter(x_data, residuals, alpha=0.6)\n",
        "axes[1].axhline(0, color='r', linestyle='--')\n",
        "axes[1].set_xlabel('x', fontsize=12)\n",
        "axes[1].set_ylabel('Residuals', fontsize=12)\n",
        "axes[1].set_title('Residual Plot (should be random)', fontsize=14)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nGood fit: residuals randomly scattered around zero!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nonlinear Curve Fitting with curve_fit\n",
        "\n",
        "**General form**: y = f(x; \u03b8\u2081, \u03b8\u2082, ...)\n",
        "\n",
        "**Method**: Levenberg-Marquardt algorithm (combines Newton + gradient descent)\n",
        "\n",
        "**Function**: `optimize.curve_fit(f, xdata, ydata, p0=initial_guess)`\n",
        "\n",
        "**Returns**:\n",
        "- `popt`: Optimal parameters\n",
        "- `pcov`: Covariance matrix (uncertainty)\n",
        "\n",
        "**Example**: Exponential growth y = A\u00b7exp(B\u00b7x) + C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exponential model\n",
        "def exponential(x, A, B, C):\n",
        "    return A * np.exp(B * x) + C\n",
        "\n",
        "# Generate data\n",
        "np.random.seed(42)\n",
        "x_data = np.linspace(0, 4, 40)\n",
        "true_params = [2.0, 0.5, 1.0]  # A, B, C\n",
        "y_true = exponential(x_data, *true_params)\n",
        "y_data = y_true + np.random.randn(40) * 0.5\n",
        "\n",
        "print(\"Nonlinear Curve Fitting: y = A\u00b7exp(B\u00b7x) + C\")\n",
        "print(f\"\\nTrue parameters:\")\n",
        "print(f\"  A = {true_params[0]}\")\n",
        "print(f\"  B = {true_params[1]}\")\n",
        "print(f\"  C = {true_params[2]}\\n\")\n",
        "\n",
        "# Fit using curve_fit\n",
        "initial_guess = [1.0, 0.1, 0.0]\n",
        "popt, pcov = optimize.curve_fit(exponential, x_data, y_data, p0=initial_guess)\n",
        "\n",
        "# Extract parameters and uncertainties\n",
        "A_fit, B_fit, C_fit = popt\n",
        "perr = np.sqrt(np.diag(pcov))  # Standard deviation of parameters\n",
        "\n",
        "print(\"Fitted parameters:\")\n",
        "print(f\"  A = {A_fit:.4f} \u00b1 {perr[0]:.4f}\")\n",
        "print(f\"  B = {B_fit:.4f} \u00b1 {perr[1]:.4f}\")\n",
        "print(f\"  C = {C_fit:.4f} \u00b1 {perr[2]:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "x_fine = np.linspace(0, 4, 200)\n",
        "y_fit = exponential(x_fine, *popt)\n",
        "y_true_plot = exponential(x_fine, *true_params)\n",
        "\n",
        "# R\u00b2\n",
        "y_pred_data = exponential(x_data, *popt)\n",
        "ss_res = np.sum((y_data - y_pred_data)**2)\n",
        "ss_tot = np.sum((y_data - np.mean(y_data))**2)\n",
        "r_squared = 1 - (ss_res / ss_tot)\n",
        "\n",
        "print(f\"\\nR\u00b2 = {r_squared:.4f}\")\n",
        "print(f\"RMSE = {np.sqrt(np.mean((y_data - y_pred_data)**2)):.4f}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.scatter(x_data, y_data, alpha=0.6, s=50, label='Noisy data')\n",
        "plt.plot(x_fine, y_fit, 'r-', linewidth=2, \n",
        "         label=f'Fit: {A_fit:.2f}\u00b7exp({B_fit:.2f}x) + {C_fit:.2f}')\n",
        "plt.plot(x_fine, y_true_plot, 'g--', linewidth=2, alpha=0.7,\n",
        "         label='True: 2.0\u00b7exp(0.5x) + 1.0')\n",
        "plt.xlabel('x', fontsize=13)\n",
        "plt.ylabel('y', fontsize=13)\n",
        "plt.title('Nonlinear Curve Fitting: Exponential Model', fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\ncurve_fit successfully estimates parameters from noisy data!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real Example: Stock Volatility Modeling (GARCH)\n",
        "\n",
        "**Problem**: Fit volatility model to stock returns\n",
        "\n",
        "**Model**: Simplified GARCH(1,1) for variance\n",
        "\\[ \\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2 \\]\n",
        "\n",
        "**For simplicity**: Fit exponential moving average of squared returns\n",
        "\\[ \\text{Volatility} = \\sqrt{A \\cdot \\text{EWMA}(r^2)} \\]\n",
        "\n",
        "**Application**: Risk management, options pricing, portfolio optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate stock returns with time-varying volatility\n",
        "np.random.seed(42)\n",
        "n_days = 252  # Trading days\n",
        "time = np.arange(n_days)\n",
        "\n",
        "# True volatility varies with time\n",
        "true_vol = 0.15 + 0.10 * np.sin(2*np.pi*time/252) + 0.05*np.sin(4*np.pi*time/252)\n",
        "returns = true_vol * np.random.randn(n_days)\n",
        "\n",
        "# Realized volatility (rolling std)\n",
        "window = 20\n",
        "realized_vol = np.array([returns[max(0,i-window):i+1].std() \n",
        "                        for i in range(n_days)])\n",
        "\n",
        "print(\"Stock Volatility Estimation\")\n",
        "print(f\"  Data: {n_days} days of returns\")\n",
        "print(f\"  Rolling window: {window} days\\n\")\n",
        "\n",
        "# Fit EWMA model: vol = A * EWMA(returns\u00b2)^0.5 + B\n",
        "def volatility_model(t, A, decay, B):\n",
        "    \"\"\"EWMA-based volatility model\"\"\"\n",
        "    ewma = np.zeros(len(t))\n",
        "    ewma[0] = returns[0]**2\n",
        "    for i in range(1, len(t)):\n",
        "        ewma[i] = decay * ewma[i-1] + (1-decay) * returns[int(t[i])]**2\n",
        "    return A * np.sqrt(ewma) + B\n",
        "\n",
        "# Fit model\n",
        "time_array = np.arange(len(realized_vol))\n",
        "popt, pcov = optimize.curve_fit(\n",
        "    volatility_model, \n",
        "    time_array, \n",
        "    realized_vol,\n",
        "    p0=[1.0, 0.94, 0.0],\n",
        "    bounds=([0.1, 0.8, -0.1], [3.0, 0.99, 0.1])\n",
        ")\n",
        "\n",
        "A_opt, decay_opt, B_opt = popt\n",
        "print(\"Fitted EWMA volatility model:\")\n",
        "print(f\"  Scaling (A): {A_opt:.4f}\")\n",
        "print(f\"  Decay (\u03bb): {decay_opt:.4f}\")\n",
        "print(f\"  Offset (B): {B_opt:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "vol_fitted = volatility_model(time_array, *popt)\n",
        "\n",
        "# Metrics\n",
        "r2 = 1 - np.sum((realized_vol - vol_fitted)**2) / np.sum((realized_vol - realized_vol.mean())**2)\n",
        "print(f\"\\nR\u00b2 = {r2:.4f}\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Returns\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(time, returns, 'b-', alpha=0.5, linewidth=0.5)\n",
        "plt.fill_between(time, -2*true_vol, 2*true_vol, alpha=0.2, color='green',\n",
        "                label='\u00b12\u03c3 true volatility')\n",
        "plt.ylabel('Returns', fontsize=12)\n",
        "plt.title('Stock Returns and Volatility', fontsize=14)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Volatility\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(time, true_vol, 'g--', linewidth=2, alpha=0.7, label='True volatility')\n",
        "plt.plot(time, realized_vol, 'b-', alpha=0.5, linewidth=1, label='Realized vol (20d)')\n",
        "plt.plot(time, vol_fitted, 'r-', linewidth=2, label=f'EWMA model (\u03bb={decay_opt:.3f})')\n",
        "plt.xlabel('Time (days)', fontsize=12)\n",
        "plt.ylabel('Volatility', fontsize=12)\n",
        "plt.title('Volatility Estimation via Curve Fitting', fontsize=14)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nEWMA model captures volatility dynamics for risk management!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polynomial Fitting\n",
        "\n",
        "**Model**: y = a\u2080 + a\u2081x + a\u2082x\u00b2 + ... + a\u2099x\u207f\n",
        "\n",
        "**NumPy function**: `np.polyfit(x, y, deg)`\n",
        "\n",
        "**Warning**: \u26a0\ufe0f High-degree polynomials can overfit!\n",
        "\n",
        "**Use cases**:\n",
        "- Trend lines (degree 1-2)\n",
        "- Calibration curves (degree 2-3)\n",
        "- Local approximation\n",
        "\n",
        "**Alternative**: Use splines for smooth curves (next notebooks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data with cubic trend + noise\n",
        "np.random.seed(42)\n",
        "x_data = np.linspace(-3, 3, 30)\n",
        "y_true = 0.5*x_data**3 - 2*x_data**2 + x_data + 1\n",
        "y_data = y_true + np.random.randn(30) * 2\n",
        "\n",
        "print(\"Polynomial Fitting: Comparing Different Degrees\\n\")\n",
        "\n",
        "# Fit polynomials of different degrees\n",
        "degrees = [1, 2, 3, 9]\n",
        "x_fine = np.linspace(-3, 3, 200)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, deg in enumerate(degrees):\n",
        "    # Fit\n",
        "    coeffs = np.polyfit(x_data, y_data, deg)\n",
        "    poly = np.poly1d(coeffs)\n",
        "    y_fit = poly(x_fine)\n",
        "    \n",
        "    # R\u00b2\n",
        "    y_pred = poly(x_data)\n",
        "    r2 = 1 - np.sum((y_data - y_pred)**2) / np.sum((y_data - y_data.mean())**2)\n",
        "    \n",
        "    # Plot\n",
        "    axes[i].scatter(x_data, y_data, alpha=0.6, s=50, label='Data')\n",
        "    axes[i].plot(x_fine, y_fit, 'r-', linewidth=2, \n",
        "                label=f'Degree {deg} fit')\n",
        "    axes[i].plot(x_fine, 0.5*x_fine**3 - 2*x_fine**2 + x_fine + 1,\n",
        "                'g--', linewidth=2, alpha=0.7, label='True function')\n",
        "    axes[i].set_xlabel('x', fontsize=11)\n",
        "    axes[i].set_ylabel('y', fontsize=11)\n",
        "    axes[i].set_title(f'Degree {deg}: R\u00b2 = {r2:.3f}', fontsize=12)\n",
        "    axes[i].legend(fontsize=9)\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "    axes[i].set_ylim(-15, 15)\n",
        "    \n",
        "    # Print results\n",
        "    print(f\"Degree {deg}: R\u00b2 = {r2:.4f}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey observations:\")\n",
        "print(\"  - Degree 1 (linear): Underfits, misses curvature\")\n",
        "print(\"  - Degree 2 (quadratic): Still underfits slightly\")\n",
        "print(\"  - Degree 3 (cubic): Good fit! Matches true model\")\n",
        "print(\"  - Degree 9: Overfits! Wiggles unrealistically\")\n",
        "print(\"\\n\u26a0\ufe0f  Higher R\u00b2 doesn't always mean better model!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Robust Fitting with least_squares\n",
        "\n",
        "**Problem**: Outliers distort least squares fit\n",
        "\n",
        "**Solution**: Robust loss functions reduce outlier influence\n",
        "\n",
        "**Loss functions**:\n",
        "- `'linear'`: Standard least squares \u03a3r\u00b2\n",
        "- `'soft_l1'`: Smooth approximation to L1\n",
        "- `'huber'`: Quadratic for small errors, linear for large\n",
        "- `'cauchy'`: Very robust to outliers\n",
        "\n",
        "**Function**: `optimize.least_squares(residuals, x0, loss='huber')`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data with outliers\n",
        "np.random.seed(42)\n",
        "x_data = np.linspace(0, 10, 40)\n",
        "y_clean = 2.5 * x_data + 1.0\n",
        "noise = np.random.randn(40) * 1.5\n",
        "y_data = y_clean + noise\n",
        "\n",
        "# Add outliers\n",
        "outlier_indices = [5, 15, 25, 35]\n",
        "y_data[outlier_indices] += np.array([15, -12, 18, -15])\n",
        "\n",
        "print(\"Robust Fitting with Outliers\")\n",
        "print(f\"  Data points: {len(x_data)}\")\n",
        "print(f\"  Outliers: {len(outlier_indices)}\\n\")\n",
        "\n",
        "# Define linear model residuals\n",
        "def residuals_linear(params, x, y):\n",
        "    a, b = params\n",
        "    return y - (a * x + b)\n",
        "\n",
        "# Standard least squares\n",
        "result_std = optimize.least_squares(\n",
        "    residuals_linear, [1, 1], args=(x_data, y_data), loss='linear'\n",
        ")\n",
        "a_std, b_std = result_std.x\n",
        "\n",
        "# Robust least squares (Huber)\n",
        "result_robust = optimize.least_squares(\n",
        "    residuals_linear, [1, 1], args=(x_data, y_data), loss='huber'\n",
        ")\n",
        "a_robust, b_robust = result_robust.x\n",
        "\n",
        "print(\"Standard least squares:\")\n",
        "print(f\"  y = {a_std:.3f}x + {b_std:.3f}\")\n",
        "\n",
        "print(\"\\nRobust least squares (Huber):\")\n",
        "print(f\"  y = {a_robust:.3f}x + {b_robust:.3f}\")\n",
        "\n",
        "print(\"\\nTrue model: y = 2.5x + 1.0\")\n",
        "print(f\"\\nError from true:\")\n",
        "print(f\"  Standard: slope error = {abs(a_std - 2.5):.3f}\")\n",
        "print(f\"  Robust: slope error = {abs(a_robust - 2.5):.3f}\")\n",
        "\n",
        "# Visualize\n",
        "x_plot = np.linspace(0, 10, 100)\n",
        "y_std = a_std * x_plot + b_std\n",
        "y_robust = a_robust * x_plot + b_robust\n",
        "y_true = 2.5 * x_plot + 1.0\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.scatter(x_data, y_data, alpha=0.6, s=50, label='Data')\n",
        "plt.scatter(x_data[outlier_indices], y_data[outlier_indices], \n",
        "           color='red', s=100, marker='X', label='Outliers', zorder=5)\n",
        "plt.plot(x_plot, y_true, 'g--', linewidth=2, alpha=0.7, label='True: y = 2.5x + 1')\n",
        "plt.plot(x_plot, y_std, 'b-', linewidth=2, \n",
        "        label=f'Standard LS: y = {a_std:.2f}x + {b_std:.2f}')\n",
        "plt.plot(x_plot, y_robust, 'r-', linewidth=2,\n",
        "        label=f'Robust (Huber): y = {a_robust:.2f}x + {b_robust:.2f}')\n",
        "plt.xlabel('x', fontsize=13)\n",
        "plt.ylabel('y', fontsize=13)\n",
        "plt.title('Robust Fitting: Handling Outliers', fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nRobust fitting reduces outlier influence!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Main Functions:\n",
        "\n",
        "```python\n",
        "# Linear regression\n",
        "result = stats.linregress(x, y)\n",
        "\n",
        "# Nonlinear curve fitting\n",
        "popt, pcov = optimize.curve_fit(model, x, y, p0=initial_guess)\n",
        "\n",
        "# Polynomial fitting\n",
        "coeffs = np.polyfit(x, y, degree)\n",
        "\n",
        "# Robust fitting\n",
        "result = optimize.least_squares(residuals, x0, loss='huber')\n",
        "```\n",
        "\n",
        "### Method Selection:\n",
        "\n",
        "| Data Type | Method | Function |\n",
        "|-----------|--------|----------|\n",
        "| **Linear** | Linear regression | `stats.linregress` |\n",
        "| **Nonlinear** | Levenberg-Marquardt | `curve_fit` |\n",
        "| **Polynomial** | Least squares | `np.polyfit` |\n",
        "| **Outliers** | Robust loss | `least_squares(loss='huber')` |\n",
        "\n",
        "### Best Practices:\n",
        "\n",
        "\u2713 **Plot data first** to choose appropriate model  \n",
        "\u2713 **Good initial guess** critical for nonlinear  \n",
        "\u2713 **Check residuals** for patterns (should be random)  \n",
        "\u2713 **Use uncertainty** (pcov) for error bars  \n",
        "\u2713 **Avoid overfitting** (high-degree polynomials)  \n",
        "\u2713 **Robust methods** when outliers present  \n",
        "\n",
        "### Model Validation:\n",
        "\n",
        "```python\n",
        "# R\u00b2 (coefficient of determination)\n",
        "ss_res = np.sum((y - y_pred)**2)\n",
        "ss_tot = np.sum((y - y.mean())**2)\n",
        "r_squared = 1 - ss_res/ss_tot\n",
        "\n",
        "# RMSE (root mean squared error)\n",
        "rmse = np.sqrt(np.mean((y - y_pred)**2))\n",
        "\n",
        "# Always plot residuals!\n",
        "residuals = y - y_pred\n",
        "plt.scatter(x, residuals)\n",
        "```\n",
        "\n",
        "### Applications:\n",
        "\n",
        "- **Science**: Fit physical laws to experimental data\n",
        "- **Finance**: Risk models, yield curves, volatility\n",
        "- **Engineering**: Calibration, system identification\n",
        "- **ML**: Feature engineering, model calibration\n",
        "- **Biology**: Growth curves, dose-response\n",
        "\n",
        "### Common Pitfalls:\n",
        "\n",
        "\u26a0\ufe0f **Bad initial guess**: Nonlinear fit converges to local minimum  \n",
        "\u26a0\ufe0f **Overfitting**: High R\u00b2 but poor generalization  \n",
        "\u26a0\ufe0f **Extrapolation**: Model unreliable outside data range  \n",
        "\u26a0\ufe0f **Outliers**: Can severely distort standard least squares  \n",
        "\u26a0\ufe0f **Correlated errors**: Violates assumptions"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}