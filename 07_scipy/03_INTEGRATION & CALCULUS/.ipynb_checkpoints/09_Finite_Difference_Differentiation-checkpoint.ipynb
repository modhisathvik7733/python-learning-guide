{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finite Difference Methods - Numerical Differentiation\n",
        "- **Purpose**: Approximate derivatives from discrete data or functions\n",
        "- **scipy.misc**: derivative function (adaptive)\n",
        "- **Manual methods**: Forward, backward, central difference formulas\n",
        "- **Applications**: Gradient computation, edge detection, rate of change, physics\n",
        "\n",
        "Key concepts:\n",
        "- **Forward difference**: f'(x) \u2248 [f(x+h) - f(x)]/h\n",
        "- **Backward difference**: f'(x) \u2248 [f(x) - f(x-h)]/h\n",
        "- **Central difference**: f'(x) \u2248 [f(x+h) - f(x-h)]/(2h)\n",
        "- **Higher-order**: Second derivative, Richardson extrapolation\n",
        "\n",
        "Real examples:\n",
        "- Velocity from position data\n",
        "- Acceleration from velocity\n",
        "- Rate of chemical reactions\n",
        "- Image gradients for edge detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.misc import derivative\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set print and plot options\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "print(\"Numerical differentiation module loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is a Derivative?\n",
        "\n",
        "**Definition**:\n",
        "\\[ f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h} \\]\n",
        "\n",
        "**Interpretation**:\n",
        "- Rate of change of f at point x\n",
        "- Slope of tangent line\n",
        "- Instantaneous velocity (if f is position)\n",
        "\n",
        "**Problem**: We have discrete data, not continuous function\n",
        "\n",
        "**Solution**: Approximate with finite differences\n",
        "\n",
        "**Accuracy vs Step Size**:\n",
        "- Too large h \u2192 Poor approximation\n",
        "- Too small h \u2192 Numerical errors (cancellation)\n",
        "- Optimal h depends on function and precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forward Difference Method\n",
        "\n",
        "**Formula**:\n",
        "\\[ f'(x) \\approx \\frac{f(x+h) - f(x)}{h} \\]\n",
        "\n",
        "**Accuracy**: O(h) - first-order accurate\n",
        "\n",
        "**Taylor expansion**:\n",
        "\\[ f(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + O(h^3) \\]\n",
        "\n",
        "Rearranging:\n",
        "\\[ f'(x) = \\frac{f(x+h) - f(x)}{h} - \\frac{h}{2}f''(x) + O(h^2) \\]\n",
        "\n",
        "**Error term**: -h\u00b7f''(x)/2\n",
        "\n",
        "**When to use**: At left boundary (can't go backward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_difference(f, x, h=1e-5):\n",
        "    \"\"\"First-order forward difference\"\"\"\n",
        "    return (f(x + h) - f(x)) / h\n",
        "\n",
        "# Test function: f(x) = x\u00b2, f'(x) = 2x\n",
        "def f(x):\n",
        "    return x**2\n",
        "\n",
        "def f_prime_exact(x):\n",
        "    return 2*x\n",
        "\n",
        "x = 2.0\n",
        "exact = f_prime_exact(x)\n",
        "\n",
        "print(\"Forward Difference Method\")\n",
        "print(f\"Function: f(x) = x\u00b2, f'(x) = 2x\")\n",
        "print(f\"Point: x = {x}\")\n",
        "print(f\"Exact derivative: f'({x}) = {exact}\\n\")\n",
        "\n",
        "# Test different step sizes\n",
        "print(f\"{'h':<12} {'Approximation':<15} {'Error':<12} {'Rel Error'}\")\n",
        "print(\"=\"*55)\n",
        "\n",
        "for h in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8]:\n",
        "    approx = forward_difference(f, x, h)\n",
        "    error = abs(approx - exact)\n",
        "    rel_error = error / abs(exact)\n",
        "    print(f\"{h:<12.0e} {approx:<15.10f} {error:<12.2e} {rel_error:.2e}\")\n",
        "\n",
        "print(\"\\nNote: Error decreases linearly with h (O(h) method)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backward Difference Method\n",
        "\n",
        "**Formula**:\n",
        "\\[ f'(x) \\approx \\frac{f(x) - f(x-h)}{h} \\]\n",
        "\n",
        "**Accuracy**: O(h) - first-order accurate\n",
        "\n",
        "**Error term**: h\u00b7f''(x)/2 (opposite sign from forward)\n",
        "\n",
        "**When to use**: At right boundary (can't go forward)\n",
        "\n",
        "**Comparison with forward**:\n",
        "- Same accuracy order\n",
        "- Opposite error direction\n",
        "- Average of both can improve accuracy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def backward_difference(f, x, h=1e-5):\n",
        "    \"\"\"First-order backward difference\"\"\"\n",
        "    return (f(x) - f(x - h)) / h\n",
        "\n",
        "x = 2.0\n",
        "h = 0.01\n",
        "exact = f_prime_exact(x)\n",
        "\n",
        "forward = forward_difference(f, x, h)\n",
        "backward = backward_difference(f, x, h)\n",
        "average = (forward + backward) / 2\n",
        "\n",
        "print(\"Comparison at x=2, h=0.01\")\n",
        "print(f\"\\nExact derivative: {exact}\")\n",
        "print(f\"\\nForward difference:  {forward:.10f}\")\n",
        "print(f\"  Error: {abs(forward - exact):.2e}\")\n",
        "print(f\"\\nBackward difference: {backward:.10f}\")\n",
        "print(f\"  Error: {abs(backward - exact):.2e}\")\n",
        "print(f\"\\nAverage (forward+backward)/2: {average:.10f}\")\n",
        "print(f\"  Error: {abs(average - exact):.2e}\")\n",
        "print(f\"\\nAveraging reduces error by ~100x! (This is central difference)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Central Difference Method\n",
        "\n",
        "**Formula**:\n",
        "\\[ f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h} \\]\n",
        "\n",
        "**Accuracy**: O(h\u00b2) - second-order accurate (much better!)\n",
        "\n",
        "**Derivation from Taylor series**:\n",
        "\\[ f(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(x) + O(h^4) \\]\n",
        "\\[ f(x-h) = f(x) - hf'(x) + \\frac{h^2}{2}f''(x) - \\frac{h^3}{6}f'''(x) + O(h^4) \\]\n",
        "\n",
        "Subtracting:\n",
        "\\[ f(x+h) - f(x-h) = 2hf'(x) + \\frac{h^3}{3}f'''(x) + O(h^5) \\]\n",
        "\n",
        "Therefore:\n",
        "\\[ f'(x) = \\frac{f(x+h) - f(x-h)}{2h} - \\frac{h^2}{6}f'''(x) + O(h^4) \\]\n",
        "\n",
        "**Error term**: -h\u00b2\u00b7f'''(x)/6\n",
        "\n",
        "**Best choice**: Use whenever possible (interior points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def central_difference(f, x, h=1e-5):\n",
        "    \"\"\"Second-order central difference\"\"\"\n",
        "    return (f(x + h) - f(x - h)) / (2*h)\n",
        "\n",
        "x = 2.0\n",
        "exact = f_prime_exact(x)\n",
        "\n",
        "print(\"Central Difference Method (O(h\u00b2))\")\n",
        "print(f\"Function: f(x) = x\u00b2, f'(x) = 2x\")\n",
        "print(f\"Point: x = {x}\")\n",
        "print(f\"Exact derivative: f'({x}) = {exact}\\n\")\n",
        "\n",
        "print(f\"{'h':<12} {'Forward':<15} {'Central':<15} {'Ratio'}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "prev_error_central = None\n",
        "for h in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]:\n",
        "    forward_approx = forward_difference(f, x, h)\n",
        "    central_approx = central_difference(f, x, h)\n",
        "    \n",
        "    error_forward = abs(forward_approx - exact)\n",
        "    error_central = abs(central_approx - exact)\n",
        "    \n",
        "    ratio = error_forward / error_central if error_central > 0 else float('inf')\n",
        "    \n",
        "    print(f\"{h:<12.0e} {error_forward:<15.2e} {error_central:<15.2e} {ratio:<.1f}x\")\n",
        "    \n",
        "print(\"\\nCentral difference is 50-100x more accurate for same h!\")\n",
        "print(\"Error decreases as h\u00b2 (not h), so 10x smaller h \u2192 100x smaller error\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## scipy.misc.derivative()\n",
        "\n",
        "**Adaptive numerical differentiation**:\n",
        "\n",
        "```python\n",
        "from scipy.misc import derivative\n",
        "derivative(func, x0, dx=1.0, n=1, order=3)\n",
        "```\n",
        "\n",
        "**Parameters**:\n",
        "- `func`: Function to differentiate\n",
        "- `x0`: Point at which to evaluate\n",
        "- `dx`: Initial spacing (auto-adjusted)\n",
        "- `n`: Order of derivative (1=first, 2=second, etc.)\n",
        "- `order`: Number of points (3, 5, 7, etc.) - higher = more accurate\n",
        "\n",
        "**Features**:\n",
        "- Automatically chooses step size\n",
        "- Uses Richardson extrapolation\n",
        "- Higher-order formulas available\n",
        "- Can compute 2nd, 3rd derivatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test scipy's derivative function\n",
        "def test_func(x):\n",
        "    return np.sin(x)\n",
        "\n",
        "x = np.pi / 4\n",
        "\n",
        "# Exact derivatives\n",
        "exact_1st = np.cos(x)      # d/dx sin(x) = cos(x)\n",
        "exact_2nd = -np.sin(x)     # d\u00b2/dx\u00b2 sin(x) = -sin(x)\n",
        "exact_3rd = -np.cos(x)     # d\u00b3/dx\u00b3 sin(x) = -cos(x)\n",
        "\n",
        "print(\"scipy.misc.derivative() function\")\n",
        "print(f\"Function: f(x) = sin(x)\")\n",
        "print(f\"Point: x = \u03c0/4 = {x:.6f}\\n\")\n",
        "\n",
        "# First derivative with different orders\n",
        "print(\"First derivative [exact = cos(\u03c0/4) = 0.707107]:\")\n",
        "for order in [3, 5, 7, 9]:\n",
        "    approx = derivative(test_func, x, dx=1e-5, n=1, order=order)\n",
        "    error = abs(approx - exact_1st)\n",
        "    print(f\"  order={order}: {approx:.10f}  (error: {error:.2e})\")\n",
        "\n",
        "# Second derivative\n",
        "print(f\"\\nSecond derivative [exact = -sin(\u03c0/4) = -0.707107]:\")\n",
        "approx_2nd = derivative(test_func, x, dx=1e-5, n=2, order=5)\n",
        "error_2nd = abs(approx_2nd - exact_2nd)\n",
        "print(f\"  Computed: {approx_2nd:.10f}\")\n",
        "print(f\"  Error: {error_2nd:.2e}\")\n",
        "\n",
        "# Third derivative\n",
        "print(f\"\\nThird derivative [exact = -cos(\u03c0/4) = -0.707107]:\")\n",
        "approx_3rd = derivative(test_func, x, dx=1e-5, n=3, order=5)\n",
        "error_3rd = abs(approx_3rd - exact_3rd)\n",
        "print(f\"  Computed: {approx_3rd:.10f}\")\n",
        "print(f\"  Error: {error_3rd:.2e}\")\n",
        "\n",
        "print(\"\\nHigher order \u2192 more accurate (but more function evaluations)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real Example: Velocity and Acceleration from Position\n",
        "\n",
        "**Physics problem**: Given position data x(t), find velocity and acceleration\n",
        "\n",
        "\\[ v(t) = \\frac{dx}{dt} \\quad \\text{(velocity)} \\]\n",
        "\\[ a(t) = \\frac{dv}{dt} = \\frac{d^2x}{dt^2} \\quad \\text{(acceleration)} \\]\n",
        "\n",
        "**Scenario**: Object in free fall\n",
        "- Position: x(t) = h\u2080 - \u00bdgt\u00b2\n",
        "- Velocity: v(t) = -gt\n",
        "- Acceleration: a(t) = -g\n",
        "\n",
        "We'll compute derivatives from position data and compare with analytical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Free fall motion\n",
        "g = 9.81  # m/s\u00b2\n",
        "h0 = 100  # initial height (m)\n",
        "\n",
        "def position(t):\n",
        "    \"\"\"Position during free fall\"\"\"\n",
        "    return h0 - 0.5*g*t**2\n",
        "\n",
        "def velocity_exact(t):\n",
        "    \"\"\"Exact velocity\"\"\"\n",
        "    return -g*t\n",
        "\n",
        "def acceleration_exact(t):\n",
        "    \"\"\"Exact acceleration\"\"\"\n",
        "    return -g\n",
        "\n",
        "# Time array\n",
        "t_array = np.linspace(0, 4, 50)\n",
        "dt = t_array[1] - t_array[0]\n",
        "\n",
        "# Position data\n",
        "x_data = position(t_array)\n",
        "\n",
        "# Compute velocity using central difference (for interior points)\n",
        "v_numerical = np.zeros_like(t_array)\n",
        "v_numerical[0] = (x_data[1] - x_data[0]) / dt  # forward at start\n",
        "v_numerical[-1] = (x_data[-1] - x_data[-2]) / dt  # backward at end\n",
        "for i in range(1, len(t_array)-1):\n",
        "    v_numerical[i] = (x_data[i+1] - x_data[i-1]) / (2*dt)  # central\n",
        "\n",
        "# Compute acceleration from velocity\n",
        "a_numerical = np.zeros_like(t_array)\n",
        "a_numerical[0] = (v_numerical[1] - v_numerical[0]) / dt\n",
        "a_numerical[-1] = (v_numerical[-1] - v_numerical[-2]) / dt\n",
        "for i in range(1, len(t_array)-1):\n",
        "    a_numerical[i] = (v_numerical[i+1] - v_numerical[i-1]) / (2*dt)\n",
        "\n",
        "# Exact values\n",
        "v_exact = velocity_exact(t_array)\n",
        "a_exact = acceleration_exact(t_array)\n",
        "\n",
        "print(\"Free Fall Motion Analysis\")\n",
        "print(f\"Initial height: {h0} m\")\n",
        "print(f\"Gravity: {g} m/s\u00b2\")\n",
        "print(f\"Time step dt: {dt:.3f} s\\n\")\n",
        "\n",
        "# Compare at t=2s\n",
        "idx = np.argmin(np.abs(t_array - 2.0))\n",
        "t_check = t_array[idx]\n",
        "\n",
        "print(f\"At t = {t_check:.2f} s:\")\n",
        "print(f\"\\nVelocity:\")\n",
        "print(f\"  Numerical: {v_numerical[idx]:.4f} m/s\")\n",
        "print(f\"  Exact: {v_exact[idx]:.4f} m/s\")\n",
        "print(f\"  Error: {abs(v_numerical[idx] - v_exact[idx]):.2e} m/s\")\n",
        "\n",
        "print(f\"\\nAcceleration:\")\n",
        "print(f\"  Numerical: {a_numerical[idx]:.4f} m/s\u00b2\")\n",
        "print(f\"  Exact: {a_exact[idx]:.4f} m/s\u00b2\")\n",
        "print(f\"  Error: {abs(a_numerical[idx] - a_exact[idx]):.2e} m/s\u00b2\")\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
        "\n",
        "# Position\n",
        "axes[0].plot(t_array, x_data, 'b-', linewidth=2, label='Position')\n",
        "axes[0].set_ylabel('Position (m)', fontsize=12)\n",
        "axes[0].set_title('Free Fall Motion', fontsize=14)\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Velocity\n",
        "axes[1].plot(t_array, v_numerical, 'ro-', linewidth=2, markersize=3, label='Numerical')\n",
        "axes[1].plot(t_array, v_exact, 'b--', linewidth=2, label='Exact')\n",
        "axes[1].set_ylabel('Velocity (m/s)', fontsize=12)\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Acceleration\n",
        "axes[2].plot(t_array, a_numerical, 'go-', linewidth=2, markersize=3, label='Numerical')\n",
        "axes[2].plot(t_array, a_exact, 'b--', linewidth=2, label='Exact (-g)')\n",
        "axes[2].set_xlabel('Time (s)', fontsize=12)\n",
        "axes[2].set_ylabel('Acceleration (m/s\u00b2)', fontsize=12)\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nNote: Numerical derivatives closely match exact values!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Second Derivative\n",
        "\n",
        "**Central difference for second derivative**:\n",
        "\n",
        "\\[ f''(x) \\approx \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2} \\]\n",
        "\n",
        "**Derivation**:\n",
        "\n",
        "From Taylor series:\n",
        "\\[ f(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(x) + O(h^4) \\]\n",
        "\\[ f(x-h) = f(x) - hf'(x) + \\frac{h^2}{2}f''(x) - \\frac{h^3}{6}f'''(x) + O(h^4) \\]\n",
        "\n",
        "Adding:\n",
        "\\[ f(x+h) + f(x-h) = 2f(x) + h^2f''(x) + O(h^4) \\]\n",
        "\n",
        "Therefore:\n",
        "\\[ f''(x) = \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2} + O(h^2) \\]\n",
        "\n",
        "**Accuracy**: O(h\u00b2) - second-order accurate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def second_derivative(f, x, h=1e-5):\n",
        "    \"\"\"Central difference second derivative\"\"\"\n",
        "    return (f(x + h) - 2*f(x) + f(x - h)) / h**2\n",
        "\n",
        "# Test function: f(x) = x\u00b3, f'(x) = 3x\u00b2, f''(x) = 6x\n",
        "def f_cubic(x):\n",
        "    return x**3\n",
        "\n",
        "def f_double_prime_exact(x):\n",
        "    return 6*x\n",
        "\n",
        "x = 2.0\n",
        "exact_2nd = f_double_prime_exact(x)\n",
        "\n",
        "print(\"Second Derivative Approximation\")\n",
        "print(f\"Function: f(x) = x\u00b3\")\n",
        "print(f\"f'(x) = 3x\u00b2, f''(x) = 6x\")\n",
        "print(f\"Point: x = {x}\")\n",
        "print(f\"Exact f''({x}) = {exact_2nd}\\n\")\n",
        "\n",
        "print(f\"{'h':<12} {'Approximation':<15} {'Error':<12}\")\n",
        "print(\"=\"*45)\n",
        "\n",
        "for h in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]:\n",
        "    approx = second_derivative(f_cubic, x, h)\n",
        "    error = abs(approx - exact_2nd)\n",
        "    print(f\"{h:<12.0e} {approx:<15.10f} {error:<12.2e}\")\n",
        "\n",
        "# Compare with scipy\n",
        "scipy_approx = derivative(f_cubic, x, dx=1e-5, n=2, order=5)\n",
        "print(f\"\\nScipy derivative: {scipy_approx:.10f}\")\n",
        "print(f\"Error: {abs(scipy_approx - exact_2nd):.2e}\")\n",
        "\n",
        "print(\"\\nError decreases as h\u00b2 (second-order method)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Differentiation of Noisy Data\n",
        "\n",
        "**Problem**: Real data often contains noise\n",
        "\n",
        "**Challenge**: Differentiation amplifies noise!\n",
        "- Small errors in data \u2192 large errors in derivative\n",
        "- Higher derivatives amplify noise more\n",
        "\n",
        "**Solutions**:\n",
        "1. **Smoothing**: Apply filter before differentiation\n",
        "2. **Larger step size**: Reduces noise sensitivity (but less accurate)\n",
        "3. **Polynomial fitting**: Fit local polynomial, differentiate analytically\n",
        "4. **Savitzky-Golay filter**: Combines smoothing + differentiation\n",
        "\n",
        "**Trade-off**: Accuracy vs noise robustness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate noisy data\n",
        "t = np.linspace(0, 2*np.pi, 100)\n",
        "y_clean = np.sin(t)\n",
        "noise = 0.1 * np.random.randn(len(t))\n",
        "y_noisy = y_clean + noise\n",
        "\n",
        "dt = t[1] - t[0]\n",
        "\n",
        "# Compute derivatives\n",
        "# Clean data\n",
        "dy_clean = np.gradient(y_clean, dt)\n",
        "dy_exact = np.cos(t)\n",
        "\n",
        "# Noisy data - direct differentiation\n",
        "dy_noisy_direct = np.gradient(y_noisy, dt)\n",
        "\n",
        "# Noisy data - with smoothing (moving average)\n",
        "from scipy.ndimage import uniform_filter1d\n",
        "y_smoothed = uniform_filter1d(y_noisy, size=5, mode='nearest')\n",
        "dy_noisy_smoothed = np.gradient(y_smoothed, dt)\n",
        "\n",
        "print(\"Differentiation of Noisy Data\")\n",
        "print(f\"Function: y = sin(t), y' = cos(t)\")\n",
        "print(f\"Noise level: \u03c3 = 0.1\\n\")\n",
        "\n",
        "# Compute errors (exclude boundaries)\n",
        "mask = slice(10, -10)\n",
        "error_clean = np.mean(np.abs(dy_clean[mask] - dy_exact[mask]))\n",
        "error_noisy = np.mean(np.abs(dy_noisy_direct[mask] - dy_exact[mask]))\n",
        "error_smoothed = np.mean(np.abs(dy_noisy_smoothed[mask] - dy_exact[mask]))\n",
        "\n",
        "print(f\"Mean absolute error:\")\n",
        "print(f\"  Clean data: {error_clean:.4f}\")\n",
        "print(f\"  Noisy (direct): {error_noisy:.4f}  ({error_noisy/error_clean:.1f}x worse)\")\n",
        "print(f\"  Noisy (smoothed): {error_smoothed:.4f}  ({error_smoothed/error_clean:.1f}x worse)\")\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "# Function values\n",
        "axes[0].plot(t, y_clean, 'b-', linewidth=2, label='Clean: sin(t)')\n",
        "axes[0].plot(t, y_noisy, 'r.', markersize=4, alpha=0.5, label='Noisy')\n",
        "axes[0].plot(t, y_smoothed, 'g-', linewidth=2, alpha=0.7, label='Smoothed')\n",
        "axes[0].set_ylabel('y', fontsize=12)\n",
        "axes[0].set_title('Original Data', fontsize=14)\n",
        "axes[0].legend(fontsize=10)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Derivatives\n",
        "axes[1].plot(t, dy_exact, 'b-', linewidth=3, label='Exact: cos(t)', alpha=0.7)\n",
        "axes[1].plot(t, dy_noisy_direct, 'r-', linewidth=1, alpha=0.5, label='From noisy (direct)')\n",
        "axes[1].plot(t, dy_noisy_smoothed, 'g-', linewidth=2, label='From smoothed')\n",
        "axes[1].set_xlabel('t', fontsize=12)\n",
        "axes[1].set_ylabel(\"y' = dy/dt\", fontsize=12)\n",
        "axes[1].set_title('Derivatives', fontsize=14)\n",
        "axes[1].legend(fontsize=10)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey insight: Smoothing before differentiation reduces noise amplification!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NumPy Gradient Function\n",
        "\n",
        "**Convenient function** for discrete data:\n",
        "\n",
        "```python\n",
        "numpy.gradient(f, *varargs)\n",
        "```\n",
        "\n",
        "**Features**:\n",
        "- Computes gradient using central differences (interior)\n",
        "- Automatically handles boundaries (forward/backward)\n",
        "- Works on N-dimensional arrays\n",
        "- Can specify non-uniform spacing\n",
        "\n",
        "**Usage**:\n",
        "```python\n",
        "dy = np.gradient(y, dx)  # uniform spacing\n",
        "dy = np.gradient(y, x)   # non-uniform spacing\n",
        "```\n",
        "\n",
        "**Best for**: Quick derivatives from discrete data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare manual vs np.gradient\n",
        "x = np.linspace(0, 2*np.pi, 50)\n",
        "y = np.sin(x)\n",
        "dx = x[1] - x[0]\n",
        "\n",
        "# Exact derivative\n",
        "dy_exact = np.cos(x)\n",
        "\n",
        "# Manual central difference\n",
        "dy_manual = np.zeros_like(y)\n",
        "dy_manual[0] = (y[1] - y[0]) / dx  # forward\n",
        "dy_manual[-1] = (y[-1] - y[-2]) / dx  # backward\n",
        "for i in range(1, len(x)-1):\n",
        "    dy_manual[i] = (y[i+1] - y[i-1]) / (2*dx)  # central\n",
        "\n",
        "# NumPy gradient\n",
        "dy_numpy = np.gradient(y, dx)\n",
        "\n",
        "print(\"NumPy gradient() vs Manual Implementation\")\n",
        "print(f\"Function: y = sin(x), dy/dx = cos(x)\\n\")\n",
        "\n",
        "# Errors\n",
        "error_manual = np.mean(np.abs(dy_manual - dy_exact))\n",
        "error_numpy = np.mean(np.abs(dy_numpy - dy_exact))\n",
        "\n",
        "print(f\"Mean absolute error:\")\n",
        "print(f\"  Manual: {error_manual:.6f}\")\n",
        "print(f\"  NumPy:  {error_numpy:.6f}\")\n",
        "print(f\"\\nDifference: {abs(error_manual - error_numpy):.2e}\")\n",
        "print(\"Results are essentially identical!\\n\")\n",
        "\n",
        "# Test with non-uniform spacing\n",
        "x_nonuniform = np.concatenate([\n",
        "    np.linspace(0, 1, 10),\n",
        "    np.linspace(1, 2, 30),\n",
        "    np.linspace(2, 3, 10)\n",
        "])\n",
        "y_nonuniform = x_nonuniform**2\n",
        "dy_nonuniform = np.gradient(y_nonuniform, x_nonuniform)\n",
        "dy_exact_nonuniform = 2*x_nonuniform\n",
        "\n",
        "error_nonuniform = np.mean(np.abs(dy_nonuniform - dy_exact_nonuniform))\n",
        "\n",
        "print(\"Non-uniform spacing test:\")\n",
        "print(f\"  Function: y = x\u00b2,  dy/dx = 2x\")\n",
        "print(f\"  Mean error: {error_nonuniform:.6f}\")\n",
        "print(\"\\nNumPy gradient handles non-uniform spacing automatically!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Partial Derivatives (2D Functions)\n",
        "\n",
        "For function f(x, y):\n",
        "\n",
        "**Partial with respect to x**:\n",
        "\\[ \\frac{\\partial f}{\\partial x} \\approx \\frac{f(x+h, y) - f(x-h, y)}{2h} \\]\n",
        "\n",
        "**Partial with respect to y**:\n",
        "\\[ \\frac{\\partial f}{\\partial y} \\approx \\frac{f(x, y+h) - f(x, y-h)}{2h} \\]\n",
        "\n",
        "**Gradient vector**:\n",
        "\\[ \\nabla f = \\left(\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}\\right) \\]\n",
        "\n",
        "**NumPy**: For 2D arrays, `np.gradient()` returns both components\n",
        "\n",
        "**Applications**: Image processing, optimization, fluid dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D function: f(x,y) = x\u00b2y + xy\u00b2\n",
        "def f_2d(x, y):\n",
        "    return x**2 * y + x * y**2\n",
        "\n",
        "# Exact partial derivatives\n",
        "def df_dx_exact(x, y):\n",
        "    return 2*x*y + y**2\n",
        "\n",
        "def df_dy_exact(x, y):\n",
        "    return x**2 + 2*x*y\n",
        "\n",
        "# Create grid\n",
        "x = np.linspace(-2, 2, 50)\n",
        "y = np.linspace(-2, 2, 50)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = f_2d(X, Y)\n",
        "\n",
        "dx = x[1] - x[0]\n",
        "dy = y[1] - y[0]\n",
        "\n",
        "# Compute gradients with NumPy\n",
        "dZ_dy, dZ_dx = np.gradient(Z, dy, dx)  # Note: order is (rows, cols) = (y, x)\n",
        "\n",
        "# Exact gradients\n",
        "dZ_dx_exact = df_dx_exact(X, Y)\n",
        "dZ_dy_exact = df_dy_exact(X, Y)\n",
        "\n",
        "print(\"Partial Derivatives of 2D Function\")\n",
        "print(f\"Function: f(x,y) = x\u00b2y + xy\u00b2\")\n",
        "print(f\"\u2202f/\u2202x = 2xy + y\u00b2\")\n",
        "print(f\"\u2202f/\u2202y = x\u00b2 + 2xy\\n\")\n",
        "\n",
        "# Errors (excluding boundaries)\n",
        "mask = np.s_[5:-5, 5:-5]\n",
        "error_x = np.mean(np.abs(dZ_dx[mask] - dZ_dx_exact[mask]))\n",
        "error_y = np.mean(np.abs(dZ_dy[mask] - dZ_dy_exact[mask]))\n",
        "\n",
        "print(f\"Mean absolute errors:\")\n",
        "print(f\"  \u2202f/\u2202x: {error_x:.6f}\")\n",
        "print(f\"  \u2202f/\u2202y: {error_y:.6f}\")\n",
        "\n",
        "# Check gradient at specific point\n",
        "i, j = 25, 25  # center point\n",
        "x_pt, y_pt = X[i,j], Y[i,j]\n",
        "\n",
        "print(f\"\\nAt point ({x_pt:.2f}, {y_pt:.2f}):\")\n",
        "print(f\"  \u2202f/\u2202x: numerical={dZ_dx[i,j]:.4f}, exact={dZ_dx_exact[i,j]:.4f}\")\n",
        "print(f\"  \u2202f/\u2202y: numerical={dZ_dy[i,j]:.4f}, exact={dZ_dy_exact[i,j]:.4f}\")\n",
        "\n",
        "# Visualize\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Original function\n",
        "ax1 = fig.add_subplot(131, projection='3d')\n",
        "ax1.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.set_zlabel('f(x,y)')\n",
        "ax1.set_title('Function f(x,y)', fontsize=12)\n",
        "\n",
        "# Partial x\n",
        "ax2 = fig.add_subplot(132, projection='3d')\n",
        "ax2.plot_surface(X, Y, dZ_dx, cmap='plasma', alpha=0.8)\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('y')\n",
        "ax2.set_zlabel('\u2202f/\u2202x')\n",
        "ax2.set_title('Partial \u2202f/\u2202x', fontsize=12)\n",
        "\n",
        "# Partial y\n",
        "ax3 = fig.add_subplot(133, projection='3d')\n",
        "ax3.plot_surface(X, Y, dZ_dy, cmap='coolwarm', alpha=0.8)\n",
        "ax3.set_xlabel('x')\n",
        "ax3.set_ylabel('y')\n",
        "ax3.set_zlabel('\u2202f/\u2202y')\n",
        "ax3.set_title('Partial \u2202f/\u2202y', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nNumPy gradient() computes partial derivatives for multi-dimensional arrays!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Finite Difference Methods\n",
        "\n",
        "### First Derivative Formulas:\n",
        "\n",
        "| Method | Formula | Accuracy | Use |\n",
        "|--------|---------|----------|-----|\n",
        "| Forward | [f(x+h) - f(x)]/h | O(h) | Left boundary |\n",
        "| Backward | [f(x) - f(x-h)]/h | O(h) | Right boundary |\n",
        "| Central | [f(x+h) - f(x-h)]/(2h) | O(h\u00b2) | Interior points |\n",
        "\n",
        "### Second Derivative:\n",
        "\n",
        "\\[ f''(x) \\approx \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2} \\quad \\text{[O(h\u00b2)]} \\]\n",
        "\n",
        "### Key Functions:\n",
        "\n",
        "```python\n",
        "# SciPy - adaptive, high accuracy\n",
        "from scipy.misc import derivative\n",
        "df = derivative(f, x0, dx=1e-5, n=1, order=3)\n",
        "\n",
        "# NumPy - discrete data\n",
        "dy = np.gradient(y, dx)  # uniform spacing\n",
        "dy = np.gradient(y, x)   # non-uniform spacing\n",
        "```\n",
        "\n",
        "### Best Practices:\n",
        "\n",
        "\u2713 **Use central difference** when possible (2x more accurate)\n",
        "\u2713 **Step size**: h \u2248 10\u207b\u2075 to 10\u207b\u2077 usually good for double precision\n",
        "\u2713 **Noisy data**: Smooth before differentiating\n",
        "\u2713 **Discrete data**: Use `np.gradient()` for convenience\n",
        "\u2713 **High accuracy**: Use `scipy.misc.derivative()` with order > 3\n",
        "\n",
        "### Accuracy vs Stability:\n",
        "\n",
        "- **Too large h**: Poor approximation (truncation error)\n",
        "- **Too small h**: Numerical cancellation (roundoff error)\n",
        "- **Optimal h**: Balance between truncation and roundoff \u2248 \u221a\u03b5 for O(h\u00b2) methods\n",
        "\n",
        "### Applications:\n",
        "- Physics: velocity, acceleration, forces\n",
        "- Engineering: slopes, rates of change\n",
        "- Image processing: edge detection (gradients)\n",
        "- Optimization: gradient descent\n",
        "- Signal processing: rate of change analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practice Problems\n",
        "\n",
        "1. **Temperature gradient**: Given temperature T(x) data, compute dT/dx\n",
        "\n",
        "2. **Curvature**: For curve y(x), compute \u03ba = y''/[1+(y')\u00b2]^(3/2)\n",
        "\n",
        "3. **Jerk**: Given position data, compute jerk j = da/dt = d\u00b3x/dt\u00b3\n",
        "\n",
        "4. **Laplacian**: For 2D function f(x,y), compute \u2207\u00b2f = \u2202\u00b2f/\u2202x\u00b2 + \u2202\u00b2f/\u2202y\u00b2\n",
        "\n",
        "5. **Error analysis**: Compare forward, backward, central for different h values"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}