{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# Sparse Array Operations\n- Arithmetic, Slicing, Matrix operations\n- Real examples: Document similarity, Matrix computations"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import numpy as np\nfrom scipy import sparse\nimport matplotlib.pyplot as plt\nprint('Sparse operations module loaded')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Arithmetic Operations\n\nSparse matrices support standard operations:\n- **Addition/Subtraction**: A + B, A - B\n- **Multiplication**: A * B (matrix), A.multiply(B) (element-wise)\n- **Scalar**: A * scalar, A / scalar\n- **Power**: A ** n\n\n**Result**: Usually sparse if inputs sparse"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Create sparse matrices\nA = sparse.csr_array([[1, 0, 2], [0, 3, 0], [4, 0, 5]])\nB = sparse.csr_array([[2, 0, 0], [0, 1, 0], [0, 0, 3]])\n\nprint('Matrix A:')\nprint(A.toarray())\nprint('\\nMatrix B:')\nprint(B.toarray())\nprint()\n\n# Addition\nC_add = A + B\nprint('A + B:')\nprint(C_add.toarray())\nprint(f'Non-zeros: {C_add.nnz}\\n')\n\n# Matrix multiplication\nC_mult = A @ B  # or A.dot(B)\nprint('A @ B (matrix multiplication):')\nprint(C_mult.toarray())\nprint(f'Non-zeros: {C_mult.nnz}\\n')\n\n# Element-wise multiplication\nC_elem = A.multiply(B)\nprint('A .* B (element-wise):')\nprint(C_elem.toarray())\nprint(f'Non-zeros: {C_elem.nnz}')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Slicing and Indexing\n\n**CSR**: Fast row slicing\n**CSC**: Fast column slicing\n\n**Operations**:\n- `A[i, :]` - row i\n- `A[:, j]` - column j\n- `A[i, j]` - single element\n- `A[rows, :]` - multiple rows"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Slicing\nA = sparse.csr_array(np.random.rand(5, 5))\nA[A < 0.7] = 0  # Sparsify\nA.eliminate_zeros()\n\nprint('Matrix A:')\nprint(A.toarray())\nprint()\n\n# Row slicing (fast for CSR)\nrow_2 = A[2, :]\nprint(f'Row 2: {row_2.toarray()}')\nprint(f'Type: {type(row_2).__name__}\\n')\n\n# Column slicing (convert to CSC for speed)\nA_csc = A.tocsc()\ncol_3 = A_csc[:, 3]\nprint(f'Column 3: {col_3.toarray().T}')\n\n# Single element\nelement = A[1, 2]\nprint(f'\\nA[1, 2] = {element}')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Matrix-Vector Multiplication\n\n**Most common operation**: A @ x\n\n**Complexity**: O(nnz) - only non-zero elements\n**Dense would be**: O(n²)\n\n**Critical for**: PageRank, power method, iterative solvers"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Large sparse matrix\nn = 10000\ndensity = 0.001\nA = sparse.random(n, n, density=density, format='csr')\nx = np.random.rand(n)\n\nprint(f'Matrix-vector multiplication')\nprint(f'  Matrix: {n}×{n}, density={density*100}%')\nprint(f'  Non-zeros: {A.nnz:,}\\n')\n\nimport time\n\n# Sparse\nstart = time.time()\ny_sparse = A @ x\ntime_sparse = time.time() - start\n\nprint(f'Sparse A @ x: {time_sparse*1000:.2f} ms')\n\n# Dense comparison (if memory allows)\nif n <= 5000:\n    A_dense = A.toarray()\n    start = time.time()\n    y_dense = A_dense @ x\n    time_dense = time.time() - start\n    print(f'Dense A @ x: {time_dense*1000:.2f} ms')\n    print(f'Speedup: {time_dense/time_sparse:.1f}×')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Real Example: TF-IDF Document Similarity\n\n**Problem**: Find similar documents\n**Method**: Cosine similarity of TF-IDF vectors\n\n**Sparse advantage**: Most words not in most documents"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Simulate TF-IDF matrix\nn_docs = 1000\nn_terms = 5000\navg_terms_per_doc = 50\n\nprint('Document Similarity with TF-IDF')\nprint(f'  Documents: {n_docs:,}')\nprint(f'  Vocabulary: {n_terms:,}\\n')\n\n# Build document-term matrix\nnp.random.seed(42)\nrows, cols, data = [], [], []\n\nfor doc in range(n_docs):\n    n_terms_doc = np.random.poisson(avg_terms_per_doc)\n    terms = np.random.choice(n_terms, size=min(n_terms_doc, n_terms), replace=False)\n    tfidf_scores = np.random.rand(len(terms))  # Simplified TF-IDF\n    \n    rows.extend([doc] * len(terms))\n    cols.extend(terms)\n    data.extend(tfidf_scores)\n\ntfidf = sparse.csr_array((data, (rows, cols)), shape=(n_docs, n_terms))\n\nprint(f'TF-IDF matrix:')\nprint(f'  Shape: {tfidf.shape}')\nprint(f'  Non-zeros: {tfidf.nnz:,}')\nprint(f'  Density: {tfidf.nnz/(n_docs*n_terms)*100:.3f}%\\n')\n\n# Normalize rows (for cosine similarity)\nfrom scipy.sparse import linalg as sp_linalg\nrow_norms = np.sqrt(np.array(tfidf.multiply(tfidf).sum(axis=1)).flatten())\ntfidf_normalized = tfidf.copy()\ntfidf_normalized.data /= np.repeat(row_norms, np.diff(tfidf.indptr))\n\n# Find documents similar to document 0\nquery_doc = tfidf_normalized[0]\nsimilarities = tfidf_normalized @ query_doc.T\nsimilarities = np.array(similarities.toarray()).flatten()\n\n# Top 5 similar (excluding self)\ntop_5 = np.argsort(similarities)[::-1][1:6]\n\nprint(f'Top 5 documents similar to Doc 0:')\nfor i, doc_id in enumerate(top_5, 1):\n    print(f'  {i}. Doc {doc_id}: similarity={similarities[doc_id]:.4f}')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Aggregation Operations\n\n**Row/column operations**:\n- `sum(axis)`: Sum along axis\n- `mean(axis)`: Average\n- `max(axis)`, `min(axis)`: Extrema\n\n**Result**: Dense array (usually small)"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# User-item rating matrix\nn_users = 1000\nn_items = 500\nrating_matrix = sparse.random(n_users, n_items, density=0.05, format='csr')\nrating_matrix.data = np.random.randint(1, 6, size=rating_matrix.nnz)  # 1-5 stars\n\nprint('Rating Matrix Analysis')\nprint(f'  Users: {n_users:,}')\nprint(f'  Items: {n_items:,}')\nprint(f'  Ratings: {rating_matrix.nnz:,}\\n')\n\n# Item statistics\nitem_rating_counts = np.array((rating_matrix != 0).sum(axis=0)).flatten()\nitem_avg_ratings = np.array(rating_matrix.sum(axis=0)).flatten() / np.maximum(item_rating_counts, 1)\n\nprint(f'Item statistics:')\nprint(f'  Avg ratings per item: {item_rating_counts.mean():.1f}')\nprint(f'  Most rated item: {item_rating_counts.max()} ratings')\nprint(f'  Items with no ratings: {(item_rating_counts == 0).sum()}\\n')\n\n# User statistics\nuser_rating_counts = np.array((rating_matrix != 0).sum(axis=1)).flatten()\nprint(f'User statistics:')\nprint(f'  Avg ratings per user: {user_rating_counts.mean():.1f}')\nprint(f'  Most active user: {user_rating_counts.max()} ratings')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Summary\n\n### Arithmetic Operations:\n```python\n# Standard operations\nC = A + B  # Addition\nC = A - B  # Subtraction\nC = A @ B  # Matrix multiplication\nC = A.multiply(B)  # Element-wise\nC = A * scalar  # Scalar multiplication\n```\n\n### Slicing:\n```python\n# CSR: fast rows\nrow = A[i, :]\nrows = A[[i, j, k], :]\n\n# CSC: fast columns\nA_csc = A.tocsc()\ncol = A_csc[:, j]\n```\n\n### Aggregation:\n```python\nrow_sums = A.sum(axis=1)  # Sum each row\ncol_means = A.mean(axis=0)  # Average each column\ntotal = A.sum()  # Total sum\nmax_val = A.max()  # Maximum element\n```\n\n### Performance Tips:\n✓ **Use CSR for rows**: Fast row slicing, matrix-vector  \n✓ **Use CSC for columns**: Fast column operations  \n✓ **Avoid element access**: A[i,j] is slow, use slicing  \n✓ **Batch operations**: Better than loops  \n✓ **Keep sparse**: Operations preserve sparsity when possible  "]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "name": "python3"},
    "language_info": {"version": "3.8.0"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}