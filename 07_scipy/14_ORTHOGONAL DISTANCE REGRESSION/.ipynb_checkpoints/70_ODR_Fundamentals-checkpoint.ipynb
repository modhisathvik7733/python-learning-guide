{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# ODR Fundamentals\n- Orthogonal Distance Regression vs Least Squares\n- When to use ODR, Error-in-variables models\n- Real examples: Measurement errors, Calibration"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import numpy as np\nfrom scipy import odr\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nprint('scipy.odr module loaded')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Least Squares vs ODR\n\n**Ordinary Least Squares (OLS)**:\n- Assumes errors only in Y (dependent variable)\n- Minimizes vertical distances\n- Standard regression approach\n- Fast and simple\n\n**Orthogonal Distance Regression (ODR)**:\n- Accounts for errors in both X and Y\n- Minimizes perpendicular (orthogonal) distances\n- Also known as Total Least Squares\n- More accurate when both variables have errors\n\n**When to use ODR**:\n✓ Measurement errors in both variables\n✓ Calibration problems (comparing instruments)\n✓ Functional relationships (no clear dependent variable)\n✓ Method comparison studies\n✓ Error-in-variables models"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["print('OLS vs ODR Comparison\\n')\nprint('='*60)\n\n# Generate data with errors in both X and Y\nnp.random.seed(42)\nn = 50\ntrue_x = np.linspace(0, 10, n)\ntrue_y = 2.5 * true_x + 3  # True relationship: y = 2.5x + 3\n\n# Add measurement errors to both variables\nx_error = np.random.randn(n) * 0.5\ny_error = np.random.randn(n) * 1.0\nx_obs = true_x + x_error\ny_obs = true_y + y_error\n\nprint(f'Sample size: {n} points')\nprint(f'True relationship: y = 2.5*x + 3')\nprint(f'X error std dev: 0.5')\nprint(f'Y error std dev: 1.0\\n')"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Ordinary Least Squares (OLS) fit\nslope_ols, intercept_ols, r, p, se = stats.linregress(x_obs, y_obs)\n\nprint('OLS Fit (assumes no X error):')\nprint('='*40)\nprint(f'  Equation: y = {slope_ols:.4f}*x + {intercept_ols:.4f}')\nprint(f'  R² = {r**2:.4f}')\nprint(f'  Standard error: {se:.4f}')\nprint(f'\\n  Error from true (2.5, 3):')\nprint(f'    Slope error: {abs(slope_ols - 2.5):.4f}')\nprint(f'    Intercept error: {abs(intercept_ols - 3):.4f}')"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Orthogonal Distance Regression (ODR) fit\ndef linear_func(B, x):\n    '''Linear model: y = B[0]*x + B[1]'''\n    return B[0] * x + B[1]\n\n# Create ODR model\nlinear_model = odr.Model(linear_func)\ndata = odr.RealData(x_obs, y_obs)\nodr_obj = odr.ODR(data, linear_model, beta0=[2, 3])  # Initial guess\noutput = odr_obj.run()\n\nprint('\\nODR Fit (accounts for X and Y errors):')\nprint('='*40)\nprint(f'  Equation: y = {output.beta[0]:.4f}*x + {output.beta[1]:.4f}')\nprint(f'  Std errors: [{output.sd_beta[0]:.4f}, {output.sd_beta[1]:.4f}]')\nprint(f'  Residual variance: {output.res_var:.6f}')\nprint(f'\\n  Error from true (2.5, 3):')\nprint(f'    Slope error: {abs(output.beta[0] - 2.5):.4f}')\nprint(f'    Intercept error: {abs(output.beta[1] - 3):.4f}')\nprint('\\n✓ ODR is closer to true parameters!')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Real Example: Instrument Calibration\n\n**Scenario**: Calibrate a new temperature sensor against a reference sensor\n**Problem**: Both sensors have measurement errors\n**Solution**: Use ODR to find the true calibration relationship\n\nThis is a common problem in:  \n- Laboratory equipment calibration\n- Sensor validation\n- Method comparison studies\n- Quality control"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["print('\\nInstrument Calibration Example')\nprint('='*60)\n\nnp.random.seed(42)\n# True temperature values (unknown in practice)\ntrue_temp = np.array([20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70])\n\n# Reference sensor readings (±0.3°C random error)\nreference = true_temp + np.random.randn(len(true_temp)) * 0.3\n\n# New sensor readings (±0.5°C error + slight systematic bias)\n# True relationship: new = 1.02 * true + 0.5\nnew_sensor = 1.02 * true_temp + 0.5 + np.random.randn(len(true_temp)) * 0.5\n\nprint(f'Calibration setup:')\nprint(f'  Number of test points: {len(true_temp)}')\nprint(f'  Temperature range: {true_temp.min()}°C to {true_temp.max()}°C')\nprint(f'  Reference sensor error: ±0.3°C (random)')\nprint(f'  New sensor error: ±0.5°C (random)')\nprint(f'  New sensor bias: Scale=1.02, Offset=0.5°C\\n')"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Calibration using ODR\ndef calib_func(B, x):\n    '''Calibration model: new = B[0] * ref + B[1]'''\n    return B[0] * x + B[1]\n\nmodel = odr.Model(calib_func)\n# Specify errors in both measurements\ndata = odr.RealData(reference, new_sensor, sx=0.3, sy=0.5)\nodr_obj = odr.ODR(data, model, beta0=[1, 0])\nresult = odr_obj.run()\n\nslope, intercept = result.beta\nslope_err, intercept_err = result.sd_beta\n\nprint('Calibration Results:')\nprint('='*40)\nprint(f'Calibration equation:')\nprint(f'  New = {slope:.5f} * Ref + {intercept:.4f}')\nprint(f'\\nParameter uncertainties:')\nprint(f'  Slope: ±{slope_err:.5f}')\nprint(f'  Intercept: ±{intercept_err:.4f}')\nprint(f'\\nTrue values (for comparison):')\nprint(f'  Slope: 1.02000')\nprint(f'  Intercept: 0.5000')\nprint(f'\\n✓ Excellent agreement with true values!')"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# How to use the calibration\nprint('\\nApplying Calibration:')\nprint('='*40)\nprint(f'Correction formula for new sensor readings:')\nprint(f'  Corrected = (New - {intercept:.4f}) / {slope:.5f}')\nprint()\nprint('Example:')\nraw_reading = 50.5\ncorrected = (raw_reading - intercept) / slope\nprint(f'  Raw new sensor reading: {raw_reading}°C')\nprint(f'  Corrected value: {corrected:.2f}°C')\nprint()\nprint('This calibration accounts for both:')\nprint('  1. Scale factor (slope)')\nprint('  2. Offset bias (intercept)')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Error Weighting in ODR\n\n**Purpose**: Account for varying measurement uncertainties\n**Syntax**: `sx` and `sy` parameters in `RealData`\n\n**Use cases**:\n- Heteroscedastic errors (error varies with measurement)\n- Different precision at different points\n- Known measurement uncertainties\n- Weighted regression"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["print('\\nError Weighting Example')\nprint('='*60)\n\n# Generate data with increasing error (heteroscedastic)\nnp.random.seed(42)\nx = np.linspace(0, 10, 20)\ny_true = 2 * x + 1\n\n# Error increases with x (common in real measurements)\nerror_magnitude = 0.5 + 0.1 * x\ny = y_true + np.random.randn(20) * error_magnitude\n\nprint('Data characteristics:')\nprint(f'  Sample size: {len(x)}')\nprint(f'  Error type: Heteroscedastic (increasing with x)')\nprint(f'  Error range: {error_magnitude.min():.2f} to {error_magnitude.max():.2f}')\nprint(f'  True relationship: y = 2*x + 1\\n')"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Unweighted ODR (treats all points equally)\ndata_unweighted = odr.RealData(x, y)\nmodel = odr.Model(linear_func)\nodr_unweighted = odr.ODR(data_unweighted, model, beta0=[2, 1])\nresult_unweighted = odr_unweighted.run()\n\nprint('Unweighted ODR (ignores varying errors):')\nprint('='*40)\nprint(f'  Slope: {result_unweighted.beta[0]:.4f}')\nprint(f'  Intercept: {result_unweighted.beta[1]:.4f}')\nprint(f'  Residual variance: {result_unweighted.res_var:.4f}')"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Weighted ODR (accounts for varying errors)\ndata_weighted = odr.RealData(x, y, sy=error_magnitude)\nodr_weighted = odr.ODR(data_weighted, model, beta0=[2, 1])\nresult_weighted = odr_weighted.run()\n\nprint('\\nWeighted ODR (uses known errors):')\nprint('='*40)\nprint(f'  Slope: {result_weighted.beta[0]:.4f}')\nprint(f'  Intercept: {result_weighted.beta[1]:.4f}')\nprint(f'  Residual variance: {result_weighted.res_var:.4f}')\nprint()\nprint('Effect of weighting:')\nprint('  • More accurate points get higher weight')\nprint('  • Less accurate points get lower weight')\nprint('  • Better parameter estimates overall')\nprint('  ✓ Weighted fit closer to true values!')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Comparison: When to Use Each Method\n\n### Use OLS (Ordinary Least Squares) when:\n- Only Y has measurement error\n- X is controlled/exact (designed experiment)\n- Speed is critical\n- Simple analysis needed\n\n### Use ODR (Orthogonal Distance Regression) when:\n- Both X and Y have measurement errors\n- Calibration problems\n- Method comparison studies\n- No clear dependent variable\n- Need unbiased estimates\n\n### Key Differences:\n\n| Aspect | OLS | ODR |\n|--------|-----|-----|\n| Error model | Y only | X and Y |\n| Distance minimized | Vertical | Perpendicular |\n| Bias when X has error | Yes | No |\n| Speed | Faster | Slower |\n| Complexity | Simple | Moderate |\n| Use case | Regression | Calibration |"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["print('\\nMethod Comparison Summary')\nprint('='*60)\nprint()\nprint('OLS (linregress):')\nprint('  Pros: Fast, simple, well-understood')\nprint('  Cons: Biased if X has errors')\nprint('  Use: Standard regression, Y-only errors\\n')\nprint('ODR (scipy.odr):')\nprint('  Pros: Unbiased, handles X and Y errors')\nprint('  Cons: Slower, more complex')\nprint('  Use: Calibration, method comparison\\n')\nprint('Rule of thumb:')\nprint('  If X error / Y error < 0.1 → OLS is fine')\nprint('  If X error / Y error > 0.1 → Use ODR')\nprint('  If calibration problem → Always use ODR')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Summary\n\n### When to Use ODR:\n✓ Both variables have measurement errors  \n✓ Calibration problems  \n✓ Functional relationships  \n✓ No clear dependent variable  \n✓ Method comparison studies  \n\n### Basic ODR Workflow:\n```python\nfrom scipy import odr\n\n# 1. Define model function\ndef model_func(B, x):\n    return B[0] * x + B[1]  # B = parameters\n\n# 2. Create model and data objects\nmodel = odr.Model(model_func)\ndata = odr.RealData(x, y, sx=x_err, sy=y_err)\n\n# 3. Create and run ODR\nodr_obj = odr.ODR(data, model, beta0=[guess1, guess2])\nresult = odr_obj.run()\n\n# 4. Extract results\nparams = result.beta        # Fitted parameters\nerrors = result.sd_beta      # Standard errors\ncovariance = result.cov_beta # Covariance matrix\n```\n\n### Advantages of ODR:\n- Accounts for errors in all variables  \n- Unbiased parameter estimates  \n- Better for calibration problems  \n- Statistically rigorous  \n- Handles weighted regression  \n\n### OLS vs ODR Trade-offs:\n- **OLS**: Faster, simpler, good when X is error-free\n- **ODR**: More accurate when X has errors, reduces to OLS when sx→0\n- **Bias**: OLS underestimates slope when X has errors\n- **Applications**: OLS for regression, ODR for calibration"]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "name": "python3"},
    "language_info": {"version": "3.8.0"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}