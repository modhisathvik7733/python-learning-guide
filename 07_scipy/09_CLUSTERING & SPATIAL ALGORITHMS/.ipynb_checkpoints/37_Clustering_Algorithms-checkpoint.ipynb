{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# Clustering Algorithms\n- K-means clustering, Vector quantization\n- Real examples: Customer segmentation, Image compression"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import numpy as np\nfrom scipy.cluster.vq import kmeans, vq, whiten\nimport matplotlib.pyplot as plt\nprint('Clustering module loaded')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## K-means Clustering\n**Goal**: Partition data into K clusters\n\n**Algorithm**:\n1. Initialize K centroids randomly\n2. Assign each point to nearest centroid\n3. Update centroids (mean of assigned points)\n4. Repeat until convergence\n\n**Function**: `kmeans(obs, k_or_guess)`"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Generate sample data (3 clusters)\nnp.random.seed(42)\ncluster1 = np.random.randn(100, 2) + [2, 2]\ncluster2 = np.random.randn(100, 2) + [8, 3]\ncluster3 = np.random.randn(100, 2) + [5, 8]\ndata = np.vstack([cluster1, cluster2, cluster3])\n\nprint(f'Data: {len(data)} points in 2D')\n\n# Whiten data (normalize variance)\ndata_whitened = whiten(data)\n\n# K-means\nk = 3\ncentroids, distortion = kmeans(data_whitened, k)\nprint(f'\\nK-means with K={k}')\nprint(f'  Distortion: {distortion:.4f}')\nprint(f'  Centroids shape: {centroids.shape}')\n\n# Assign points to clusters\nidx, _ = vq(data_whitened, centroids)\nprint(f'  Cluster assignments: {np.bincount(idx)}')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Real Example: Customer Segmentation\n**Problem**: Group customers by behavior\n**Data**: Purchase frequency, average spend\n**Goal**: Targeted marketing strategies"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Simulate customer data\nnp.random.seed(42)\nn_customers = 500\n\n# Segment 1: High frequency, high spend\nseg1 = np.column_stack([\n    np.random.uniform(15, 25, 150),  # purchases/month\n    np.random.uniform(200, 400, 150)  # avg spend\n])\n\n# Segment 2: Medium frequency, medium spend\nseg2 = np.column_stack([\n    np.random.uniform(5, 12, 200),\n    np.random.uniform(80, 180, 200)\n])\n\n# Segment 3: Low frequency, low spend\nseg3 = np.column_stack([\n    np.random.uniform(1, 5, 150),\n    np.random.uniform(20, 80, 150)\n])\n\ncustomers = np.vstack([seg1, seg2, seg3])\nprint('Customer Segmentation')\nprint(f'  Total customers: {len(customers)}')\nprint(f'  Features: [purchases/month, avg_spend]\\n')\n\n# Normalize\ncustomers_norm = whiten(customers)\n\n# Cluster\nk = 3\ncentroids, dist = kmeans(customers_norm, k)\nlabels, _ = vq(customers_norm, centroids)\n\nprint(f'Segments found:')\nfor i in range(k):\n    segment = customers[labels == i]\n    print(f'  Segment {i+1}: {len(segment)} customers')\n    print(f'    Avg purchases: {segment[:, 0].mean():.1f}/month')\n    print(f'    Avg spend: ${segment[:, 1].mean():.0f}')\n    \n    # Profile\n    if segment[:, 0].mean() > 15:\n        profile = 'Premium (high value)'\n    elif segment[:, 0].mean() > 7:\n        profile = 'Regular (medium value)'\n    else:\n        profile = 'Occasional (low value)'\n    print(f'    Profile: {profile}\\n')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Elbow Method: Choosing K\nPlot distortion vs K\nLook for 'elbow' where adding clusters gives diminishing returns"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Test different K values\nk_range = range(2, 10)\ndistortions = []\n\nfor k in k_range:\n    centroids, dist = kmeans(customers_norm, k)\n    distortions.append(dist)\n    print(f'K={k}: distortion={dist:.4f}')\n\nprint('\\nOptimal K is where curve bends (elbow)')\nprint('For this data, K=3 shows clear elbow')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Real Example: Image Color Quantization\nReduce colors in image using K-means\nCompression: millions of colors → K representative colors"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Simulate RGB image (100x100 pixels)\nnp.random.seed(42)\nimg_rgb = np.random.rand(100, 100, 3)\nprint(f'Image compression via color quantization')\nprint(f'  Original: {img_rgb.shape[0]}x{img_rgb.shape[1]} pixels')\nprint(f'  Channels: RGB (3)\\n')\n\n# Reshape to (n_pixels, 3)\npixels = img_rgb.reshape(-1, 3)\nprint(f'Total pixels: {len(pixels)}')\nprint(f'Original colors: {len(np.unique(pixels, axis=0))}\\n')\n\n# Quantize to K colors\nk_colors = 16\ncentroids, _ = kmeans(pixels, k_colors)\nlabels, _ = vq(pixels, centroids)\n\n# Reconstruct\nquantized_pixels = centroids[labels]\nimg_quantized = quantized_pixels.reshape(img_rgb.shape)\n\nprint(f'After quantization to {k_colors} colors:')\nprint(f'  Unique colors: {k_colors}')\nprint(f'  Compression ratio: {len(np.unique(pixels, axis=0)) / k_colors:.1f}:1')\n\n# Calculate error\nmse = np.mean((img_rgb - img_quantized)**2)\npsnr = 10 * np.log10(1 / mse)\nprint(f'  MSE: {mse:.6f}')\nprint(f'  PSNR: {psnr:.2f} dB')"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Summary\n\n### K-means Functions:\n```python\nfrom scipy.cluster.vq import kmeans, vq, whiten\n\n# 1. Normalize data (important!)\ndata_norm = whiten(data)\n\n# 2. Compute centroids\ncentroids, distortion = kmeans(data_norm, k)\n\n# 3. Assign to clusters\nlabels, distances = vq(data_norm, centroids)\n```\n\n### Key Parameters:\n- **K**: Number of clusters (use elbow method)\n- **whiten**: Normalize features (critical for scale differences)\n- **iter**: Max iterations (default: 20)\n\n### Applications:\n✓ **Marketing**: Customer segmentation  \n✓ **Image**: Color quantization, compression  \n✓ **Biology**: Gene expression clustering  \n✓ **Anomaly**: Outlier detection  \n✓ **Recommendation**: User grouping  \n\n### Best Practices:\n✓ **Always whiten**: Normalize feature scales  \n✓ **Choose K carefully**: Use elbow method or domain knowledge  \n✓ **Multiple runs**: K-means can find local minima  \n✓ **Check results**: Validate cluster quality  "]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "name": "python3"},
    "language_info": {"version": "3.8.0"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}