


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import (
    StandardScaler, MinMaxScaler, RobustScaler, 
    PowerTransformer, Normalizer
)
from sklearn.datasets import load_diabetes, load_wine

# Set random seed for reproducibility
np.random.seed(42)





# Create sample employee data
data = {
    'age': [25, 30, 35, 40, 45, 50, 28, 33, 38, 43],
    'salary': [45000, 55000, 65000, 75000, 85000, 95000, 50000, 60000, 70000, 80000],
    'experience_years': [2, 5, 8, 12, 15, 20, 3, 6, 10, 14],
    'hours_per_week': [40, 45, 42, 38, 50, 48, 41, 43, 39, 46]
}

df = pd.DataFrame(data)

print("Original Data:")
print(df)
print("\nStatistics:")
print(df.describe())

# Notice the different scales:
print("\nFeature Ranges:")
for col in df.columns:
    print(f"{col:20s}: [{df[col].min():,.0f}, {df[col].max():,.0f}]")





# StandardScaler
scaler_std = StandardScaler()

# Fit and transform
df_std = pd.DataFrame(
    scaler_std.fit_transform(df),
    columns=df.columns
)

print("StandardScaler Results:")
print(df_std.round(3))
print("\nVerify: Mean ≈ 0, Std ≈ 1")
print(df_std.describe().round(3))

# Access learned parameters
print("\nLearned Parameters:")
print(f"Mean (µ):  {scaler_std.mean_}")
print(f"Std (σ):   {np.sqrt(scaler_std.var_)}")





# MinMaxScaler (default: [0, 1])
scaler_minmax = MinMaxScaler()
df_minmax = pd.DataFrame(
    scaler_minmax.fit_transform(df),
    columns=df.columns
)

print("MinMaxScaler Results (range [0, 1]):")
print(df_minmax.round(3))
print("\nMin and Max values:")
print(f"Min: {df_minmax.min().values}")
print(f"Max: {df_minmax.max().values}")

# Custom range [-1, 1]
scaler_custom = MinMaxScaler(feature_range=(-1, 1))
df_custom = pd.DataFrame(
    scaler_custom.fit_transform(df),
    columns=df.columns
)

print("\nMinMaxScaler with custom range [-1, 1]:")
print(df_custom.round(3))
print(f"\nRange: [{df_custom.min().min():.1f}, {df_custom.max().max():.1f}]")





# Add outlier to demonstrate RobustScaler
df_with_outlier = df.copy()
df_with_outlier.loc[10] = [25, 250000, 2, 40]  # Salary outlier!

print("Data with Outlier:")
print(df_with_outlier)

# Compare StandardScaler vs RobustScaler
print("\n" + "="*60)
print("COMPARISON: StandardScaler vs RobustScaler")
print("="*60)

# StandardScaler (affected by outlier)
std_scaler = StandardScaler()
df_std_out = pd.DataFrame(
    std_scaler.fit_transform(df_with_outlier),
    columns=df.columns
)

# RobustScaler (not affected by outlier)
robust_scaler = RobustScaler()
df_robust = pd.DataFrame(
    robust_scaler.fit_transform(df_with_outlier),
    columns=df.columns
)

print("\nStandardScaler (salary column):")
print(df_std_out['salary'].values)
print(f"Notice: Outlier at index 10 has value {df_std_out['salary'].iloc[10]:.2f}")
print(f"Other values compressed near 0")

print("\nRobustScaler (salary column):")
print(df_robust['salary'].values)
print(f"Outlier: {df_robust['salary'].iloc[10]:.2f}")
print(f"Other values preserve their relative differences")





# Create skewed data
np.random.seed(42)
skewed_data = np.random.exponential(scale=2.0, size=1000).reshape(-1, 1)

print("Original Skewed Data Statistics:")
print(f"Mean: {skewed_data.mean():.2f}")
print(f"Median: {np.median(skewed_data):.2f}")
print(f"Skewness: {pd.Series(skewed_data.flatten()).skew():.2f}")

# Apply PowerTransformer (Yeo-Johnson)
power_transformer = PowerTransformer(method='yeo-johnson', standardize=True)
transformed_data = power_transformer.fit_transform(skewed_data)

print("\nTransformed Data Statistics:")
print(f"Mean: {transformed_data.mean():.2f}")
print(f"Median: {np.median(transformed_data):.2f}")
print(f"Skewness: {pd.Series(transformed_data.flatten()).skew():.2f}")
print("\nNotice: Skewness closer to 0 (more symmetric)")

# Visualize transformation
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

axes[0].hist(skewed_data, bins=50, edgecolor='black', alpha=0.7)
axes[0].set_title('Original Skewed Data')
axes[0].set_xlabel('Value')
axes[0].set_ylabel('Frequency')

axes[1].hist(transformed_data, bins=50, edgecolor='black', alpha=0.7, color='orange')
axes[1].set_title('After PowerTransformer')
axes[1].set_xlabel('Value')
axes[1].set_ylabel('Frequency')

plt.tight_layout()
plt.show()





# Sample data (3 samples, 4 features)
X = np.array([
    [1, 2, 3, 4],
    [5, 6, 7, 8],
    [9, 10, 11, 12]
])

print("Original Data:")
print(X)

# L2 Normalizer (default)
normalizer_l2 = Normalizer(norm='l2')
X_l2 = normalizer_l2.fit_transform(X)

print("\nL2 Normalized:")
print(X_l2.round(3))
print("\nVerify: Each row has L2 norm = 1")
print("Row norms:", np.linalg.norm(X_l2, axis=1))

# L1 Normalizer
normalizer_l1 = Normalizer(norm='l1')
X_l1 = normalizer_l1.fit_transform(X)

print("\nL1 Normalized:")
print(X_l1.round(3))
print("\nVerify: Each row sums to 1")
print("Row sums:", X_l1.sum(axis=1))





from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Load wine dataset
wine = load_wine()
X, y = wine.data, wine.target

print("Wine Dataset:")
print(f"Samples: {X.shape[0]}, Features: {X.shape[1]}")
print(f"\nFeature ranges (unscaled):")
for i, name in enumerate(wine.feature_names[:5]):
    print(f"{name:30s}: [{X[:, i].min():.2f}, {X[:, i].max():.2f}]")

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Test different scalers with SVM
scalers = {
    'No Scaling': None,
    'StandardScaler': StandardScaler(),
    'MinMaxScaler': MinMaxScaler(),
    'RobustScaler': RobustScaler(),
    'PowerTransformer': PowerTransformer()
}

print("\n" + "="*60)
print("SVM Performance with Different Scalers")
print("="*60)

for name, scaler in scalers.items():
    if scaler is None:
        X_train_scaled = X_train
        X_test_scaled = X_test
    else:
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
    
    # Train SVM
    svm = SVC(random_state=42)
    svm.fit(X_train_scaled, y_train)
    
    # Evaluate
    train_acc = svm.score(X_train_scaled, y_train)
    test_acc = svm.score(X_test_scaled, y_test)
    
    print(f"\n{name:20s}: Train={train_acc:.4f}, Test={test_acc:.4f}")





# Original data
original = np.array([[25, 50000], [30, 60000]])
print("Original:")
print(original)

# Scale
scaler = StandardScaler()
scaled = scaler.fit_transform(original)
print("\nScaled:")
print(scaled)

# Inverse transform
back_to_original = scaler.inverse_transform(scaled)
print("\nInverse Transform:")
print(back_to_original)
print("\nAre they equal?", np.allclose(original, back_to_original))



