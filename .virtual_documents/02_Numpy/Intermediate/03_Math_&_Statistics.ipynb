


import numpy as np

arr = np.array([1, 2, 3, 4, 5])

# Basic stats
print("Sum:", arr.sum())        # 15
print("Mean:", arr.mean())      # 3.0
print("Std dev:", arr.std())    # 1.414...
print("Variance:", arr.var())   # 2.0
print("Min:", arr.min())        # 1
print("Max:", arr.max())        # 5






#### **Cell 4: Code - Axis-Based Operations**

matrix = np.array([[1, 2], 
                   [3, 4],
                   [5, 6]])

# Column-wise operations
print("Column sums:", matrix.sum(axis=0))     # [9,12]
print("Column means:", matrix.mean(axis=0))   # [3,4]

# Row-wise operations
print("\nRow maxes:", matrix.max(axis=1))      # [2,4,6]
print("Row std dev:", matrix.std(axis=1))     # [0.5, 0.5, 0.5]

# Global operation
print("\nGlobal mean:", matrix.mean())         # 3.5





arr = np.array([3, 1, 4, 2, 5])

print("Min index:", arr.argmin())  # 1 (value=1 at index1)
print("Max index:", arr.argmax())  # 4 (value=5 at index4)

# 2D with axis
matrix = np.array([[1, 9], 
                   [5, 3],
                   [7, 2]])

print("\nColumn min indices:", matrix.argmin(axis=0))  # [0,2]
print("Row max indices:", matrix.argmax(axis=1))      # [1,0,0]






#### **Cell 8: Code - NaN Safe Operations**

arr = np.array([1, 2, np.nan, 4])

print("Standard mean:", arr.mean())          # nan
print("NaN-safe mean:", np.nanmean(arr))     # 2.333...

# Full set of nan variants
print("NaN-safe sum:", np.nansum(arr))       # 7.0
print("NaN-safe max:", np.nanmax(arr))       # 4.0
print("NaN-safe min index:", np.nanargmin(arr))  # 0 (value=1)





data = np.random.normal(0, 1, 1000)  # 1000 normal samples

# Percentiles
quartiles = np.percentile(data, [25, 50, 75])
print("25th/50th/75th percentiles:", quartiles)

# Median vs Mean
print("\nMedian:", np.median(data))
print("Mean:", np.mean(data))

# Correlation
x = np.array([1,2,3,4,5])
y = np.array([2,4,5,4,5])
corr = np.corrcoef(x, y)[0,1]
print("\nCorrelation:", corr)  # ~0.79

# Histogram
counts, bins = np.histogram(data, bins=10)
print("\nHistogram counts:", counts)





import time

size = 10_000_000
py_list = list(range(size))
np_arr = np.arange(size)

# Sum benchmark
start = time.time()
py_sum = sum(py_list)
py_time = time.time() - start

start = time.time()
np_sum = np_arr.sum()
np_time = time.time() - start

print(f"Python sum: {py_time:.5f} sec")
print(f"NumPy sum: {np_time:.5f} sec")
print(f"Speed ratio: {py_time/np_time:.1f}x")


import time

size = 10_000_000
py_list = list(range(size))
np_arr = np.arange(size)

# Sum benchmark
start = time.time()
py_sum = sum(py_list)
py_time = time.time() - start

start = time.time()
np_sum = np_arr.sum()
np_time = time.time() - start

print(f"Python sum: {py_time:.5f} sec")
print(f"NumPy sum: {np_time:.5f} sec")
print(f"Speed ratio: {py_time/np_time:.1f}x")





# Standardization (z-score normalization)
data = np.random.randint(0, 100, (100, 3))  # 100 samples, 3 features

mean = data.mean(axis=0)
std = data.std(axis=0)
scaled = (data - mean) / std

print("Original mean:", mean)
print("Scaled mean:", scaled.mean(axis=0))  # ~[0,0,0]
print("Scaled std:", scaled.std(axis=0))    # ~[1,1,1]



