


import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Display settings
pd.set_option('display.max_rows', 20)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('display.precision', 2)

print("âœ… Libraries imported")
print(f"Pandas version: {pd.__version__}")
print(f"Current date/time: {pd.Timestamp.now()}")





print("=== DATETIME BASICS ===\n")

# Example 1: Create Timestamps
print("Example 1: Creating Timestamps\n")
ts1 = pd.Timestamp('2024-01-15')
ts2 = pd.Timestamp(2024, 1, 15, 14, 30)
ts3 = pd.Timestamp.now()

print(f"From string: {ts1}")
print(f"From components: {ts2}")
print(f"Current time: {ts3}")
print()

# Example 2: Parse different formats
print("Example 2: Parse various date formats\n")
dates = [
    '2024-01-15',           # ISO
    '15/01/2024',           # DD/MM/YYYY
    'Jan 15, 2024',         # Text
    '2024-01-15 14:30:00'   # With time
]

for date_str in dates:
    parsed = pd.to_datetime(date_str)
    print(f"{date_str:25} â†’ {parsed}")
print()

# Example 3: Custom format parsing
print("Example 3: Parse custom format\n")
custom_date = '15-Jan-2024'
parsed = pd.to_datetime(custom_date, format='%d-%b-%Y')
print(f"Custom: {custom_date} â†’ {parsed}")
print()

# Example 4: Extract components
print("Example 4: Extract date components\n")
ts = pd.Timestamp('2024-01-15 14:30:45')
print(f"Full timestamp: {ts}")
print(f"Year: {ts.year}")
print(f"Month: {ts.month}")
print(f"Day: {ts.day}")
print(f"Hour: {ts.hour}")
print(f"Minute: {ts.minute}")
print(f"Day of week: {ts.day_name()}")
print(f"Quarter: {ts.quarter}")
print()

# Example 5: Convert DataFrame column
print("Example 5: Convert DataFrame column to datetime\n")
df = pd.DataFrame({
    'date_str': ['2024-01-01', '2024-01-02', '2024-01-03'],
    'value': [100, 110, 105]
})
print("Before conversion:")
print(df.dtypes)

df['date'] = pd.to_datetime(df['date_str'])
print("\nAfter conversion:")
print(df.dtypes)
print("\n", df)
print()

# Example 6: Handle errors
print("Example 6: Handle parsing errors\n")
mixed_dates = ['2024-01-01', 'invalid', '2024-01-03']

# errors='coerce' converts invalid to NaT (Not a Time)
parsed_dates = pd.to_datetime(mixed_dates, errors='coerce')
print("With errors='coerce':")
print(parsed_dates)
print("\nInvalid dates become NaT (Not a Time)")





print("=== DATETIMEINDEX EXAMPLES ===\n")

# Create sample time series data
np.random.seed(42)
dates = pd.date_range('2024-01-01', periods=90, freq='D')
ts_data = pd.DataFrame({
    'sales': np.random.randint(100, 200, 90) + np.random.randn(90) * 10,
    'customers': np.random.randint(50, 100, 90),
    'temperature': 20 + np.random.randn(90) * 5
}, index=dates)

# Example 1: Basic DatetimeIndex
print("Example 1: Time series with DatetimeIndex\n")
print(ts_data.head(10))
print(f"\nIndex type: {type(ts_data.index)}")
print(f"Frequency: {ts_data.index.freq}")
print()

# Example 2: Partial string indexing
print("="*70)
print("Example 2: Partial string indexing (most powerful feature!)\n")

print("All data from January 2024:")
print(ts_data['2024-01'].head())

print("\nAll data from February:")
print(ts_data['2024-02'].head())
print()

# Example 3: Date range slicing
print("="*70)
print("Example 3: Date range slicing\n")
jan_to_feb = ts_data['2024-01-15':'2024-02-15']
print(f"Data from Jan 15 to Feb 15 ({len(jan_to_feb)} days):")
print(jan_to_feb.head())
print()

# Example 4: Extract specific date
print("="*70)
print("Example 4: Extract specific date\n")
single_day = ts_data['2024-01-15']
print("Data for January 15, 2024:")
print(single_day)
print()

# Example 5: DatetimeIndex properties
print("="*70)
print("Example 5: Extract date components\n")
ts_data['year'] = ts_data.index.year
ts_data['month'] = ts_data.index.month
ts_data['day'] = ts_data.index.day
ts_data['day_name'] = ts_data.index.day_name()
ts_data['is_weekend'] = ts_data.index.dayofweek >= 5

print(ts_data[['sales', 'month', 'day', 'day_name', 'is_weekend']].head(10))
print()

# Example 6: Filter by day of week
print("="*70)
print("Example 6: Filter weekends vs weekdays\n")
weekends = ts_data[ts_data['is_weekend']]
weekdays = ts_data[~ts_data['is_weekend']]

print(f"Average sales on weekends: {weekends['sales'].mean():.2f}")
print(f"Average sales on weekdays: {weekdays['sales'].mean():.2f}")
print()

# Example 7: Filter by month
print("="*70)
print("Example 7: Compare months\n")
monthly_avg = ts_data.groupby(ts_data.index.month)['sales'].mean()
print("Average sales by month:")
print(monthly_avg)

# Clean up temporary columns
ts_data = ts_data[['sales', 'customers', 'temperature']]





print("=== DATE RANGE EXAMPLES ===\n")

# Example 1: Daily dates
print("Example 1: Daily dates for January 2024\n")
daily = pd.date_range('2024-01-01', '2024-01-10', freq='D')
print(daily)
print()

# Example 2: Business days (skip weekends)
print("Example 2: Business days (Mon-Fri only)\n")
business_days = pd.date_range('2024-01-01', periods=10, freq='B')
print(business_days)
print("\nNotice: Skips weekends!")
print()

# Example 3: Weekly dates
print("="*70)
print("Example 3: Weekly dates (every Monday)\n")
weekly = pd.date_range('2024-01-01', periods=8, freq='W-MON')
print(weekly)
print()

# Example 4: Monthly dates
print("="*70)
print("Example 4: Month start vs month end\n")
month_start = pd.date_range('2024-01-01', periods=6, freq='MS')
month_end = pd.date_range('2024-01-01', periods=6, freq='M')

print("Month Start:")
print(month_start)
print("\nMonth End:")
print(month_end)
print()

# Example 5: Quarterly dates
print("="*70)
print("Example 5: Quarterly dates (quarter start)\n")
quarterly = pd.date_range('2024-01-01', periods=8, freq='QS')
print(quarterly)
print()

# Example 6: Custom frequency (every 2 days)
print("="*70)
print("Example 6: Every 2 days\n")
every_2_days = pd.date_range('2024-01-01', periods=10, freq='2D')
print(every_2_days)
print()

# Example 7: Hourly timestamps
print("="*70)
print("Example 7: Hourly timestamps for a day\n")
hourly = pd.date_range('2024-01-01', periods=24, freq='H')
print(hourly[:12])  # Show first 12 hours
print()

# Example 8: Create time series with date range
print("="*70)
print("Example 8: Create time series DataFrame\n")
dates = pd.date_range('2024-01-01', periods=5, freq='D')
df = pd.DataFrame({
    'sales': [100, 110, 105, 120, 115],
    'costs': [60, 65, 62, 70, 68]
}, index=dates)
print(df)
print()

# Example 9: Business month end
print("="*70)
print("Example 9: Business month end (last business day of month)\n")
bm = pd.date_range('2024-01-01', periods=6, freq='BM')
print(bm)
print("\nUseful for monthly reports!")





print("=== RESAMPLING EXAMPLES ===\n")

# Create high-frequency data
np.random.seed(42)
dates = pd.date_range('2024-01-01', periods=90, freq='D')
daily_data = pd.DataFrame({
    'sales': np.random.randint(100, 200, 90) + np.random.randn(90) * 10,
    'orders': np.random.randint(20, 50, 90)
}, index=dates)

# Example 1: Daily to Weekly (downsample)
print("Example 1: Daily â†’ Weekly (sum)\n")
print("Original daily data (first 14 days):")
print(daily_data.head(14))

weekly = daily_data.resample('W').sum()
print("\nWeekly totals:")
print(weekly.head())
print()

# Example 2: Daily to Monthly (downsample)
print("="*70)
print("Example 2: Daily â†’ Monthly\n")
monthly = daily_data.resample('M').agg({
    'sales': 'sum',       # Total sales
    'orders': 'mean'      # Average orders per day
})
print("Monthly summary:")
print(monthly)
print()

# Example 3: Multiple aggregations
print("="*70)
print("Example 3: Multiple aggregations per column\n")
monthly_detailed = daily_data.resample('M').agg({
    'sales': ['sum', 'mean', 'min', 'max'],
    'orders': ['sum', 'mean']
})
print(monthly_detailed.round(2))
print()

# Example 4: Upsampling with forward fill
print("="*70)
print("Example 4: Upsampling - Monthly â†’ Daily\n")
monthly_simple = pd.DataFrame({
    'target': [1000, 1100, 1200]
}, index=pd.date_range('2024-01-01', periods=3, freq='MS'))

print("Monthly data:")
print(monthly_simple)

daily_upsampled = monthly_simple.resample('D').ffill()
print("\nUpsampled to daily (forward fill):")
print(daily_upsampled.head(10))
print(f"\nShape changed from {monthly_simple.shape} to {daily_upsampled.shape}")
print()

# Example 5: Interpolation
print("="*70)
print("Example 5: Upsampling with interpolation\n")
daily_interpolated = monthly_simple.resample('D').interpolate()
print("Interpolated values (smooth transition):")
print(daily_interpolated.head(10))
print()

# Example 6: Business days
print("="*70)
print("Example 6: Resample to business days\n")
business_monthly = daily_data.resample('BM').sum()  # Business month end
print("Business month end totals:")
print(business_monthly)
print()

# Example 7: Quarter aggregation
print("="*70)
print("Example 7: Quarterly summary\n")
quarterly = daily_data.resample('Q').agg({
    'sales': ['sum', 'mean'],
    'orders': 'sum'
})
print(quarterly.round(2))
print()

# Example 8: OHLC (Open-High-Low-Close)
print("="*70)
print("Example 8: OHLC summary (stock-like)\n")
weekly_ohlc = daily_data['sales'].resample('W').agg([
    ('open', 'first'),
    ('high', 'max'),
    ('low', 'min'),
    ('close', 'last')
])
print(weekly_ohlc.head().round(2))
print("\nUseful for financial time series!")





print("=== ROLLING WINDOW EXAMPLES ===\n")

# Create sample data with trend and noise
np.random.seed(42)
dates = pd.date_range('2024-01-01', periods=60, freq='D')
trend = np.linspace(100, 150, 60)
noise = np.random.randn(60) * 10
price = trend + noise

df = pd.DataFrame({'price': price}, index=dates)

# Example 1: Simple moving average
print("Example 1: 7-day moving average\n")
df['MA_7'] = df['price'].rolling(7).mean()
print(df[['price', 'MA_7']].head(10))
print("\nNotice: First 6 values are NaN (not enough data)")
print()

# Example 2: Multiple moving averages
print("="*70)
print("Example 2: Multiple moving averages (short and long term)\n")
df['MA_7'] = df['price'].rolling(7).mean()
df['MA_30'] = df['price'].rolling(30).mean()
print(df[['price', 'MA_7', 'MA_30']].tail(10).round(2))
print("\nMA_7 reacts faster to changes, MA_30 is smoother")
print()

# Example 3: min_periods parameter
print("="*70)
print("Example 3: Use min_periods to handle early values\n")
df['MA_7_minp'] = df['price'].rolling(7, min_periods=1).mean()
print(df[['price', 'MA_7', 'MA_7_minp']].head(10).round(2))
print("\nWith min_periods=1, no NaN at start")
print()

# Example 4: Rolling statistics
print("="*70)
print("Example 4: Multiple rolling statistics\n")
df['rolling_mean'] = df['price'].rolling(7).mean()
df['rolling_std'] = df['price'].rolling(7).std()
df['rolling_min'] = df['price'].rolling(7).min()
df['rolling_max'] = df['price'].rolling(7).max()

print(df[['price', 'rolling_mean', 'rolling_std', 'rolling_min', 'rolling_max']].tail(10).round(2))
print()

# Example 5: Bollinger Bands
print("="*70)
print("Example 5: Bollinger Bands (trading indicator)\n")
window = 20
df['MA'] = df['price'].rolling(window).mean()
df['STD'] = df['price'].rolling(window).std()
df['Upper_Band'] = df['MA'] + 2 * df['STD']
df['Lower_Band'] = df['MA'] - 2 * df['STD']

print(df[['price', 'MA', 'Upper_Band', 'Lower_Band']].tail(10).round(2))
print("\nPrice between bands = normal, outside = potential signal")
print()

# Example 6: Exponential moving average
print("="*70)
print("Example 6: Exponential moving average (EMA)\n")
df['EMA_7'] = df['price'].ewm(span=7).mean()
df['MA_7_regular'] = df['price'].rolling(7).mean()
print(df[['price', 'MA_7_regular', 'EMA_7']].tail(10).round(2))
print("\nEMA gives more weight to recent values")
print()

# Example 7: Centered window
print("="*70)
print("Example 7: Centered window (useful for retrospective analysis)\n")
df['MA_centered'] = df['price'].rolling(7, center=True).mean()
df['MA_normal'] = df['price'].rolling(7).mean()
print(df[['price', 'MA_normal', 'MA_centered']].iloc[3:10].round(2))
print()

# Example 8: Custom rolling function
print("="*70)
print("Example 8: Custom rolling function (price range)\n")
def price_range(x):
    return x.max() - x.min()

df['7day_range'] = df['price'].rolling(7).apply(price_range)
print(df[['price', '7day_range']].tail(10).round(2))
print("\nShows volatility: higher range = more volatile")

# Clean up for next examples
df = df[['price']]





print("=== TIME SHIFT EXAMPLES ===\n")

# Create sample data
dates = pd.date_range('2024-01-01', periods=10, freq='D')
df = pd.DataFrame({
    'price': [100, 105, 103, 110, 108, 115, 112, 120, 118, 125]
}, index=dates)

# Example 1: Basic shift (lag)
print("Example 1: Lag by 1 period (previous value)\n")
df['prev_price'] = df['price'].shift(1)
print(df[['price', 'prev_price']])
print()

# Example 2: Calculate daily change
print("="*70)
print("Example 2: Calculate daily change\n")
df['change'] = df['price'] - df['price'].shift(1)
print(df[['price', 'prev_price', 'change']])
print()

# Example 3: Percentage change
print("="*70)
print("Example 3: Percentage change (daily return)\n")
df['pct_change'] = df['price'].pct_change() * 100
print(df[['price', 'change', 'pct_change']].round(2))
print()

# Example 4: Multiple lags
print("="*70)
print("Example 4: Multiple lag periods\n")
df['lag_1'] = df['price'].shift(1)
df['lag_2'] = df['price'].shift(2)
df['lag_3'] = df['price'].shift(3)
print(df[['price', 'lag_1', 'lag_2', 'lag_3']])
print()

# Example 5: Lead (negative shift)
print("="*70)
print("Example 5: Lead - next day's value\n")
df['next_day'] = df['price'].shift(-1)
df['future_change'] = df['next_day'] - df['price']
print(df[['price', 'next_day', 'future_change']])
print()

# Example 6: diff() method
print("="*70)
print("Example 6: diff() - shortcut for change calculation\n")
df['diff_1'] = df['price'].diff()     # Same as price - price.shift(1)
df['diff_2'] = df['price'].diff(2)    # 2-period difference
print(df[['price', 'diff_1', 'diff_2']])
print()

# Example 7: Cumulative calculations
print("="*70)
print("Example 7: Cumulative sum of changes\n")
df['daily_change'] = df['price'].diff()
df['cumulative_gain'] = df['daily_change'].cumsum()
print(df[['price', 'daily_change', 'cumulative_gain']].round(2))
print()

# Example 8: Compare with last week
print("="*70)
print("Example 8: Week-over-week comparison\n")

# Create weekly data
weekly_dates = pd.date_range('2024-01-01', periods=8, freq='W')
weekly_df = pd.DataFrame({
    'sales': [1000, 1100, 1050, 1200, 1150, 1300, 1250, 1400]
}, index=weekly_dates)

weekly_df['last_week'] = weekly_df['sales'].shift(1)
weekly_df['wow_change'] = weekly_df['sales'] - weekly_df['last_week']
weekly_df['wow_pct'] = weekly_df['sales'].pct_change() * 100

print(weekly_df.round(2))
print()

# Example 9: ML feature creation
print("="*70)
print("Example 9: Create lagged features for ML\n")
features = pd.DataFrame({
    'value': [10, 15, 12, 18, 20, 17, 22, 25]
})

# Create multiple lag features
for i in range(1, 4):
    features[f'lag_{i}'] = features['value'].shift(i)

print(features)
print("\nThese lagged features can be used as ML inputs")

# Clean up
df = df[['price']]





print("=== TIME ZONE EXAMPLES ===\n")

# Example 1: Create timezone-naive vs aware
print("Example 1: Timezone-naive vs timezone-aware\n")
naive = pd.Timestamp('2024-01-15 14:30:00')
aware = pd.Timestamp('2024-01-15 14:30:00', tz='US/Eastern')

print(f"Naive: {naive}")
print(f"  Timezone: {naive.tz}")
print(f"\nAware: {aware}")
print(f"  Timezone: {aware.tz}")
print()

# Example 2: Localize (add timezone)
print("="*70)
print("Example 2: Add timezone to naive timestamps\n")
dates = pd.date_range('2024-01-01', periods=5, freq='H')
df = pd.DataFrame({'value': range(5)}, index=dates)

print("Original (naive):")
print(df.index)

# Localize to US Eastern
df_eastern = df.copy()
df_eastern.index = df_eastern.index.tz_localize('US/Eastern')
print("\nLocalized to US/Eastern:")
print(df_eastern.index)
print()

# Example 3: Convert between timezones
print("="*70)
print("Example 3: Convert between timezones\n")

# Start with US Eastern
eastern_time = pd.Timestamp('2024-01-15 14:30:00', tz='US/Eastern')
print(f"US/Eastern:     {eastern_time}")

# Convert to other timezones
utc_time = eastern_time.tz_convert('UTC')
london_time = eastern_time.tz_convert('Europe/London')
tokyo_time = eastern_time.tz_convert('Asia/Tokyo')
india_time = eastern_time.tz_convert('Asia/Kolkata')

print(f"UTC:            {utc_time}")
print(f"London:         {london_time}")
print(f"Tokyo:          {tokyo_time}")
print(f"India:          {india_time}")
print()

# Example 4: DataFrame timezone conversion
print("="*70)
print("Example 4: Convert DataFrame timezone\n")

# Create data in UTC
utc_dates = pd.date_range('2024-01-01', periods=5, freq='H', tz='UTC')
df_utc = pd.DataFrame({'value': [10, 15, 12, 18, 20]}, index=utc_dates)

print("Original (UTC):")
print(df_utc)

# Convert to Eastern
df_eastern = df_utc.tz_convert('US/Eastern')
print("\nConverted to US/Eastern:")
print(df_eastern)
print()

# Example 5: Remove timezone
print("="*70)
print("Example 5: Remove timezone (make naive)\n")
print("Timezone-aware:")
print(df_eastern.index)

df_naive = df_eastern.tz_localize(None)
print("\nMade naive (timezone removed):")
print(df_naive.index)
print()

# Example 6: Working with UTC (best practice)
print("="*70)
print("Example 6: Store in UTC, display in local\n")

# Parse dates from different sources (all to UTC)
ny_time = pd.Timestamp('2024-01-15 09:00:00', tz='US/Eastern')
london_time = pd.Timestamp('2024-01-15 14:00:00', tz='Europe/London')

# Convert both to UTC for storage
ny_utc = ny_time.tz_convert('UTC')
london_utc = london_time.tz_convert('UTC')

print("Stored in UTC:")
print(f"  NY event:     {ny_utc}")
print(f"  London event: {london_utc}")

# Convert back for display
print("\nDisplay in Tokyo time:")
print(f"  NY event:     {ny_utc.tz_convert('Asia/Tokyo')}")
print(f"  London event: {london_utc.tz_convert('Asia/Tokyo')}")
print()

print("ðŸ’¡ Best Practice: Store in UTC, convert for display")





print("=== REAL-WORLD TIME SERIES ANALYSIS ===\n")

# Scenario 1: E-commerce Sales Analysis
print("Scenario 1: E-commerce Sales Analysis\n")

# Create realistic sales data
np.random.seed(42)
dates = pd.date_range('2023-01-01', '2024-03-31', freq='D')
n_days = len(dates)

# Base sales with weekly pattern and trend
trend = np.linspace(1000, 1500, n_days)
weekly_pattern = 200 * np.sin(np.arange(n_days) * 2 * np.pi / 7)
noise = np.random.randn(n_days) * 50
sales = trend + weekly_pattern + noise

df = pd.DataFrame({'sales': sales}, index=dates)

# Analysis
print("Daily sales data (sample):")
print(df.head())

# Monthly summary
monthly = df.resample('M').agg({
    'sales': ['sum', 'mean', 'std']
})
monthly.columns = ['total', 'avg_daily', 'std']
print("\nMonthly summary:")
print(monthly.tail(6).round(0))

# Moving averages
df['MA_7'] = df['sales'].rolling(7).mean()
df['MA_30'] = df['sales'].rolling(30).mean()

print("\nWith moving averages:")
print(df[['sales', 'MA_7', 'MA_30']].tail().round(0))

# Year-over-year growth
df['yoy_change'] = df['sales'].pct_change(365) * 100
print(f"\nCurrent YoY growth: {df['yoy_change'].iloc[-1]:.1f}%")
print()

# Scenario 2: Temperature Data Analysis
print("="*70)
print("Scenario 2: Temperature Monitoring\n")

# Create hourly temperature data
hourly_dates = pd.date_range('2024-01-01', periods=24*7, freq='H')
temp_base = 20
daily_cycle = 5 * np.sin(np.arange(len(hourly_dates)) * 2 * np.pi / 24)
temp = temp_base + daily_cycle + np.random.randn(len(hourly_dates))

temp_df = pd.DataFrame({'temperature': temp}, index=hourly_dates)

print("Hourly temperature (first day):")
print(temp_df.head(24).round(1))

# Daily statistics
daily_temp = temp_df.resample('D').agg([
    ('min', 'min'),
    ('max', 'max'),
    ('avg', 'mean')
])
daily_temp.columns = daily_temp.columns.droplevel(0)

print("\nDaily temperature summary:")
print(daily_temp.round(1))
print()

# Scenario 3: Stock Price Technical Analysis
print("="*70)
print("Scenario 3: Stock Price Technical Analysis\n")

# Simulate stock prices
stock_dates = pd.date_range('2024-01-01', periods=100, freq='B')
returns = np.random.randn(100) * 0.02
price = 100 * np.exp(np.cumsum(returns))

stock_df = pd.DataFrame({'close': price}, index=stock_dates)

# Technical indicators
stock_df['SMA_20'] = stock_df['close'].rolling(20).mean()
stock_df['SMA_50'] = stock_df['close'].rolling(50).mean()
stock_df['returns'] = stock_df['close'].pct_change()
stock_df['volatility'] = stock_df['returns'].rolling(20).std() * np.sqrt(252)

# Bollinger Bands
stock_df['BB_middle'] = stock_df['close'].rolling(20).mean()
stock_df['BB_std'] = stock_df['close'].rolling(20).std()
stock_df['BB_upper'] = stock_df['BB_middle'] + 2 * stock_df['BB_std']
stock_df['BB_lower'] = stock_df['BB_middle'] - 2 * stock_df['BB_std']

print("Stock analysis (last 10 days):")
print(stock_df[['close', 'SMA_20', 'SMA_50', 'volatility']].tail(10).round(2))

# Trading signal (simple)
stock_df['signal'] = np.where(stock_df['SMA_20'] > stock_df['SMA_50'], 'BUY', 'SELL')
print(f"\nCurrent signal: {stock_df['signal'].iloc[-1]}")
print()

# Scenario 4: Web Traffic Analysis
print("="*70)
print("Scenario 4: Website Traffic Patterns\n")

# Daily traffic
traffic_dates = pd.date_range('2024-01-01', periods=30, freq='D')
base_traffic = 10000
weekend_boost = [1.3 if d in [5, 6] else 1.0 for d in traffic_dates.dayofweek]
traffic = base_traffic * np.array(weekend_boost) + np.random.randn(30) * 500

traffic_df = pd.DataFrame({'visits': traffic}, index=traffic_dates)
traffic_df['dow'] = traffic_df.index.day_name()
traffic_df['is_weekend'] = traffic_df.index.dayofweek >= 5

print("Traffic by day of week:")
dow_avg = traffic_df.groupby('dow')['visits'].mean().round(0)
# Sort by day of week
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
dow_avg = dow_avg.reindex(day_order)
print(dow_avg)

print("\nWeekend vs Weekday:")
print(traffic_df.groupby('is_weekend')['visits'].mean().round(0))












