


import pandas as pd
import numpy as np
import sys

# Display settings
pd.set_option('display.max_rows', 20)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('display.precision', 2)

print("âœ… Libraries imported")
print(f"Pandas version: {pd.__version__}")





print("=== CREATING CATEGORICAL DATA ===\n")

# Example 1: Convert to categorical
print("Example 1: Convert string column to categorical\n")
colors = pd.Series(['red', 'blue', 'red', 'green', 'blue', 'red'])
print("Original (object):")
print(f"  Type: {colors.dtype}")
print(f"  Values: {colors.tolist()}")

colors_cat = colors.astype('category')
print("\nCategorical:")
print(f"  Type: {colors_cat.dtype}")
print(f"  Categories: {colors_cat.cat.categories.tolist()}")
print(f"  Codes: {colors_cat.cat.codes.tolist()}")
print()

# Example 2: Create with pd.Categorical
print("="*70)
print("Example 2: Using pd.Categorical()\n")
sizes = pd.Categorical(['S', 'M', 'L', 'S', 'XL', 'M'])
print(f"Categories: {sizes.categories.tolist()}")
print(f"Codes: {sizes.codes.tolist()}")
print(f"Ordered: {sizes.ordered}")
print()

# Example 3: Ordered categorical
print("="*70)
print("Example 3: Ordered categorical (with natural order)\n")
education = pd.Categorical(
    ['Bachelor', 'PhD', 'High School', 'Master', 'Bachelor'],
    categories=['High School', 'Bachelor', 'Master', 'PhD'],
    ordered=True
)
print(f"Categories: {education.categories.tolist()}")
print(f"Ordered: {education.ordered}")
print(f"Values: {list(education)}")
print()

# Example 4: Comparison with ordered categorical
print("="*70)
print("Example 4: Comparisons work with ordered categoricals\n")
edu_series = pd.Series(education)
print("Can compare: Bachelor vs Master")
print(f"  Bachelor < Master: {pd.Categorical(['Bachelor'], categories=education.categories, ordered=True)[0] < pd.Categorical(['Master'], categories=education.categories, ordered=True)[0]}")
print("\nFilter: Education >= Bachelor")
print(edu_series[edu_series >= 'Bachelor'])
print()

# Example 5: Specify all categories (including unused)
print("="*70)
print("Example 5: Specify categories (including unused ones)\n")
status = pd.Categorical(
    ['pending', 'approved', 'pending'],
    categories=['pending', 'approved', 'rejected', 'cancelled']  # 4 possible values
)
print(f"Data: {list(status)}")
print(f"All categories: {status.categories.tolist()}")
print(f"Value counts:")
print(pd.Series(status).value_counts())
print("\n'rejected' and 'cancelled' exist as categories but have 0 count")
print()

# Example 6: DataFrame with categorical
print("="*70)
print("Example 6: Categorical in DataFrame\n")
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],
    'grade': ['A', 'B', 'A', 'C'],
    'size': ['M', 'L', 'M', 'S']
})
print("Original dtypes:")
print(df.dtypes)

# Convert to categorical
df['grade'] = df['grade'].astype('category')
df['size'] = pd.Categorical(df['size'], categories=['S', 'M', 'L', 'XL'], ordered=True)

print("\nAfter conversion:")
print(df.dtypes)
print("\nDataFrame:")
print(df)





print("=== MEMORY BENEFITS ===\n")

# Example 1: Memory comparison
print("Example 1: Memory usage comparison\n")

# Create large dataset with repeated values
n = 100_000
cities = ['New York', 'London', 'Tokyo', 'Paris', 'Mumbai'] * (n // 5)

# As object (string)
df_object = pd.DataFrame({'city': cities})
memory_object = df_object.memory_usage(deep=True).sum() / 1024**2  # MB

# As categorical
df_cat = pd.DataFrame({'city': pd.Categorical(cities)})
memory_cat = df_cat.memory_usage(deep=True).sum() / 1024**2  # MB

print(f"Dataset: {n:,} rows, 5 unique cities")
print(f"\nObject (string):  {memory_object:.2f} MB")
print(f"Categorical:      {memory_cat:.2f} MB")
print(f"\nSavings: {(1 - memory_cat/memory_object) * 100:.1f}%")
print(f"Reduction: {memory_object/memory_cat:.1f}x smaller")
print()

# Example 2: Check memory of columns
print("="*70)
print("Example 2: Compare multiple columns\n")

df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'] * 1000,
    'status': ['active', 'inactive', 'pending'] * 1000,
    'level': ['beginner', 'intermediate', 'advanced'] * 1000
})

print("Original (all object):")
print(df.dtypes)
print(f"Total memory: {df.memory_usage(deep=True).sum() / 1024:.2f} KB")

# Convert to categorical
df_cat = df.copy()
for col in df_cat.columns:
    df_cat[col] = df_cat[col].astype('category')

print("\nConverted to categorical:")
print(df_cat.dtypes)
print(f"Total memory: {df_cat.memory_usage(deep=True).sum() / 1024:.2f} KB")

savings = (1 - df_cat.memory_usage(deep=True).sum() / df.memory_usage(deep=True).sum()) * 100
print(f"\nMemory savings: {savings:.1f}%")
print()

# Example 3: When NOT to use categorical
print("="*70)
print("Example 3: High cardinality - NOT good for categorical\n")

# Create data with many unique values
unique_ids = [f'ID_{i:06d}' for i in range(10000)]

df_unique_obj = pd.DataFrame({'id': unique_ids})
df_unique_cat = pd.DataFrame({'id': pd.Categorical(unique_ids)})

mem_obj = df_unique_obj.memory_usage(deep=True).sum() / 1024
mem_cat = df_unique_cat.memory_usage(deep=True).sum() / 1024

print(f"10,000 unique IDs:")
print(f"  Object:      {mem_obj:.2f} KB")
print(f"  Categorical: {mem_cat:.2f} KB")
print(f"\nâŒ Categorical is {'worse' if mem_cat > mem_obj else 'better'}!")
print("\nðŸ’¡ Don't use categorical for high cardinality data")
print()

# Example 4: Unique ratio test
print("="*70)
print("Example 4: Unique ratio test (should it be categorical?)\n")

test_data = {
    'city': ['NYC', 'LA', 'NYC'] * 1000,           # Low cardinality
    'zip_code': list(range(3000)),                 # High cardinality
    'status': ['active', 'inactive'] * 1500        # Very low
}

df_test = pd.DataFrame(test_data)

for col in df_test.columns:
    unique_ratio = df_test[col].nunique() / len(df_test)
    recommendation = 'âœ… Good for categorical' if unique_ratio < 0.5 else 'âŒ Not recommended'
    print(f"{col:12} | Unique: {df_test[col].nunique():5} | Ratio: {unique_ratio:.2%} | {recommendation}")





print("=== CATEGORICAL OPERATIONS ===\n")

# Create sample data
sizes = pd.Series(['S', 'M', 'L', 'S', 'M', 'S', 'L', 'M'], dtype='category')

# Example 1: Access properties
print("Example 1: Categorical properties\n")
print(f"Categories: {sizes.cat.categories.tolist()}")
print(f"Codes: {sizes.cat.codes.tolist()}")
print(f"Ordered: {sizes.cat.ordered}")
print(f"Number of categories: {len(sizes.cat.categories)}")
print()

# Example 2: Add categories
print("="*70)
print("Example 2: Add new categories\n")
print(f"Original categories: {sizes.cat.categories.tolist()}")
sizes = sizes.cat.add_categories(['XL', 'XXL'])
print(f"After adding: {sizes.cat.categories.tolist()}")
print()

# Example 3: Remove unused categories
print("="*70)
print("Example 3: Remove unused categories\n")
print(f"Before: {sizes.cat.categories.tolist()}")
print(f"Value counts:")
print(sizes.value_counts())
sizes = sizes.cat.remove_unused_categories()
print(f"\nAfter removing unused: {sizes.cat.categories.tolist()}")
print("\nXL and XXL removed (not used in data)")
print()

# Example 4: Rename categories
print("="*70)
print("Example 4: Rename categories\n")
status = pd.Series(['pending', 'approved', 'pending', 'rejected'], dtype='category')
print(f"Original: {status.tolist()}")

status = status.cat.rename_categories({
    'pending': 'In Progress',
    'approved': 'Completed',
    'rejected': 'Cancelled'
})
print(f"Renamed: {status.tolist()}")
print()

# Example 5: Reorder categories
print("="*70)
print("Example 5: Reorder and set as ordered\n")
education = pd.Series(['Bachelor', 'PhD', 'High School', 'Master'], dtype='category')
print(f"Original order: {education.cat.categories.tolist()}")
print(f"Ordered: {education.cat.ordered}")

# Reorder in natural order
education = education.cat.reorder_categories(
    ['High School', 'Bachelor', 'Master', 'PhD']
)
education = education.cat.as_ordered()

print(f"\nNew order: {education.cat.categories.tolist()}")
print(f"Ordered: {education.cat.ordered}")
print()

# Example 6: Sorting with ordered categorical
print("="*70)
print("Example 6: Sorting (ordered vs unordered)\n")

# Unordered - sorts alphabetically
months_unordered = pd.Series(['Mar', 'Jan', 'Feb', 'Dec', 'Apr'], dtype='category')
print("Unordered (alphabetical sort):")
print(months_unordered.sort_values().tolist())

# Ordered - sorts by category order
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
months_ordered = pd.Categorical(
    ['Mar', 'Jan', 'Feb', 'Dec', 'Apr'],
    categories=month_order,
    ordered=True
)
print("\nOrdered (chronological sort):")
print(pd.Series(months_ordered).sort_values().tolist())
print()

# Example 7: Value counts maintains category order
print("="*70)
print("Example 7: value_counts with ordered categories\n")

sizes_ordered = pd.Categorical(
    ['M', 'S', 'L', 'M', 'S', 'M', 'L', 'S'],
    categories=['S', 'M', 'L', 'XL'],
    ordered=True
)
print("Value counts (sorted by size order, not frequency):")
print(pd.Series(sizes_ordered).value_counts(sort=False))
print("\nNote: XL shown even though count is 0")
print()

# Example 8: GroupBy with categorical
print("="*70)
print("Example 8: GroupBy with categorical (faster!)\n")

df = pd.DataFrame({
    'category': pd.Categorical(['A', 'B', 'A', 'C', 'B', 'A']),
    'value': [10, 20, 15, 30, 25, 12]
})

grouped = df.groupby('category')['value'].mean()
print(grouped)
print("\nâœ… GroupBy operations are faster with categorical!")





print("=== BINNING CONTINUOUS DATA ===\n")

# Example 1: Basic cut with auto bins
print("Example 1: pd.cut() with automatic bins\n")
ages = [22, 35, 45, 28, 67, 19, 52, 31, 25]
age_bins = pd.cut(ages, bins=3)

print(f"Original ages: {ages}")
print(f"\nBinned (3 equal-width bins):")
print(age_bins)
print(f"\nCategories: {age_bins.categories.tolist()}")
print()

# Example 2: Cut with custom bins and labels
print("="*70)
print("Example 2: Custom bins and labels\n")
age_groups = pd.cut(
    ages,
    bins=[0, 18, 35, 60, 100],
    labels=['Child', 'Young Adult', 'Adult', 'Senior']
)

df = pd.DataFrame({
    'age': ages,
    'age_group': age_groups
})
print(df)
print(f"\nValue counts:")
print(df['age_group'].value_counts())
print()

# Example 3: qcut for quantiles
print("="*70)
print("Example 3: pd.qcut() - equal-sized groups\n")
sales = [100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650]
quartiles = pd.qcut(sales, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])

df_sales = pd.DataFrame({
    'sales': sales,
    'quartile': quartiles
})
print(df_sales)
print(f"\nEach quartile has {df_sales['quartile'].value_counts().values[0]} values")
print()

# Example 4: cut() vs qcut() comparison
print("="*70)
print("Example 4: cut() vs qcut() comparison\n")
values = [10, 20, 25, 30, 35, 50, 60, 80, 90, 100]

# Equal width bins
cut_bins = pd.cut(values, bins=3, labels=['Low', 'Med', 'High'])

# Equal count bins
qcut_bins = pd.qcut(values, q=3, labels=['Low', 'Med', 'High'])

comparison = pd.DataFrame({
    'value': values,
    'cut (width)': cut_bins,
    'qcut (count)': qcut_bins
})
print(comparison)

print("\ncut() value counts:")
print(comparison['cut (width)'].value_counts())
print("\nqcut() value counts:")
print(comparison['qcut (count)'].value_counts())
print()

# Example 5: Income brackets
print("="*70)
print("Example 5: Real-world - Income brackets\n")
incomes = [25000, 45000, 55000, 75000, 95000, 120000, 35000, 65000]

income_brackets = pd.cut(
    incomes,
    bins=[0, 30000, 60000, 100000, np.inf],
    labels=['Low', 'Medium', 'High', 'Very High']
)

df_income = pd.DataFrame({
    'income': incomes,
    'bracket': income_brackets
})
print(df_income)
print()

# Example 6: Test score grades
print("="*70)
print("Example 6: Test scores to letter grades\n")
scores = [45, 78, 92, 67, 88, 55, 95, 72, 61, 85]

grades = pd.cut(
    scores,
    bins=[0, 60, 70, 80, 90, 100],
    labels=['F', 'D', 'C', 'B', 'A'],
    right=True
)

df_grades = pd.DataFrame({
    'score': scores,
    'grade': grades
})
print(df_grades.sort_values('score'))
print(f"\nGrade distribution:")
print(df_grades['grade'].value_counts().sort_index())
print()

# Example 7: Include lowest with right=False
print("="*70)
print("Example 7: right=True vs right=False\n")
test_values = [10, 20, 30, 40]

# right=True: (10, 20], (20, 30], (30, 40]
bins_right_true = pd.cut(test_values, bins=3, right=True)

# right=False: [10, 20), [20, 30), [30, 40)
bins_right_false = pd.cut(test_values, bins=3, right=False)

print("right=True (default):")
print(f"  10 â†’ {bins_right_true[0]}")
print(f"  20 â†’ {bins_right_true[1]}")
print("\nright=False:")
print(f"  10 â†’ {bins_right_false[0]}")
print(f"  20 â†’ {bins_right_false[1]}")





print("=== ENCODING CATEGORICAL DATA ===\n")

# Example 1: One-hot encoding with get_dummies
print("Example 1: One-hot encoding (nominal data)\n")
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],
    'color': ['Red', 'Blue', 'Green', 'Red']
})

print("Original:")
print(df)

# One-hot encode color
df_encoded = pd.get_dummies(df, columns=['color'], prefix='color')
print("\nOne-hot encoded:")
print(df_encoded)
print()

# Example 2: get_dummies on Series
print("="*70)
print("Example 2: Encode single column\n")
status = pd.Series(['active', 'inactive', 'pending', 'active', 'inactive'])
print("Original:")
print(status)

status_encoded = pd.get_dummies(status, prefix='status')
print("\nEncoded:")
print(status_encoded)
print()

# Example 3: drop_first parameter
print("="*70)
print("Example 3: drop_first=True (avoid dummy variable trap)\n")

df_test = pd.DataFrame({'category': ['A', 'B', 'C', 'A']})

print("Without drop_first:")
print(pd.get_dummies(df_test, columns=['category']))

print("\nWith drop_first=True:")
print(pd.get_dummies(df_test, columns=['category'], drop_first=True))
print("\nðŸ’¡ Use drop_first=True for linear regression to avoid multicollinearity")
print()

# Example 4: Label encoding (ordinal)
print("="*70)
print("Example 4: Label encoding for ordinal data\n")

df_ordinal = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],
    'size': ['S', 'M', 'L', 'M']
})

# Create ordered categorical
df_ordinal['size'] = pd.Categorical(
    df_ordinal['size'],
    categories=['S', 'M', 'L', 'XL'],
    ordered=True
)

# Get codes
df_ordinal['size_code'] = df_ordinal['size'].cat.codes

print(df_ordinal)
print("\nMapping: Sâ†’0, Mâ†’1, Lâ†’2, XLâ†’3")
print()

# Example 5: Multiple column encoding
print("="*70)
print("Example 5: Encode multiple columns at once\n")

df_multi = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'],
    'city': ['NYC', 'LA', 'NYC'],
    'status': ['active', 'inactive', 'active'],
    'score': [85, 90, 88]
})

print("Original:")
print(df_multi)

# Encode both city and status
df_encoded = pd.get_dummies(df_multi, columns=['city', 'status'])
print("\nEncoded:")
print(df_encoded)
print()

# Example 6: Compare nominal vs ordinal encoding
print("="*70)
print("Example 6: Nominal vs Ordinal encoding\n")

data = {
    'color': ['Red', 'Blue', 'Green', 'Red'],      # Nominal
    'education': ['High School', 'Bachelor', 'Master', 'PhD']  # Ordinal
}
df_compare = pd.DataFrame(data)

# Nominal â†’ One-hot
color_encoded = pd.get_dummies(df_compare['color'], prefix='color')

# Ordinal â†’ Label encoding
edu_cat = pd.Categorical(
    df_compare['education'],
    categories=['High School', 'Bachelor', 'Master', 'PhD'],
    ordered=True
)
edu_codes = pd.Series(edu_cat.codes, name='education_code')

result = pd.concat([df_compare, color_encoded, edu_codes], axis=1)
print(result)
print("\nâœ… Color: One-hot (no order)")
print("âœ… Education: Label encoded (preserves order)")
print()

# Example 7: Handling missing values
print("="*70)
print("Example 7: Encoding with missing values\n")

df_na = pd.DataFrame({
    'status': ['active', np.nan, 'inactive', 'active', np.nan]
})

print("Original (with NaN):")
print(df_na)

# get_dummies handles NaN automatically
encoded_na = pd.get_dummies(df_na, columns=['status'], dummy_na=True)
print("\nEncoded (dummy_na=True creates column for NaN):")
print(encoded_na)
print()

# Example 8: Convert back from codes
print("="*70)
print("Example 8: Convert codes back to categories\n")

sizes = pd.Categorical(['S', 'M', 'L'], categories=['S', 'M', 'L', 'XL'], ordered=True)
codes = sizes.codes

print(f"Original: {list(sizes)}")
print(f"Codes: {list(codes)}")

# Convert back
back_to_cat = pd.Categorical.from_codes(codes, categories=['S', 'M', 'L', 'XL'])
print(f"Back to categories: {list(back_to_cat)}")





print("=== REAL-WORLD APPLICATIONS ===\n")

# Application 1: Customer Survey Analysis
print("Application 1: Customer Satisfaction Survey\n")

survey_data = pd.DataFrame({
    'customer_id': range(1, 11),
    'satisfaction': ['Satisfied', 'Very Satisfied', 'Neutral', 'Unsatisfied',
                    'Very Satisfied', 'Satisfied', 'Very Unsatisfied', 'Neutral',
                    'Satisfied', 'Very Satisfied'],
    'age': [25, 34, 45, 28, 52, 38, 31, 47, 29, 41]
})

# Create ordered categorical
survey_data['satisfaction'] = pd.Categorical(
    survey_data['satisfaction'],
    categories=['Very Unsatisfied', 'Unsatisfied', 'Neutral', 'Satisfied', 'Very Satisfied'],
    ordered=True
)

print("Survey data:")
print(survey_data)

print("\nSatisfaction distribution (maintains order):")
print(survey_data['satisfaction'].value_counts(sort=False))

# Filter positive responses
positive = survey_data[survey_data['satisfaction'] >= 'Satisfied']
print(f"\nPositive responses (>= Satisfied): {len(positive)} / {len(survey_data)} ({len(positive)/len(survey_data)*100:.0f}%)")
print()

# Application 2: Customer Segmentation
print("="*70)
print("Application 2: Customer Segmentation\n")

np.random.seed(42)
customers = pd.DataFrame({
    'customer_id': range(1, 21),
    'age': np.random.randint(20, 70, 20),
    'total_spent': np.random.randint(100, 5000, 20),
    'num_orders': np.random.randint(1, 50, 20)
})

# Age groups
customers['age_group'] = pd.cut(
    customers['age'],
    bins=[0, 30, 50, 100],
    labels=['Young', 'Middle-aged', 'Senior']
)

# Spending tiers
customers['spending_tier'] = pd.qcut(
    customers['total_spent'],
    q=3,
    labels=['Low', 'Medium', 'High']
)

print("Customer segments:")
print(customers[['customer_id', 'age', 'age_group', 'total_spent', 'spending_tier']].head(10))

print("\nSegment analysis:")
segment_summary = customers.groupby(['age_group', 'spending_tier']).agg({
    'customer_id': 'count',
    'total_spent': 'mean'
}).round(0)
segment_summary.columns = ['count', 'avg_spent']
print(segment_summary)
print()

# Application 3: E-commerce Order Status
print("="*70)
print("Application 3: E-commerce Order Status\n")

orders = pd.DataFrame({
    'order_id': range(1, 9),
    'status': ['Pending', 'Shipped', 'Processing', 'Delivered', 
               'Shipped', 'Cancelled', 'Delivered', 'Processing'],
    'amount': [100, 250, 175, 300, 150, 200, 275, 125]
})

# Ordered status
orders['status'] = pd.Categorical(
    orders['status'],
    categories=['Pending', 'Processing', 'Shipped', 'Delivered', 'Cancelled'],
    ordered=True
)

print("Orders:")
print(orders.sort_values('status'))

print("\nStatus distribution:")
print(orders['status'].value_counts(sort=False))

# Filter active orders
active = orders[orders['status'] < 'Delivered']
print(f"\nActive orders (not delivered/cancelled): {len(active)}")
print()

# Application 4: HR Performance Review
print("="*70)
print("Application 4: HR Performance Review\n")

employees = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank'],
    'level': ['Junior', 'Senior', 'Mid', 'Lead', 'Mid', 'Senior'],
    'score': [72, 88, 65, 95, 78, 91],
    'salary': [50000, 90000, 65000, 120000, 70000, 95000]
})

# Job level (ordered)
employees['level'] = pd.Categorical(
    employees['level'],
    categories=['Junior', 'Mid', 'Senior', 'Lead'],
    ordered=True
)

# Performance rating
employees['rating'] = pd.cut(
    employees['score'],
    bins=[0, 70, 80, 90, 100],
    labels=['Needs Improvement', 'Meets', 'Exceeds', 'Outstanding']
)

print(employees.sort_values('level'))

print("\nSalary by level:")
print(employees.groupby('level')['salary'].agg(['mean', 'min', 'max']).round(0))
print()

# Application 5: ML Preparation
print("="*70)
print("Application 5: Prepare data for Machine Learning\n")

ml_data = pd.DataFrame({
    'age': [25, 35, 45, 28, 52],
    'city': ['NYC', 'LA', 'NYC', 'Chicago', 'LA'],
    'education': ['Bachelor', 'Master', 'PhD', 'Bachelor', 'Master'],
    'income': [50000, 75000, 95000, 55000, 80000]
})

print("Original data:")
print(ml_data)

# Prepare features
ml_features = ml_data.copy()

# 1. Age groups
ml_features['age_group'] = pd.cut(
    ml_features['age'],
    bins=[0, 30, 50, 100],
    labels=['Young', 'Adult', 'Senior']
)

# 2. Education (ordinal encoding)
ml_features['education'] = pd.Categorical(
    ml_features['education'],
    categories=['High School', 'Bachelor', 'Master', 'PhD'],
    ordered=True
)
ml_features['education_code'] = ml_features['education'].cat.codes

# 3. City (one-hot encoding)
city_dummies = pd.get_dummies(ml_features['city'], prefix='city')

# Combine
ml_final = pd.concat([
    ml_features[['age', 'education_code', 'income']],
    city_dummies
], axis=1)

print("\nML-ready features:")
print(ml_final)
print("\nâœ… All categorical converted to numeric")
print("âœ… Ready for machine learning models!")








print("=== PRACTICE EXERCISE SOLUTIONS ===\n")

# Exercise 1: Create categorical
print("Exercise 1: Create and inspect categorical\n")
colors = pd.Series(['red', 'blue', 'green', 'red', 'blue'])
colors_cat = colors.astype('category')
print(f"Categories: {colors_cat.cat.categories.tolist()}")
print(f"Codes: {colors_cat.cat.codes.tolist()}")
print()

# Exercise 6: Memory comparison
print("="*70)
print("Exercise 6: Memory comparison\n")
n = 10000
data = ['Category_A', 'Category_B', 'Category_C'] * (n // 3)
df_obj = pd.DataFrame({'col': data})
df_cat = pd.DataFrame({'col': pd.Categorical(data)})

mem_obj = df_obj.memory_usage(deep=True).sum() / 1024
mem_cat = df_cat.memory_usage(deep=True).sum() / 1024
print(f"Object:      {mem_obj:.2f} KB")
print(f"Categorical: {mem_cat:.2f} KB")
print(f"Savings:     {(1 - mem_cat/mem_obj)*100:.1f}%")
print()

# Exercise 8: Quantile binning
print("="*70)
print("Exercise 8: Quartiles with equal counts\n")
values = list(range(1, 21))
quartiles = pd.qcut(values, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])
print(f"Values: {values}")
print(f"\nQuartiles: {list(quartiles)}")
print(f"\nCounts (should be equal):")
print(quartiles.value_counts())
print()

# Exercise 11: Customer segmentation
print("="*70)
print("Exercise 11: Customer segmentation\n")
np.random.seed(42)
customers = pd.DataFrame({
    'id': range(1, 13),
    'age': [22, 35, 45, 28, 52, 38, 61, 29, 44, 33, 56, 41],
    'spending': [500, 2500, 3500, 1500, 4500, 2000, 5000, 1000, 3000, 2200, 4000, 2800]
})

# Age groups
customers['age_group'] = pd.cut(
    customers['age'],
    bins=[0, 30, 50, 100],
    labels=['Young', 'Middle', 'Senior']
)

# Spending quartiles
customers['spend_tier'] = pd.qcut(
    customers['spending'],
    q=4,
    labels=['Low', 'Medium', 'High', 'Premium']
)

print(customers)
print("\nSegment counts:")
print(pd.crosstab(customers['age_group'], customers['spend_tier']))
print()

# Exercise 13: Mixed encoding
print("="*70)
print("Exercise 13: Mixed encoding for ML\n")
data = pd.DataFrame({
    'city': ['NYC', 'LA', 'NYC', 'Chicago'],      # Nominal
    'size': ['S', 'L', 'M', 'L'],                # Ordinal
    'rating': [4, 5, 3, 4]                       # Numeric
})

print("Original:")
print(data)

# One-hot for city (nominal)
city_encoded = pd.get_dummies(data['city'], prefix='city')

# Label encoding for size (ordinal)
size_cat = pd.Categorical(data['size'], categories=['S', 'M', 'L', 'XL'], ordered=True)
size_encoded = pd.Series(size_cat.codes, name='size_code')

# Combine
ml_ready = pd.concat([city_encoded, size_encoded, data['rating']], axis=1)
print("\nML-ready (all numeric):")
print(ml_ready)
print("\nâœ… Ready for machine learning!")






